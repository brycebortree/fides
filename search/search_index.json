{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction to Fides Fides [pronounced /fee-dhez/ , from Latin: Fid\u0113s] is an open-source privacy as code (PaC) tool by Ethyca that allows you to easily declare your systems' privacy characteristics, track privacy related changes to systems & data in version control, and enforce policies in both your source code and your runtime infrastructure. This includes support for major privacy regulations (e.g. GDPR , CCPA and LGPD ) and standards like ISO 19944 by default. Fides can manage both enforcement of privacy in your CI pipeline and orchestration of data privacy requests in your runtime environment. Why is it called Fides? Fides was the goddess of trust and good faith in Roman paganism. Fides represented everything that was required for \"honor and credibility\" in every aspect of Roman life. In addition to this, Fides means \"reliability\": reliability between two parties, which is always reciprocal . As we considered naming conventions, Fides stood out for her embodiment of this project's philosophy - to provide developers with a powerful tool to make privacy a default feature of any software. If you'd like a brief Roman mythology lesson, check out Fides on Wikipedia . Key Features Privacy as Code You describe your datasets and code using Fides' high-level description language in human-readable, declarative manifest files. This allows you to create a consistent, versioned definition of privacy characteristics in your code to automate reporting, evaluate risk and execute policies against. Automated Privacy Checks Fides integrates with git using the fidesctl tool to allow you to automate privacy checks in your CI pipeline and evalute changes against your privacy policies on each commit. This allows you to review changes and assure they meet your privacy policies before deployment. Support all Privacy Standards Fides ships with a comprehensive taxonomy that allows you to efficiently describe the privacy behaviors of your system for major regulations, including GDPR , CCPA and LGPD as well as major standards like ISO 19944 . Extensible Taxonomy Fides' taxonomy can be easily extended, allowing teams to add support for system specific concepts or data types while inheriting concepts to ensure compliance with global privacy regulations. Automate Privacy Reporting Fides' declarations can be configurd to automatically generate privacy review reports suitable for privacy and legal team review. This allows developers to focus on implementation while providing privacy teams with greater insight into the software's behavior. Data Privacy Rights Automation Fides' data orchestration capabilities mean you can use declarations to generate complex data rights automated processes that execute automatically against user's privacy rights requests. This allows you to easily configure automated, API driven privacy requests for access, erasure and de-identification of data. Next Steps To start learning how Fides works, visit the Tutorial page to walkthrough using the taxonomy, annotating datasets and systems, writing and evaluating policies, and more. Welcome!","title":"What is Fides?"},{"location":"#introduction-to-fides","text":"Fides [pronounced /fee-dhez/ , from Latin: Fid\u0113s] is an open-source privacy as code (PaC) tool by Ethyca that allows you to easily declare your systems' privacy characteristics, track privacy related changes to systems & data in version control, and enforce policies in both your source code and your runtime infrastructure. This includes support for major privacy regulations (e.g. GDPR , CCPA and LGPD ) and standards like ISO 19944 by default. Fides can manage both enforcement of privacy in your CI pipeline and orchestration of data privacy requests in your runtime environment.","title":"Introduction to Fides"},{"location":"#why-is-it-called-fides","text":"Fides was the goddess of trust and good faith in Roman paganism. Fides represented everything that was required for \"honor and credibility\" in every aspect of Roman life. In addition to this, Fides means \"reliability\": reliability between two parties, which is always reciprocal . As we considered naming conventions, Fides stood out for her embodiment of this project's philosophy - to provide developers with a powerful tool to make privacy a default feature of any software. If you'd like a brief Roman mythology lesson, check out Fides on Wikipedia .","title":"Why is it called Fides?"},{"location":"#key-features","text":"","title":"Key Features"},{"location":"#privacy-as-code","text":"You describe your datasets and code using Fides' high-level description language in human-readable, declarative manifest files. This allows you to create a consistent, versioned definition of privacy characteristics in your code to automate reporting, evaluate risk and execute policies against.","title":"Privacy as Code"},{"location":"#automated-privacy-checks","text":"Fides integrates with git using the fidesctl tool to allow you to automate privacy checks in your CI pipeline and evalute changes against your privacy policies on each commit. This allows you to review changes and assure they meet your privacy policies before deployment.","title":"Automated Privacy Checks"},{"location":"#support-all-privacy-standards","text":"Fides ships with a comprehensive taxonomy that allows you to efficiently describe the privacy behaviors of your system for major regulations, including GDPR , CCPA and LGPD as well as major standards like ISO 19944 .","title":"Support all Privacy Standards"},{"location":"#extensible-taxonomy","text":"Fides' taxonomy can be easily extended, allowing teams to add support for system specific concepts or data types while inheriting concepts to ensure compliance with global privacy regulations.","title":"Extensible Taxonomy"},{"location":"#automate-privacy-reporting","text":"Fides' declarations can be configurd to automatically generate privacy review reports suitable for privacy and legal team review. This allows developers to focus on implementation while providing privacy teams with greater insight into the software's behavior.","title":"Automate Privacy Reporting"},{"location":"#data-privacy-rights-automation","text":"Fides' data orchestration capabilities mean you can use declarations to generate complex data rights automated processes that execute automatically against user's privacy rights requests. This allows you to easily configure automated, API driven privacy requests for access, erasure and de-identification of data.","title":"Data Privacy Rights Automation"},{"location":"#next-steps","text":"To start learning how Fides works, visit the Tutorial page to walkthrough using the taxonomy, annotating datasets and systems, writing and evaluating policies, and more. Welcome!","title":"Next Steps"},{"location":"ci_reference/","text":"CI/CD Reference Fidesctl is primarily a tool designed to integrate with your CI pipeline configuration. You should plan to implement at least two CI actions: fidesctl evaluate --dry <resource_dir> Run against the latest commit on code changesets (pull requests, merge requests, etc.) Checks if code changes will be accepted, without also applying changes to the fidesctl server fidesctl evaluate <resource_dir> Run against commits representing merges into the default branch Synchronizes the latest changes to the fidesctl server The following code snippets are meant only as simple example implementations, to illustrate how you might integrate fidesctl using various popular CI pipline tools. Always inspect, understand, and test your production CI configuration files. GitHub Actions .github/workflows/fidesctl_ci.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 name : Fidesctl CI # Only check on Pull Requests that target main on : pull_request : branches : - main paths : # Only run checks when the resource files change or the workflow file changes - fides_resources/** - .github/workflows/fidesctl_ci.yml jobs : fidesctl_ci : runs-on : ubuntu-latest container : image : ethyca/fidesctl:latest steps : - name : Dry Evaluation uses : actions/checkout@v2 run : fidesctl evaluate --dry fides_resources/ env : FIDESCTL__CLI__SERVER_URL : \"https://fidesctl.privacyco.com\" .github/workflows/fidesctl_cd.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 name : Fidesctl CD # Run the check every time a new commit hits the default branch on : push : branches : - main tags : - \"*\" jobs : fidesctl_cd : runs-on : ubuntu-latest container : image : ethyca/fidesctl:latest steps : - name : Evaluation uses : actions/checkout@v2 run : fidesctl evaluate fides_resources/ env : FIDESCTL__CLI__SERVER_URL : \"https://fidesctl.privacyco.com\" GitLab CI .gitlab-ci.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 stages : - test - deploy variables : &global-variables FIDESCTL__CLI__SERVER_URL : \"https://fidesctl.privacyco.com\" fidesctl-ci : stage : test image : ethyca/fidesctl script : fidesctl evaluate --dry fides_resources/ only : if : '$CI_PIPELINE_SOURCE = merge_request_event' changes : - fides_resources/** - .gitlab-ci.yml variables : << : *global-variables fidesctl-cd : stage : deploy image : ethyca/fidesctl script : fidesctl evaluate fides_resources/ if : '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH' variables : << : *global-variables Jenkins Jenkinsfile (Declarative Syntax) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 pipeline { agent { docker { image 'ethyca/fidesctl:latest' } } stages { stage ( 'test' ){ environment { FIDESCTL__CLI__SERVER_URL = 'https://fidesctl.privacyco.com' } steps { sh 'fidesctl evaluate --dry fides_resources/' } when { anyOf { changeset 'fides_resources/**' changeset 'Jenkinsfile' } changeRequest () } } stage ( 'deploy' ) { environment { FIDESCTL__CLI__SERVER_URL = 'https://fidesctl.privacyco.com' } steps { sh 'fidesctl evaluate fides_resources/' } when { branch 'main' } } } } CircleCI .circleci/config.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 version : 2.1 executors : fidesctl : docker : - image : ethyca/fidesctl:latest environment : FIDESCTL__CLI__SERVER_URL : 'https://fidesctl.privacyco.com' jobs : fidesctl-evaluate-dry : executor : fidesctl steps : - run : fidesctl evaluate --dry fides_resources/ fidesctl-evaluate : executor : fidesctl steps : - run : fidesctl evaluate fides_resources/ workflows : version : 2 test : jobs : - fidesctl-evaluate-dry : filters : branches : ignore : main deploy : jobs : - fidesctl-evaluate : filters : branches : only : main","title":"CI/CD Reference"},{"location":"ci_reference/#cicd-reference","text":"Fidesctl is primarily a tool designed to integrate with your CI pipeline configuration. You should plan to implement at least two CI actions: fidesctl evaluate --dry <resource_dir> Run against the latest commit on code changesets (pull requests, merge requests, etc.) Checks if code changes will be accepted, without also applying changes to the fidesctl server fidesctl evaluate <resource_dir> Run against commits representing merges into the default branch Synchronizes the latest changes to the fidesctl server The following code snippets are meant only as simple example implementations, to illustrate how you might integrate fidesctl using various popular CI pipline tools. Always inspect, understand, and test your production CI configuration files.","title":"CI/CD Reference"},{"location":"ci_reference/#github-actions","text":".github/workflows/fidesctl_ci.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 name : Fidesctl CI # Only check on Pull Requests that target main on : pull_request : branches : - main paths : # Only run checks when the resource files change or the workflow file changes - fides_resources/** - .github/workflows/fidesctl_ci.yml jobs : fidesctl_ci : runs-on : ubuntu-latest container : image : ethyca/fidesctl:latest steps : - name : Dry Evaluation uses : actions/checkout@v2 run : fidesctl evaluate --dry fides_resources/ env : FIDESCTL__CLI__SERVER_URL : \"https://fidesctl.privacyco.com\" .github/workflows/fidesctl_cd.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 name : Fidesctl CD # Run the check every time a new commit hits the default branch on : push : branches : - main tags : - \"*\" jobs : fidesctl_cd : runs-on : ubuntu-latest container : image : ethyca/fidesctl:latest steps : - name : Evaluation uses : actions/checkout@v2 run : fidesctl evaluate fides_resources/ env : FIDESCTL__CLI__SERVER_URL : \"https://fidesctl.privacyco.com\"","title":"GitHub Actions"},{"location":"ci_reference/#gitlab-ci","text":".gitlab-ci.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 stages : - test - deploy variables : &global-variables FIDESCTL__CLI__SERVER_URL : \"https://fidesctl.privacyco.com\" fidesctl-ci : stage : test image : ethyca/fidesctl script : fidesctl evaluate --dry fides_resources/ only : if : '$CI_PIPELINE_SOURCE = merge_request_event' changes : - fides_resources/** - .gitlab-ci.yml variables : << : *global-variables fidesctl-cd : stage : deploy image : ethyca/fidesctl script : fidesctl evaluate fides_resources/ if : '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH' variables : << : *global-variables","title":"GitLab CI"},{"location":"ci_reference/#jenkins","text":"Jenkinsfile (Declarative Syntax) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 pipeline { agent { docker { image 'ethyca/fidesctl:latest' } } stages { stage ( 'test' ){ environment { FIDESCTL__CLI__SERVER_URL = 'https://fidesctl.privacyco.com' } steps { sh 'fidesctl evaluate --dry fides_resources/' } when { anyOf { changeset 'fides_resources/**' changeset 'Jenkinsfile' } changeRequest () } } stage ( 'deploy' ) { environment { FIDESCTL__CLI__SERVER_URL = 'https://fidesctl.privacyco.com' } steps { sh 'fidesctl evaluate fides_resources/' } when { branch 'main' } } } }","title":"Jenkins"},{"location":"ci_reference/#circleci","text":".circleci/config.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 version : 2.1 executors : fidesctl : docker : - image : ethyca/fidesctl:latest environment : FIDESCTL__CLI__SERVER_URL : 'https://fidesctl.privacyco.com' jobs : fidesctl-evaluate-dry : executor : fidesctl steps : - run : fidesctl evaluate --dry fides_resources/ fidesctl-evaluate : executor : fidesctl steps : - run : fidesctl evaluate fides_resources/ workflows : version : 2 test : jobs : - fidesctl-evaluate-dry : filters : branches : ignore : main deploy : jobs : - fidesctl-evaluate : filters : branches : only : main","title":"CircleCI"},{"location":"cli/","text":"CLI These docs reflect the latest PyPI release. fidesctl The parent group for the Fidesctl CLI. Usage: 1 fidesctl [OPTIONS] COMMAND1 [ARGS]... [COMMAND2 [ARGS]...]... Options: 1 2 3 4 5 6 7 8 9 --version Show the version and exit. -f, --config-path TEXT Path to a configuration file. Use 'fidesctl view- config' to print the config. --local Run in 'local_mode'. This mode doesn't make API calls and can be used without the API server/database. --help Show this message and exit. fidesctl annotate-dataset Guided flow for annotating datasets. The dataset file will be edited in-place. Usage: 1 fidesctl annotate-dataset [OPTIONS] INPUT_FILENAME Options: 1 2 3 -a, --all-members Annotate all dataset members, not just fields -v, --validate Strictly validate annotation inputs. --help Show this message and exit. fidesctl apply Validates local manifest files and then sends them to the server to be persisted. Usage: 1 fidesctl apply [OPTIONS] MANIFESTS_DIR Options: 1 2 3 4 5 --dry Does not send changes to the server. --diff Print the diff between the server's old and new states in Python DeepDiff format --help Show this message and exit. fidesctl delete Delete a resource on the server. Usage: 1 2 3 fidesctl delete [OPTIONS] [data_category|data_qualifier|data_subject|data_use| dataset|organization|policy|registry|system|evaluation] FIDES_KEY Options: 1 --help Show this message and exit. fidesctl evaluate Compare your System's Privacy Declarations with your Organization's Policy Rules. All local resources are applied to the server before evaluation. If your policy evaluation fails, it is expected that you will need to either adjust your Privacy Declarations, Datasets, or Policies before trying again. Usage: 1 fidesctl evaluate [OPTIONS] MANIFESTS_DIR Options: 1 2 3 4 5 6 7 8 -k, --fides-key TEXT The fides_key of the single policy that you wish to evaluate. -m, --message TEXT A message that you can supply to describe the context of this evaluation. --dry Does not send changes to the server. --help Show this message and exit. fidesctl generate-dataset Connect to a database directly via a SQLAlchemy-stlye connection string and generate a dataset manifest file that consists of every schema/table/field. This is a one-time operation that does not track the state of the database. It will need to be run again if the database schema changes. Usage: 1 fidesctl generate-dataset [OPTIONS] CONNECTION_STRING OUTPUT_FILENAME Options: 1 --help Show this message and exit. fidesctl get View a resource from the server as a JSON object. Usage: 1 2 fidesctl get [OPTIONS] [data_category|data_qualifier|data_subject|data_use|dat aset|organization|policy|registry|system|evaluation] FIDES_KEY Options: 1 --help Show this message and exit. fidesctl init-db Initialize the Fidesctl database. Usage: 1 fidesctl init-db [OPTIONS] Options: 1 --help Show this message and exit. fidesctl ls Get a list of all resources of this type from the server and display them as JSON. Usage: 1 2 fidesctl ls [OPTIONS] [data_category|data_qualifier|data_subject|data_use|data set|organization|policy|registry|system|evaluation] Options: 1 --help Show this message and exit. fidesctl parse Reads the resource files that are stored in MANIFESTS_DIR and its subdirectories to verify the validity of all manifest files. If the taxonomy is invalid, this command prints the error messages and triggers a non-zero exit code. Usage: 1 fidesctl parse [OPTIONS] MANIFESTS_DIR Options: 1 2 -v, --verbose Enable verbose output. --help Show this message and exit. fidesctl ping Sends a request to the Fidesctl API healthcheck endpoint and prints the response. Usage: 1 fidesctl ping [OPTIONS] Options: 1 --help Show this message and exit. fidesctl reset-db Wipes all user-created data and resets the database back to its freshly initialized state. Usage: 1 fidesctl reset-db [OPTIONS] Options: 1 2 -y, --yes Automatically responds 'yes' to any prompts. --help Show this message and exit. fidesctl view-config Prints the current fidesctl configuration values. Usage: 1 fidesctl view-config [OPTIONS] Options: 1 --help Show this message and exit. fidesctl webserver Starts the fidesctl API server using Uvicorn on port 8080. Usage: 1 fidesctl webserver [OPTIONS] Options: 1 --help Show this message and exit.","title":"CLI"},{"location":"cli/#cli","text":"These docs reflect the latest PyPI release.","title":"CLI"},{"location":"cli/#fidesctl","text":"The parent group for the Fidesctl CLI. Usage: 1 fidesctl [OPTIONS] COMMAND1 [ARGS]... [COMMAND2 [ARGS]...]... Options: 1 2 3 4 5 6 7 8 9 --version Show the version and exit. -f, --config-path TEXT Path to a configuration file. Use 'fidesctl view- config' to print the config. --local Run in 'local_mode'. This mode doesn't make API calls and can be used without the API server/database. --help Show this message and exit.","title":"fidesctl"},{"location":"cli/#fidesctl-annotate-dataset","text":"Guided flow for annotating datasets. The dataset file will be edited in-place. Usage: 1 fidesctl annotate-dataset [OPTIONS] INPUT_FILENAME Options: 1 2 3 -a, --all-members Annotate all dataset members, not just fields -v, --validate Strictly validate annotation inputs. --help Show this message and exit.","title":"annotate-dataset"},{"location":"cli/#fidesctl-apply","text":"Validates local manifest files and then sends them to the server to be persisted. Usage: 1 fidesctl apply [OPTIONS] MANIFESTS_DIR Options: 1 2 3 4 5 --dry Does not send changes to the server. --diff Print the diff between the server's old and new states in Python DeepDiff format --help Show this message and exit.","title":"apply"},{"location":"cli/#fidesctl-delete","text":"Delete a resource on the server. Usage: 1 2 3 fidesctl delete [OPTIONS] [data_category|data_qualifier|data_subject|data_use| dataset|organization|policy|registry|system|evaluation] FIDES_KEY Options: 1 --help Show this message and exit.","title":"delete"},{"location":"cli/#fidesctl-evaluate","text":"Compare your System's Privacy Declarations with your Organization's Policy Rules. All local resources are applied to the server before evaluation. If your policy evaluation fails, it is expected that you will need to either adjust your Privacy Declarations, Datasets, or Policies before trying again. Usage: 1 fidesctl evaluate [OPTIONS] MANIFESTS_DIR Options: 1 2 3 4 5 6 7 8 -k, --fides-key TEXT The fides_key of the single policy that you wish to evaluate. -m, --message TEXT A message that you can supply to describe the context of this evaluation. --dry Does not send changes to the server. --help Show this message and exit.","title":"evaluate"},{"location":"cli/#fidesctl-generate-dataset","text":"Connect to a database directly via a SQLAlchemy-stlye connection string and generate a dataset manifest file that consists of every schema/table/field. This is a one-time operation that does not track the state of the database. It will need to be run again if the database schema changes. Usage: 1 fidesctl generate-dataset [OPTIONS] CONNECTION_STRING OUTPUT_FILENAME Options: 1 --help Show this message and exit.","title":"generate-dataset"},{"location":"cli/#fidesctl-get","text":"View a resource from the server as a JSON object. Usage: 1 2 fidesctl get [OPTIONS] [data_category|data_qualifier|data_subject|data_use|dat aset|organization|policy|registry|system|evaluation] FIDES_KEY Options: 1 --help Show this message and exit.","title":"get"},{"location":"cli/#fidesctl-init-db","text":"Initialize the Fidesctl database. Usage: 1 fidesctl init-db [OPTIONS] Options: 1 --help Show this message and exit.","title":"init-db"},{"location":"cli/#fidesctl-ls","text":"Get a list of all resources of this type from the server and display them as JSON. Usage: 1 2 fidesctl ls [OPTIONS] [data_category|data_qualifier|data_subject|data_use|data set|organization|policy|registry|system|evaluation] Options: 1 --help Show this message and exit.","title":"ls"},{"location":"cli/#fidesctl-parse","text":"Reads the resource files that are stored in MANIFESTS_DIR and its subdirectories to verify the validity of all manifest files. If the taxonomy is invalid, this command prints the error messages and triggers a non-zero exit code. Usage: 1 fidesctl parse [OPTIONS] MANIFESTS_DIR Options: 1 2 -v, --verbose Enable verbose output. --help Show this message and exit.","title":"parse"},{"location":"cli/#fidesctl-ping","text":"Sends a request to the Fidesctl API healthcheck endpoint and prints the response. Usage: 1 fidesctl ping [OPTIONS] Options: 1 --help Show this message and exit.","title":"ping"},{"location":"cli/#fidesctl-reset-db","text":"Wipes all user-created data and resets the database back to its freshly initialized state. Usage: 1 fidesctl reset-db [OPTIONS] Options: 1 2 -y, --yes Automatically responds 'yes' to any prompts. --help Show this message and exit.","title":"reset-db"},{"location":"cli/#fidesctl-view-config","text":"Prints the current fidesctl configuration values. Usage: 1 fidesctl view-config [OPTIONS] Options: 1 --help Show this message and exit.","title":"view-config"},{"location":"cli/#fidesctl-webserver","text":"Starts the fidesctl API server using Uvicorn on port 8080. Usage: 1 fidesctl webserver [OPTIONS] Options: 1 --help Show this message and exit.","title":"webserver"},{"location":"ethyca/","text":"About Ethyca The mission of Ethyca is to make Internet-scale technology respectful and ethical. We're a venture-backed privacy technology team headquartered in New York, but working as a distributed team across the US to solve what we believe is the most important problem in technology today: the human right to privacy in vastly complex data-driven systems. What is Fides? Fides is a universally understandable, open-source language that can be used to describe privacy within tech infrastructure. Our existing tools ( Fidesctl and Fidesops ) use this language to power a low friction set of developer tools that integrate with your existing CI pipelines, making privacy a feature of your tech stack. With Fides, we hope everyone can build better tools for privacy in the next decade and beyond. What we Believe Data privacy is a human right that should be a native feature of any respectful technology. Today building great privacy as a feature in software is friction-filled and complicated. We're building open-source privacy tools for the developer community because we believe the only way to achieve a respectful internet is to make privacy an easy-to-implement layer of any tech stack. The Future We've been working on this problem since 2018 and have a clear view of our next five years. We're excited about the roadmap of features we'll add to Fides in order to make it the comprehensive tool for addressing the major challenges of privacy in both the code management and runtime environments. This means building solutions for automated privacy analysis, context rich data classification, automated data orchestration for privacy rights, semantic access control models, and more. We'd love you to contribute to Fides and you can do this directly as part of the open-source community. If you're interested in solving some of the toughest and most important problems facing internet scale data-driven software, join us now and get paid to work on this problem too! Your Participation Fides' success is predicated on your participation -- Privacy as Code can only become a reality if we ensure it's easy to understand, implement and an interopable standard for wide adoption. Your feedback, contributions and improvements are encouraged as we work towards building a community with the sole objective of building more repsectful software for everyone on the internet.","title":"About Ethyca"},{"location":"ethyca/#about-ethyca","text":"The mission of Ethyca is to make Internet-scale technology respectful and ethical. We're a venture-backed privacy technology team headquartered in New York, but working as a distributed team across the US to solve what we believe is the most important problem in technology today: the human right to privacy in vastly complex data-driven systems.","title":"About Ethyca"},{"location":"ethyca/#what-is-fides","text":"Fides is a universally understandable, open-source language that can be used to describe privacy within tech infrastructure. Our existing tools ( Fidesctl and Fidesops ) use this language to power a low friction set of developer tools that integrate with your existing CI pipelines, making privacy a feature of your tech stack. With Fides, we hope everyone can build better tools for privacy in the next decade and beyond.","title":"What is Fides?"},{"location":"ethyca/#what-we-believe","text":"Data privacy is a human right that should be a native feature of any respectful technology. Today building great privacy as a feature in software is friction-filled and complicated. We're building open-source privacy tools for the developer community because we believe the only way to achieve a respectful internet is to make privacy an easy-to-implement layer of any tech stack.","title":"What we Believe"},{"location":"ethyca/#the-future","text":"We've been working on this problem since 2018 and have a clear view of our next five years. We're excited about the roadmap of features we'll add to Fides in order to make it the comprehensive tool for addressing the major challenges of privacy in both the code management and runtime environments. This means building solutions for automated privacy analysis, context rich data classification, automated data orchestration for privacy rights, semantic access control models, and more. We'd love you to contribute to Fides and you can do this directly as part of the open-source community. If you're interested in solving some of the toughest and most important problems facing internet scale data-driven software, join us now and get paid to work on this problem too!","title":"The Future"},{"location":"ethyca/#your-participation","text":"Fides' success is predicated on your participation -- Privacy as Code can only become a reality if we ensure it's easy to understand, implement and an interopable standard for wide adoption. Your feedback, contributions and improvements are encouraged as we work towards building a community with the sole objective of building more repsectful software for everyone on the internet.","title":"Your Participation"},{"location":"license/","text":"License 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION 1. Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright 2021- Ethyca, Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"license/#license","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION 1. Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright 2021- Ethyca, Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"api/","text":"Fidesctl API These docs represent the cutting-edge, and may contain endpoints/features that have yet to be released in stable versions. const ui = SwaggerUIBundle({ url: 'openapi.json', dom_id: '#swagger-ui', }) /* If there is an anchor tag, reload it after the page loads to scroll to * that section, since the Swagger UI takes some time to render. */ if (location.hash) { setTimeout(function() { location.href = location.href }, 200); }","title":"API"},{"location":"api/#fidesctl-api","text":"These docs represent the cutting-edge, and may contain endpoints/features that have yet to be released in stable versions. const ui = SwaggerUIBundle({ url: 'openapi.json', dom_id: '#swagger-ui', }) /* If there is an anchor tag, reload it after the page loads to scroll to * that section, since the Swagger UI takes some time to render. */ if (location.hash) { setTimeout(function() { location.href = location.href }, 200); }","title":"Fidesctl API"},{"location":"community/code_of_conduct/","text":"Fides Code of Conduct Our Pledge In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. Our Standards Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct that could reasonably be considered inappropriate in a professional setting Our Responsibilities Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope This Code of Conduct applies within all project spaces, and it also applies when an individual is representing the project or its community in public spaces. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting Thomas at thomas@ethyca.com . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"Code of Conduct"},{"location":"community/code_of_conduct/#fides-code-of-conduct","text":"","title":"Fides Code of Conduct"},{"location":"community/code_of_conduct/#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.","title":"Our Pledge"},{"location":"community/code_of_conduct/#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct that could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"community/code_of_conduct/#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our Responsibilities"},{"location":"community/code_of_conduct/#scope","text":"This Code of Conduct applies within all project spaces, and it also applies when an individual is representing the project or its community in public spaces. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope"},{"location":"community/code_of_conduct/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting Thomas at thomas@ethyca.com . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement"},{"location":"community/code_of_conduct/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"Attribution"},{"location":"community/hints_tips/","text":"Community The Fides project welcomes issues, contributions and discussion from all users, regardless of background or experience level. In order to create a positive and welcoming environment, all interactions are governed by the Fides Code of Conduct . Guidelines Whether it's giving us feedback, raising a question, or showing your Fides-related work, we are looking forward to hearing from you. The Fides community is vibrant because of the quality of its members and the discussions they bring. To keep the workspace inviting and helpful for everyone, there are a few guidelines that we ask all members to follow. Rule 1: Assume Positive Intent Being nice is the most important pillar of the Fides community. We are considerate to each other's effort and time. It's also easy to misinterpret people through Slack, so we make an extra effort to chat in a positive tone. We assume that you are here to learn and exchange ideas, and we ask that you contribute to making a welcoming community. If someone is helping you, be mindful of the effort they are putting in. While we are always happy to help users, we can not help users with step-by-step debugging. Use your professional judgment in discerning whether requests are unreasonable. The Fides team always tries to listen to the community. Please be understanding if your issue or feature request is not deemed an immediate priority. Rule 2: Use threads for larger messages Because of the size of our community and frequency of posts, it's easy for large messages to drown out smaller messages. Using threads helps people see more messages on their screen. Larger code blocks should be posted in threads. Rule 3: Avoid posting sensitive information Community members sometimes need to post code snippets as they ask for help. Be sure to remove sensitive information from posts to the public channels. If your Fides account information is needed to help you, we will ask you to direct message such information. Be cautious of anyone asking for information through direct messages. Rule 4: Write high quality questions The Fides community is here to support you. That said, it is significantly easier to answer well-researched and clearly-written questions. Even adding potentially relevant links to a post helps tremendously. Informative Slack threads are archived by our resident bot Marvin. Having well-written threads helps future users encountering the same problem. Oftentimes your question may have been answered somewhere else; some good resources to start looking before asking a question: Fides Documentation GitHub Issues StackOverflow Rule 5: Don't abuse tagging users Requests for help will be seen by the Fides team, and will be directed to the appropriate person. Tagging individual users is highly discouraged unless it is in the context of a conversation thread. Rule 6: Avoid using DMs to ask for help Fides employees should not be sent questions in DMs unless we specifically ask you to send us private information. There are times when it makes sense to directly message another community member experiencing a similar issue, or working with similar technologies. Just be aware that some people may not want to be messaged. It also helps other people if you post your question publicly. Similar to above, informative Slack threads are archived. Having conversations in public channels drives better quality discussions that can be referenced in the future. Rule 7: Don't advertise material unrelated to Fides Our community is in the channel to learn more about Fides. Showing us Fides-related stuff that you're working on is highly encouraged. Advertising products and events unrelated to Fides will be removed.","title":"Community Hints & Tips"},{"location":"community/hints_tips/#community","text":"The Fides project welcomes issues, contributions and discussion from all users, regardless of background or experience level. In order to create a positive and welcoming environment, all interactions are governed by the Fides Code of Conduct .","title":"Community"},{"location":"community/hints_tips/#guidelines","text":"Whether it's giving us feedback, raising a question, or showing your Fides-related work, we are looking forward to hearing from you. The Fides community is vibrant because of the quality of its members and the discussions they bring. To keep the workspace inviting and helpful for everyone, there are a few guidelines that we ask all members to follow.","title":"Guidelines"},{"location":"community/hints_tips/#rule-1-assume-positive-intent","text":"Being nice is the most important pillar of the Fides community. We are considerate to each other's effort and time. It's also easy to misinterpret people through Slack, so we make an extra effort to chat in a positive tone. We assume that you are here to learn and exchange ideas, and we ask that you contribute to making a welcoming community. If someone is helping you, be mindful of the effort they are putting in. While we are always happy to help users, we can not help users with step-by-step debugging. Use your professional judgment in discerning whether requests are unreasonable. The Fides team always tries to listen to the community. Please be understanding if your issue or feature request is not deemed an immediate priority.","title":"Rule 1: Assume Positive Intent"},{"location":"community/hints_tips/#rule-2-use-threads-for-larger-messages","text":"Because of the size of our community and frequency of posts, it's easy for large messages to drown out smaller messages. Using threads helps people see more messages on their screen. Larger code blocks should be posted in threads.","title":"Rule 2: Use threads for larger messages"},{"location":"community/hints_tips/#rule-3-avoid-posting-sensitive-information","text":"Community members sometimes need to post code snippets as they ask for help. Be sure to remove sensitive information from posts to the public channels. If your Fides account information is needed to help you, we will ask you to direct message such information. Be cautious of anyone asking for information through direct messages.","title":"Rule 3: Avoid posting sensitive information"},{"location":"community/hints_tips/#rule-4-write-high-quality-questions","text":"The Fides community is here to support you. That said, it is significantly easier to answer well-researched and clearly-written questions. Even adding potentially relevant links to a post helps tremendously. Informative Slack threads are archived by our resident bot Marvin. Having well-written threads helps future users encountering the same problem. Oftentimes your question may have been answered somewhere else; some good resources to start looking before asking a question: Fides Documentation GitHub Issues StackOverflow","title":"Rule 4: Write high quality questions"},{"location":"community/hints_tips/#rule-5-dont-abuse-tagging-users","text":"Requests for help will be seen by the Fides team, and will be directed to the appropriate person. Tagging individual users is highly discouraged unless it is in the context of a conversation thread.","title":"Rule 5: Don't abuse tagging users"},{"location":"community/hints_tips/#rule-6-avoid-using-dms-to-ask-for-help","text":"Fides employees should not be sent questions in DMs unless we specifically ask you to send us private information. There are times when it makes sense to directly message another community member experiencing a similar issue, or working with similar technologies. Just be aware that some people may not want to be messaged. It also helps other people if you post your question publicly. Similar to above, informative Slack threads are archived. Having conversations in public channels drives better quality discussions that can be referenced in the future.","title":"Rule 6: Avoid using DMs to ask for help"},{"location":"community/hints_tips/#rule-7-dont-advertise-material-unrelated-to-fides","text":"Our community is in the channel to learn more about Fides. Showing us Fides-related stuff that you're working on is highly encouraged. Advertising products and events unrelated to Fides will be removed.","title":"Rule 7: Don't advertise material unrelated to Fides"},{"location":"community/overview/","text":"Join the Fides Community We believe the only way to solve privacy is as a community of likeminded developers that care to solve these problems for the rest of the world. To make it easier to connect and share ideas, we've created a set of community channels which we'd love to hear from you on: Start Contributing \u2003 Chat on Slack \u2003 Chat on Discord","title":"Github, Slack & Discord"},{"location":"community/overview/#join-the-fides-community","text":"We believe the only way to solve privacy is as a community of likeminded developers that care to solve these problems for the rest of the world. To make it easier to connect and share ideas, we've created a set of community channels which we'd love to hear from you on: Start Contributing \u2003 Chat on Slack \u2003 Chat on Discord","title":"Join the Fides Community"},{"location":"development/code_style/","text":"Code Style General Docstrings Docstrings are required for every function, class and method. No specific style is required or encouraged, as we expect that most of the relevant information can be gleaned from both the function signature's type-hints as well as descriptive parameter names. The docstring should serve to give additional context/flavour beyond that which can be gained from the code itself. Docstring Example 1 2 3 4 5 6 7 8 9 10 11 12 # Bad def execute_evaluation ( taxonomy : Taxonomy ) -> Evaluation : \"\"\" Execute an evaluation. \"\"\" # Good def execute_evaluation ( taxonomy : Taxonomy ) -> Evaluation : \"\"\" Check the stated constraints of each Privacy Policy's rules against each system's privacy declarations. \"\"\" Variable/Parameter Naming Variable and parameter names should be as self-describing as possible. Brevity is not a concern here. Here are some common examples for writing good self-documenting code: Single Letter Variable Names 1 2 3 4 5 6 7 8 9 10 11 12 13 # Incorrect s = 726 # Correct elapsed_time_seconds = 726 # Incorrect for n in nodes : print ( n ) # Correct for node in nodes : print ( node ) Abbreviated Variable Names 1 2 3 4 5 6 7 8 # Incorrect r = requests . get ( url ) # Incorrect resp = reqeusts . get ( url ) # Correct response = requests . get ( url ) Type Ambiguous Variable Names 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Incorrect food = [ \"apple\" , \"banana\" ] # Incorrect foods = [ \"apple\" , \"banana\" ] # Correct # Use type annotations if the name is somewhat ambiguous foods : List [ str ] = [ \"apple\" , \"banana\" ] # Correct # The type is contained in the name foods_list = [ \"apple\" , \"banana\" ] # Correct # Both of the above styles foods_list : List [ str ] = [ \"apple\" , \"banana\" ] Pre-Commit Hooks Fidesctl includes a .pre-commit-config.yaml to facilitate running CI checks before pushing up to a PR. The pre-commit package is included in the dev-requirements.txt . Once that is installed, follow these steps to get up and running: pre-commit install - This is a one-time setup step to create the git pre-commit hooks. These pre-commit hooks will now run automatically. However you can also use pre-commit run to run them manually once all of your changes have been staged. NOTE : A Python interpreter must be available from wherever the git commands are being run, as this is required to run the pre-commit package. CI Checks CI checks are stored as targets within the Makefile, and can be run from the top-level fides directory with the following pattern: Pattern 1 make <lowercased_name> Examples 1 2 3 make black make mypy make xenon Black formatting Fidesctl's code is formatted using the black style. This style is checked in a CI step, and merges to master are prevented if code does not conform. A number of extensions are available for popular editors that will automatically apply black to your code. Pylint Fidesctl's code is linted using pylint . Linter checks run as part of a CI step and merges to master are prevented if code does not conform. Mypy Fidesctl's code is statically-typed using mypy . Type checking is validated as a CI step, and merges to master are prevented if code does not pass type checks. As a general rule, mypy typing requires all function arguments and return values to be annotated. Xenon Fidesctl's code is checked for its cyclomatic-complexity by Xenon. If a single logical piece of code is deemed too complex, then a CI step will fail, at which point the focus should be on breaking up said complex function/method/class.","title":"Code Style"},{"location":"development/code_style/#code-style","text":"","title":"Code Style"},{"location":"development/code_style/#general","text":"","title":"General"},{"location":"development/code_style/#docstrings","text":"Docstrings are required for every function, class and method. No specific style is required or encouraged, as we expect that most of the relevant information can be gleaned from both the function signature's type-hints as well as descriptive parameter names. The docstring should serve to give additional context/flavour beyond that which can be gained from the code itself. Docstring Example 1 2 3 4 5 6 7 8 9 10 11 12 # Bad def execute_evaluation ( taxonomy : Taxonomy ) -> Evaluation : \"\"\" Execute an evaluation. \"\"\" # Good def execute_evaluation ( taxonomy : Taxonomy ) -> Evaluation : \"\"\" Check the stated constraints of each Privacy Policy's rules against each system's privacy declarations. \"\"\"","title":"Docstrings"},{"location":"development/code_style/#variableparameter-naming","text":"Variable and parameter names should be as self-describing as possible. Brevity is not a concern here. Here are some common examples for writing good self-documenting code: Single Letter Variable Names 1 2 3 4 5 6 7 8 9 10 11 12 13 # Incorrect s = 726 # Correct elapsed_time_seconds = 726 # Incorrect for n in nodes : print ( n ) # Correct for node in nodes : print ( node ) Abbreviated Variable Names 1 2 3 4 5 6 7 8 # Incorrect r = requests . get ( url ) # Incorrect resp = reqeusts . get ( url ) # Correct response = requests . get ( url ) Type Ambiguous Variable Names 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Incorrect food = [ \"apple\" , \"banana\" ] # Incorrect foods = [ \"apple\" , \"banana\" ] # Correct # Use type annotations if the name is somewhat ambiguous foods : List [ str ] = [ \"apple\" , \"banana\" ] # Correct # The type is contained in the name foods_list = [ \"apple\" , \"banana\" ] # Correct # Both of the above styles foods_list : List [ str ] = [ \"apple\" , \"banana\" ]","title":"Variable/Parameter Naming"},{"location":"development/code_style/#pre-commit-hooks","text":"Fidesctl includes a .pre-commit-config.yaml to facilitate running CI checks before pushing up to a PR. The pre-commit package is included in the dev-requirements.txt . Once that is installed, follow these steps to get up and running: pre-commit install - This is a one-time setup step to create the git pre-commit hooks. These pre-commit hooks will now run automatically. However you can also use pre-commit run to run them manually once all of your changes have been staged. NOTE : A Python interpreter must be available from wherever the git commands are being run, as this is required to run the pre-commit package.","title":"Pre-Commit Hooks"},{"location":"development/code_style/#ci-checks","text":"CI checks are stored as targets within the Makefile, and can be run from the top-level fides directory with the following pattern: Pattern 1 make <lowercased_name> Examples 1 2 3 make black make mypy make xenon","title":"CI Checks"},{"location":"development/code_style/#black-formatting","text":"Fidesctl's code is formatted using the black style. This style is checked in a CI step, and merges to master are prevented if code does not conform. A number of extensions are available for popular editors that will automatically apply black to your code.","title":"Black formatting"},{"location":"development/code_style/#pylint","text":"Fidesctl's code is linted using pylint . Linter checks run as part of a CI step and merges to master are prevented if code does not conform.","title":"Pylint"},{"location":"development/code_style/#mypy","text":"Fidesctl's code is statically-typed using mypy . Type checking is validated as a CI step, and merges to master are prevented if code does not pass type checks. As a general rule, mypy typing requires all function arguments and return values to be annotated.","title":"Mypy"},{"location":"development/code_style/#xenon","text":"Fidesctl's code is checked for its cyclomatic-complexity by Xenon. If a single logical piece of code is deemed too complex, then a CI step will fail, at which point the focus should be on breaking up said complex function/method/class.","title":"Xenon"},{"location":"development/database_migration/","text":"Database Migration Changes to fidesctl could require a change to the database model. This includes scenarios where you want to persist a new field or replace an existing field. Changes made to the fidesctl database are done through alembic migration scripts. Migrations can be found in the following direcotry: fidesctl/src/fidesapi/migrations/versions To create a new migration we use the alembic revision command: 1 2 cd fidesctl/src/fidesapi alembic revision --autogenerate -m \"migration message\" The autogenerated script should be verified and could require some manual changes. Migrations will run on the fidesctl server startup.","title":"Database Migration"},{"location":"development/database_migration/#database-migration","text":"Changes to fidesctl could require a change to the database model. This includes scenarios where you want to persist a new field or replace an existing field. Changes made to the fidesctl database are done through alembic migration scripts. Migrations can be found in the following direcotry: fidesctl/src/fidesapi/migrations/versions To create a new migration we use the alembic revision command: 1 2 cd fidesctl/src/fidesapi alembic revision --autogenerate -m \"migration message\" The autogenerated script should be verified and could require some manual changes. Migrations will run on the fidesctl server startup.","title":"Database Migration"},{"location":"development/documentation/","text":"Documentation Documentation is incredibly important to fidesctl, both for explaining its concepts to general audiences and describing its usage to developers. Concepts Fidesctl includes a great deal of \"concept\" documentation, which covers features, tutorials, guides, and examples separately from the auto-generated API reference. This page is part of the concept documentation for development! To write concept docs, add Markdown files to the docs/fides/docs/ directory (or one of its subdirectories). To ensure that your page is displayed in the navigation, edit mkdocs.yml to include a reference to it. Semantics Capitalization Concepts that refer to proper nouns or are trademarked should always be capitalized. The exception here is fidesctl and fidesops, which are lowercased as a stylistic choice. Other Fides terms, like \"Data Category\" or \"System\", should also be capitalized to be clear about the fact that a Fides resource is being referenced. When a System is applied, it is either created or updated through the fidesctl api. The System model requires a field called fides_key . Previewing docs locally Documentation (including both concepts and API references) is built and deployed with every merge to Fides's master branch. If you're using VS Code Dev Containers, the docs will automatically be available at localhost:8000 , otherwise you'll need to run the following command: 1 make docs-serve You'll see a status update as the docs build, and then an announcement that they are available on http://127.0.0.1:8000 .","title":"Documentation"},{"location":"development/documentation/#documentation","text":"Documentation is incredibly important to fidesctl, both for explaining its concepts to general audiences and describing its usage to developers.","title":"Documentation"},{"location":"development/documentation/#concepts","text":"Fidesctl includes a great deal of \"concept\" documentation, which covers features, tutorials, guides, and examples separately from the auto-generated API reference. This page is part of the concept documentation for development! To write concept docs, add Markdown files to the docs/fides/docs/ directory (or one of its subdirectories). To ensure that your page is displayed in the navigation, edit mkdocs.yml to include a reference to it.","title":"Concepts"},{"location":"development/documentation/#semantics","text":"","title":"Semantics"},{"location":"development/documentation/#capitalization","text":"Concepts that refer to proper nouns or are trademarked should always be capitalized. The exception here is fidesctl and fidesops, which are lowercased as a stylistic choice. Other Fides terms, like \"Data Category\" or \"System\", should also be capitalized to be clear about the fact that a Fides resource is being referenced. When a System is applied, it is either created or updated through the fidesctl api. The System model requires a field called fides_key .","title":"Capitalization"},{"location":"development/documentation/#previewing-docs-locally","text":"Documentation (including both concepts and API references) is built and deployed with every merge to Fides's master branch. If you're using VS Code Dev Containers, the docs will automatically be available at localhost:8000 , otherwise you'll need to run the following command: 1 make docs-serve You'll see a status update as the docs build, and then an announcement that they are available on http://127.0.0.1:8000 .","title":"Previewing docs locally"},{"location":"development/overview/","text":"Development Overview Thanks for contributing to Fidesctl! This section of the docs is designed to help you become familiar with how we work, the standards we apply, and how to ensure your contribution is successful. If you're stuck, don't be shy about asking for help on GitHub . Getting Started The first step is to clone the Fidesctl repo for development: 1 git clone https://github.com/ethyca/fides Once that's complete, there are a few different ways to spin up the project and get coding! Developer Workflows There are a few different ways to develop Fidesctl, they are listed below in order of how strongly they are recommended! If you're using VS Code, the recommended way to work on Fidesctl is by leveraging the Dev Containers feature. The repo has a .devcontainer/devcontainer.json file already included that will set up a complete environment in VS Code, including the suggested VS Code extensions and settings. Follow these steps to get started: Install the Remote-Containers extension for VS Code. Open the command window (the F1 key will open it, by default) and select the Remote-Containers: Open Folder in Container... command. Click \"Open\", without having selected any specific folder. The containers will now spin up and VS Code will be running inside of the containers. The bottom left of the IDE will now say Dev Container: Fidesctl . When you open a new VS Code shell, it will be inside of the fidesctl container, and you'll have access to all of the fidesctl commands as well as any Python commands like pytest , black , mypy , etc. If you're using an editor besides VS Code, then the next best way to work on Fidesctl is by utilizing the Makefile commands: Make sure that you have docker , docker-compose and make installed. Once you have everything set up, run make cli to spin up a shell within the fidesctl container. You can and should run all of your various development commands from within this shell, such as pytest , black , etc. Finally, the least-recommended method would be to install the project in your local environment and develop directly. Write your code We have no doubt you can write amazing code! However, we want to help you ensure your code plays nicely with the rest of the Fidesctl ecosystem. Many projects describe code style and documentation as a suggestion; in Fidesctl it's a CI-checked requirement. To learn how to style your code, see the style guide . To learn how to migrate the database schema, see the database migration guide . To learn how to document your code, see the docs guide . To learn how to test your code, see the tests guide . To learn what format your PR should follow, make sure to follow the pull request guidelines . Submit your code In order to submit code to Fidesctl, please: Fork the Fidesctl repository Create a new branch on your fork Open a Pull Request once your work is ready for review Once automated tests have passed, a maintainer will review your PR and provide feedback on any changes it requires to be approved. Once approved, your PR will be merged into Fidesctl. Congratulations You're a Fidesctl contributor - welcome to the team! \ud83c\udf89","title":"Overview"},{"location":"development/overview/#development-overview","text":"Thanks for contributing to Fidesctl! This section of the docs is designed to help you become familiar with how we work, the standards we apply, and how to ensure your contribution is successful. If you're stuck, don't be shy about asking for help on GitHub .","title":"Development Overview"},{"location":"development/overview/#getting-started","text":"The first step is to clone the Fidesctl repo for development: 1 git clone https://github.com/ethyca/fides Once that's complete, there are a few different ways to spin up the project and get coding!","title":"Getting Started"},{"location":"development/overview/#developer-workflows","text":"There are a few different ways to develop Fidesctl, they are listed below in order of how strongly they are recommended! If you're using VS Code, the recommended way to work on Fidesctl is by leveraging the Dev Containers feature. The repo has a .devcontainer/devcontainer.json file already included that will set up a complete environment in VS Code, including the suggested VS Code extensions and settings. Follow these steps to get started: Install the Remote-Containers extension for VS Code. Open the command window (the F1 key will open it, by default) and select the Remote-Containers: Open Folder in Container... command. Click \"Open\", without having selected any specific folder. The containers will now spin up and VS Code will be running inside of the containers. The bottom left of the IDE will now say Dev Container: Fidesctl . When you open a new VS Code shell, it will be inside of the fidesctl container, and you'll have access to all of the fidesctl commands as well as any Python commands like pytest , black , mypy , etc. If you're using an editor besides VS Code, then the next best way to work on Fidesctl is by utilizing the Makefile commands: Make sure that you have docker , docker-compose and make installed. Once you have everything set up, run make cli to spin up a shell within the fidesctl container. You can and should run all of your various development commands from within this shell, such as pytest , black , etc. Finally, the least-recommended method would be to install the project in your local environment and develop directly.","title":"Developer Workflows"},{"location":"development/overview/#write-your-code","text":"We have no doubt you can write amazing code! However, we want to help you ensure your code plays nicely with the rest of the Fidesctl ecosystem. Many projects describe code style and documentation as a suggestion; in Fidesctl it's a CI-checked requirement. To learn how to style your code, see the style guide . To learn how to migrate the database schema, see the database migration guide . To learn how to document your code, see the docs guide . To learn how to test your code, see the tests guide . To learn what format your PR should follow, make sure to follow the pull request guidelines .","title":"Write your code"},{"location":"development/overview/#submit-your-code","text":"In order to submit code to Fidesctl, please: Fork the Fidesctl repository Create a new branch on your fork Open a Pull Request once your work is ready for review Once automated tests have passed, a maintainer will review your PR and provide feedback on any changes it requires to be approved. Once approved, your PR will be merged into Fidesctl.","title":"Submit your code"},{"location":"development/overview/#congratulations","text":"You're a Fidesctl contributor - welcome to the team! \ud83c\udf89","title":"Congratulations"},{"location":"development/pull_requests/","text":"Pull Requests Pull requests are the primary unit of work within the Fidesctl project. All code changes are expected to be submitted via a PR, and as such here are a few requirements for submitting PRs: Completely fill out the provided pull request template. PRs should be in a draft state until they are ready for a final review + merge. A non-draft PR signals to the community that the author believes the PR is ready to ship! If you need early feedback on your PR, feel free to ask for it directly while your PR is in a draft state. Make sure that all checks are passing and all boxes have been checked before taking the PR out of a draft state. PR reviews require other people to spend their time, so please be courteous and double check your work before passing it to a reviewer. If you're unsure about a potential feature implementation or there is anything else that needs discussing, feel free to ask for an early review/feedback in the comments of the draft PR. PRs should be focused, reflecting a single logical change or feature. Generally, it is better to have multiple smaller PRs than one big one. This reduces the merge risk and shortens review time.","title":"Pull Requests"},{"location":"development/pull_requests/#pull-requests","text":"Pull requests are the primary unit of work within the Fidesctl project. All code changes are expected to be submitted via a PR, and as such here are a few requirements for submitting PRs: Completely fill out the provided pull request template. PRs should be in a draft state until they are ready for a final review + merge. A non-draft PR signals to the community that the author believes the PR is ready to ship! If you need early feedback on your PR, feel free to ask for it directly while your PR is in a draft state. Make sure that all checks are passing and all boxes have been checked before taking the PR out of a draft state. PR reviews require other people to spend their time, so please be courteous and double check your work before passing it to a reviewer. If you're unsure about a potential feature implementation or there is anything else that needs discussing, feel free to ask for an early review/feedback in the comments of the draft PR. PRs should be focused, reflecting a single logical change or feature. Generally, it is better to have multiple smaller PRs than one big one. This reduces the merge risk and shortens review time.","title":"Pull Requests"},{"location":"development/releases/","text":"Releases Versioning Fidesctl uses semantic versioning. Due to the rapid development of the project, some minor versions may also contain minor breaking changes. Best practice is always pinning versions and carefully testing before bumping to a new version. Patch versions will never cause breaking changes, and are only used to hotfix critical bugs. Release Schedule Fidesctl does not follow a set release schedule, but instead ships versions based on the addition of features/functionality. Each release, with the exception of hotfixes, will contain at least one substantial new feature. Planning For each release a corresponding GitHub Project is created. These projects can be found here . Issues are then added to release projects as a way to organize what will be included in each release. Once a release project is complete and the core team signs off on the readiness of the release, a new version is cut using GitHub releases. You can see all fidesctl releases here . Each new release triggers a GitHub Action that pushes the new version to PyPI and Conda as well as pushes a clean version to DockerHub. The release project is then marked as closed . Hotfixes are an exception to this and can be added and pushed as patch versions when needed. Branching Fidesctl uses continuous delivery with a single main branch. All code changes get merged into this branch. For releases, a new tag is created and the release process kicks off automatically. In the case of patches, a branch is created from the relevant tag and commits are then cherry-picked into it and a new patch version tag is created.","title":"Releases"},{"location":"development/releases/#releases","text":"","title":"Releases"},{"location":"development/releases/#versioning","text":"Fidesctl uses semantic versioning. Due to the rapid development of the project, some minor versions may also contain minor breaking changes. Best practice is always pinning versions and carefully testing before bumping to a new version. Patch versions will never cause breaking changes, and are only used to hotfix critical bugs.","title":"Versioning"},{"location":"development/releases/#release-schedule","text":"Fidesctl does not follow a set release schedule, but instead ships versions based on the addition of features/functionality. Each release, with the exception of hotfixes, will contain at least one substantial new feature.","title":"Release Schedule"},{"location":"development/releases/#planning","text":"For each release a corresponding GitHub Project is created. These projects can be found here . Issues are then added to release projects as a way to organize what will be included in each release. Once a release project is complete and the core team signs off on the readiness of the release, a new version is cut using GitHub releases. You can see all fidesctl releases here . Each new release triggers a GitHub Action that pushes the new version to PyPI and Conda as well as pushes a clean version to DockerHub. The release project is then marked as closed . Hotfixes are an exception to this and can be added and pushed as patch versions when needed.","title":"Planning"},{"location":"development/releases/#branching","text":"Fidesctl uses continuous delivery with a single main branch. All code changes get merged into this branch. For releases, a new tag is created and the release process kicks off automatically. In the case of patches, a branch is created from the relevant tag and commits are then cherry-picked into it and a new patch version tag is created.","title":"Branching"},{"location":"development/testing/","text":"Testing Fidesctl loves tests! There are a few important reasons to write tests: Make sure your code works Tests ensure that your code does the thing you intend it to do. If you have a function that adds two numbers, you'll want to test that it does, in fact, return their sum. If behavior depends on a configuration setting, ensure that changing that setting changes the behavior. In short, if you wrote a line of code, you should test that line works as expected. Make sure your code doesn't not work It may seem silly, but another important reason to write tests is to ensure that your code behaves as expected even when it's broken . This is especially important for a project like Fidesctl, which is focused on helping engineers when something unexpected happens to their code. For example, you could write tests about what you expect to happen if your function is called with incorrect (or no) arguments, or to ensure that any errors are properly trapped and handled. Tests are documentation Ultimately, your tests are the best documentation for your code. Another developer should be able to look at your tests and understand what your code does, how to invoke it, and what edge cases it contains. Therefore, try to write short, self-explanatory tests with descriptive titles. Help future developers As Fidesctl grows, your code will be reused in more and more places, by developers who may not be familiar with the details of your implementation. Therefore, your tests are an opportunity to ensure that your code is used correctly in the future. For example, if your code needs to be used in a certain way, or expects a certain configuration, or is always expected to return a certain output, or has any other details that might impact its ability to be used in the framework, write a test for it! At minimum, you'll help a future developer understand that you consciously chose to design your code a certain way. Writing tests Fidesctl's tests are stored in the tests directory. Tests should have descriptive names that make it clear what you're testing. If necessary, add a docstring or comment to explain why you're testing this specific thing. 1 2 3 4 5 6 7 # Good test name def test_dry_evaluate_system_fail ( server_url , resources_dict ): ... # Bad test name def test_dry_evaluate (): ... Fidesctl has a few pytest fixtures available for testing; see conftest.py for details. Integration tests vs. Mocked tests Generally, tests that include mocking are discouraged. Mocking can create a false sense of security and obfuscate possible errors in the code that only present themselves when integration tested. Running tests Fidesctl uses pytest for unit testing. To run tests, invoke pytest from the /fides/fidesctl/ directory: 1 2 cd fidesctl pytest Running specific tests To run a subset of tests, provide a filename or directory; to match a specific test name, use the -k flag: 1 2 # run all tests in the tests/integration directory that contain the word \"api\" in their title pytest tests/integration/ -k api The --sw flag will exit pytest the first time it encounters an error; subsequent runs with the same flag will skip any tests that succeeded and run the failed test first. For more information on available Pytest invocation options, see the documentation here . CI Workflows CI will run automatically against any PR you open. Please run your tests locally first to avoid \"debugging in CI\", as this takes up resources that could be used by other contributors and is generally an inefficient usage of your time!","title":"Testing"},{"location":"development/testing/#testing","text":"Fidesctl loves tests! There are a few important reasons to write tests: Make sure your code works Tests ensure that your code does the thing you intend it to do. If you have a function that adds two numbers, you'll want to test that it does, in fact, return their sum. If behavior depends on a configuration setting, ensure that changing that setting changes the behavior. In short, if you wrote a line of code, you should test that line works as expected. Make sure your code doesn't not work It may seem silly, but another important reason to write tests is to ensure that your code behaves as expected even when it's broken . This is especially important for a project like Fidesctl, which is focused on helping engineers when something unexpected happens to their code. For example, you could write tests about what you expect to happen if your function is called with incorrect (or no) arguments, or to ensure that any errors are properly trapped and handled. Tests are documentation Ultimately, your tests are the best documentation for your code. Another developer should be able to look at your tests and understand what your code does, how to invoke it, and what edge cases it contains. Therefore, try to write short, self-explanatory tests with descriptive titles. Help future developers As Fidesctl grows, your code will be reused in more and more places, by developers who may not be familiar with the details of your implementation. Therefore, your tests are an opportunity to ensure that your code is used correctly in the future. For example, if your code needs to be used in a certain way, or expects a certain configuration, or is always expected to return a certain output, or has any other details that might impact its ability to be used in the framework, write a test for it! At minimum, you'll help a future developer understand that you consciously chose to design your code a certain way.","title":"Testing"},{"location":"development/testing/#writing-tests","text":"Fidesctl's tests are stored in the tests directory. Tests should have descriptive names that make it clear what you're testing. If necessary, add a docstring or comment to explain why you're testing this specific thing. 1 2 3 4 5 6 7 # Good test name def test_dry_evaluate_system_fail ( server_url , resources_dict ): ... # Bad test name def test_dry_evaluate (): ... Fidesctl has a few pytest fixtures available for testing; see conftest.py for details.","title":"Writing tests"},{"location":"development/testing/#integration-tests-vs-mocked-tests","text":"Generally, tests that include mocking are discouraged. Mocking can create a false sense of security and obfuscate possible errors in the code that only present themselves when integration tested.","title":"Integration tests vs. Mocked tests"},{"location":"development/testing/#running-tests","text":"Fidesctl uses pytest for unit testing. To run tests, invoke pytest from the /fides/fidesctl/ directory: 1 2 cd fidesctl pytest","title":"Running tests"},{"location":"development/testing/#running-specific-tests","text":"To run a subset of tests, provide a filename or directory; to match a specific test name, use the -k flag: 1 2 # run all tests in the tests/integration directory that contain the word \"api\" in their title pytest tests/integration/ -k api The --sw flag will exit pytest the first time it encounters an error; subsequent runs with the same flag will skip any tests that succeeded and run the failed test first. For more information on available Pytest invocation options, see the documentation here .","title":"Running specific tests"},{"location":"development/testing/#ci-workflows","text":"CI will run automatically against any PR you open. Please run your tests locally first to avoid \"debugging in CI\", as this takes up resources that could be used by other contributors and is generally an inefficient usage of your time!","title":"CI Workflows"},{"location":"guides/generate_dataset/","text":"Generating a Dataset As an alternative to manually creating dataset resource files like in our tutorial , it is possible to generate these files using the generate-dataset CLI command. The CLI will connect to a given resource and automatically generate a non-annotated resource YAML file in the specified location, based on the database schema. Not only is this the simplest way to begin annotating your resources, but it also follows the expected fidesctl format for these resources. This is important as some commands, like scan , expect resources to follow this format. Working With a Database The generate-dataset command can connect to a database and automatically generate resource YAML file. Given a database schema with a single users table as follows: 1 2 3 4 5 6 flaskr = # SELECT * FROM users; id | created_at | email | password | first_name | last_name ----+---------------------+-------------------+------------------------------------+------------+----------- 1 | 2020 -01-01 00 :00:00 | admin@example.com | pbkdf2:sha256:260000 $O87nanbSkl ... | Admin | User 2 | 2020 -01-03 00 :00:00 | user@example.com | pbkdf2:sha256:260000 $PGcBy5NzZe ... | Example | User ( 2 rows ) We can invoke the generate-dataset by simply providing a connection url for this database: 1 2 3 ./venv/bin/fidesctl generate-dataset \\ postgresql://postgres:postgres@localhost:5432/flaskr \\ fides_resources/flaskr_postgres_dataset.yml The result is a resource file with a dataset with collections and fields to represent our schema: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 dataset : - fides_key : public organization_fides_key : default_organization name : public description : 'Fides Generated Description for Schema: public' meta : null data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified collections : - name : public.users description : 'Fides Generated Description for Table: public.users' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified fields : - name : created_at description : 'Fides Generated Description for Column: created_at' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : email description : 'Fides Generated Description for Column: email' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : first_name description : 'Fides Generated Description for Column: first_name' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : id description : 'Fides Generated Description for Column: id' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : last_name description : 'Fides Generated Description for Column: last_name' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : password description : 'Fides Generated Description for Column: password' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified The resulting file still requires annotating the dataset with data categories to represent what is stored.","title":"Generating a Dataset"},{"location":"guides/generate_dataset/#generating-a-dataset","text":"As an alternative to manually creating dataset resource files like in our tutorial , it is possible to generate these files using the generate-dataset CLI command. The CLI will connect to a given resource and automatically generate a non-annotated resource YAML file in the specified location, based on the database schema. Not only is this the simplest way to begin annotating your resources, but it also follows the expected fidesctl format for these resources. This is important as some commands, like scan , expect resources to follow this format.","title":"Generating a Dataset"},{"location":"guides/generate_dataset/#working-with-a-database","text":"The generate-dataset command can connect to a database and automatically generate resource YAML file. Given a database schema with a single users table as follows: 1 2 3 4 5 6 flaskr = # SELECT * FROM users; id | created_at | email | password | first_name | last_name ----+---------------------+-------------------+------------------------------------+------------+----------- 1 | 2020 -01-01 00 :00:00 | admin@example.com | pbkdf2:sha256:260000 $O87nanbSkl ... | Admin | User 2 | 2020 -01-03 00 :00:00 | user@example.com | pbkdf2:sha256:260000 $PGcBy5NzZe ... | Example | User ( 2 rows ) We can invoke the generate-dataset by simply providing a connection url for this database: 1 2 3 ./venv/bin/fidesctl generate-dataset \\ postgresql://postgres:postgres@localhost:5432/flaskr \\ fides_resources/flaskr_postgres_dataset.yml The result is a resource file with a dataset with collections and fields to represent our schema: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 dataset : - fides_key : public organization_fides_key : default_organization name : public description : 'Fides Generated Description for Schema: public' meta : null data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified collections : - name : public.users description : 'Fides Generated Description for Table: public.users' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified fields : - name : created_at description : 'Fides Generated Description for Column: created_at' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : email description : 'Fides Generated Description for Column: email' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : first_name description : 'Fides Generated Description for Column: first_name' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : id description : 'Fides Generated Description for Column: id' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : last_name description : 'Fides Generated Description for Column: last_name' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : password description : 'Fides Generated Description for Column: password' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified The resulting file still requires annotating the dataset with data categories to represent what is stored.","title":"Working With a Database"},{"location":"guides/scan_resource/","text":"Scanning a Resource As you annotate resources with fidesctl it is important to keep your fidesctl resources up to date. The scan command is available to compare your resources and what is defined in your fidesctl server or resource files. It will output any part of the dataset which is not defined or categorized. The command will exit in error if a coverage threshold is not met. The scan command works best when used in tandem with the generate-dataset command as it creates resources in the expected format. The fidesctl format for datasets must be followed in order to be able to track coverage. Scanning a Database The scan command can connect to a database and compare its schema to your already defined resources. Given a database schema with a single users table as follows: 1 2 3 4 5 6 flaskr = # SELECT * FROM users; id | created_at | email | password | first_name | last_name ----+---------------------+-------------------+------------------------------------+------------+----------- 1 | 2020 -01-01 00 :00:00 | admin@example.com | pbkdf2:sha256:260000 $O87nanbSkl ... | Admin | User 2 | 2020 -01-03 00 :00:00 | user@example.com | pbkdf2:sha256:260000 $PGcBy5NzZe ... | Example | User ( 2 rows ) We have fully annotated this schema before with the following dataset resource file: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 dataset : - fides_key : public organization_fides_key : default_organization name : public description : 'Fides Generated Description for Schema: public' meta : null data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified collections : - name : public.users description : 'Fides Generated Description for Table: public.users' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified fields : - name : created_at description : 'Fides Generated Description for Column: created_at' data_categories : [ system.operations ] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : email description : 'Fides Generated Description for Column: email' data_categories : [ user.provided.identifiable.contact.email ] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : first_name description : 'Fides Generated Description for Column: first_name' data_categories : [ user.provided.identifiable.name ] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : id description : 'Fides Generated Description for Column: id' data_categories : [ user.derived.identifiable.unique_id ] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : last_name description : 'Fides Generated Description for Column: last_name' data_categories : [ user.provided.identifiable.name ] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : password description : 'Fides Generated Description for Column: password' data_categories : [ user.provided.identifiable.credentials.password ] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified fidesctl scan --manifest-dir dataset.yml database postgresql+psycopg2://postgres:fidesctl@fidesctl-db:5432/postgres We can invoke the scan by simply providing a connection url for this database: 1 2 3 4 ./venv/bin/fidesctl scan \\ --manifest-dir dataset.yml \\ database \\ postgresql+psycopg2://postgres:fidesctl@fidesctl-db:5432/postgres The command output confirms our database resource is covered fully! 1 2 3 4 5 6 Loading resource manifests from: dataset.yml Taxonomy successfully created. Successfully scanned the following datasets: public Annotation coverage: 100 %","title":"Scanning a Resource"},{"location":"guides/scan_resource/#scanning-a-resource","text":"As you annotate resources with fidesctl it is important to keep your fidesctl resources up to date. The scan command is available to compare your resources and what is defined in your fidesctl server or resource files. It will output any part of the dataset which is not defined or categorized. The command will exit in error if a coverage threshold is not met. The scan command works best when used in tandem with the generate-dataset command as it creates resources in the expected format. The fidesctl format for datasets must be followed in order to be able to track coverage.","title":"Scanning a Resource"},{"location":"guides/scan_resource/#scanning-a-database","text":"The scan command can connect to a database and compare its schema to your already defined resources. Given a database schema with a single users table as follows: 1 2 3 4 5 6 flaskr = # SELECT * FROM users; id | created_at | email | password | first_name | last_name ----+---------------------+-------------------+------------------------------------+------------+----------- 1 | 2020 -01-01 00 :00:00 | admin@example.com | pbkdf2:sha256:260000 $O87nanbSkl ... | Admin | User 2 | 2020 -01-03 00 :00:00 | user@example.com | pbkdf2:sha256:260000 $PGcBy5NzZe ... | Example | User ( 2 rows ) We have fully annotated this schema before with the following dataset resource file: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 dataset : - fides_key : public organization_fides_key : default_organization name : public description : 'Fides Generated Description for Schema: public' meta : null data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified collections : - name : public.users description : 'Fides Generated Description for Table: public.users' data_categories : [] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified fields : - name : created_at description : 'Fides Generated Description for Column: created_at' data_categories : [ system.operations ] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : email description : 'Fides Generated Description for Column: email' data_categories : [ user.provided.identifiable.contact.email ] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : first_name description : 'Fides Generated Description for Column: first_name' data_categories : [ user.provided.identifiable.name ] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : id description : 'Fides Generated Description for Column: id' data_categories : [ user.derived.identifiable.unique_id ] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : last_name description : 'Fides Generated Description for Column: last_name' data_categories : [ user.provided.identifiable.name ] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - name : password description : 'Fides Generated Description for Column: password' data_categories : [ user.provided.identifiable.credentials.password ] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified fidesctl scan --manifest-dir dataset.yml database postgresql+psycopg2://postgres:fidesctl@fidesctl-db:5432/postgres We can invoke the scan by simply providing a connection url for this database: 1 2 3 4 ./venv/bin/fidesctl scan \\ --manifest-dir dataset.yml \\ database \\ postgresql+psycopg2://postgres:fidesctl@fidesctl-db:5432/postgres The command output confirms our database resource is covered fully! 1 2 3 4 5 6 Loading resource manifests from: dataset.yml Taxonomy successfully created. Successfully scanned the following datasets: public Annotation coverage: 100 %","title":"Scanning a Database"},{"location":"installation/conda/","text":"Installation from Conda This page describes installations using the fidesctl package published on Conda . Installation To install fidesctl, first create an environment with the fidesctl package and necessary channels: 1 2 3 4 conda create --name fidesctl-environment fidesctl \\ --channel ethyca \\ --channel plotly \\ --channel conda-forge Then activate your environment to begin using the fidesctl cli: conda activate fidesctl-environment","title":"Installation from Conda"},{"location":"installation/conda/#installation-from-conda","text":"This page describes installations using the fidesctl package published on Conda .","title":"Installation from Conda"},{"location":"installation/conda/#installation","text":"To install fidesctl, first create an environment with the fidesctl package and necessary channels: 1 2 3 4 conda create --name fidesctl-environment fidesctl \\ --channel ethyca \\ --channel plotly \\ --channel conda-forge Then activate your environment to begin using the fidesctl cli: conda activate fidesctl-environment","title":"Installation"},{"location":"installation/configuration/","text":"Configuration Fidesctl supports two methods of configuration. The first is via a toml file, and the second is via environment variables. They can also be used in tandem, with the environment variables overriding the toml configuration values. By default the fidesctl CLI doesn't require a config file and will instead leverage the default values. These are very likely to be wrong however so it is recommended to always configure your settings properly. Configuration file Here's an example of a fidesctl configuration file: 1 2 3 4 5 6 7 8 9 10 11 [cli] server_url = \"http://localhost:8080\" [api] database_url = \"postgresql://postgres:postgres@localhost:5432/fidesctl\" test_database_url = \"postgresql://postgres:postgres@localhost:5432/fidesctl_test\" # The following are set to their current default values log_destination = \"\" # Also accepts: Any valid file path log_level = \"INFO\" # Also accepts: TRACE, DEBUG, WARNING, ERROR, CRITICAL (Not case sensitive) log_serialization = \"\" # Also accepts: JSON (Not case sensitive) By default fidesctl will look for a configuration file in the following three places: At the path specified by the FIDESCTL_CONFIG_PATH environment variable In the current working directory In the user's home directory Environment Variables To configure environment variables for fidesctl, the following pattern is used: 1 FIDESCTL__<SECTION>__<VAR_NAME> For example, if we want to set the server_url on a Linux machine we could use: 1 export FIDESCTL__CLI__SERVER_URL = \"http://localhost:8080\"","title":"Configuration"},{"location":"installation/configuration/#configuration","text":"Fidesctl supports two methods of configuration. The first is via a toml file, and the second is via environment variables. They can also be used in tandem, with the environment variables overriding the toml configuration values. By default the fidesctl CLI doesn't require a config file and will instead leverage the default values. These are very likely to be wrong however so it is recommended to always configure your settings properly.","title":"Configuration"},{"location":"installation/configuration/#configuration-file","text":"Here's an example of a fidesctl configuration file: 1 2 3 4 5 6 7 8 9 10 11 [cli] server_url = \"http://localhost:8080\" [api] database_url = \"postgresql://postgres:postgres@localhost:5432/fidesctl\" test_database_url = \"postgresql://postgres:postgres@localhost:5432/fidesctl_test\" # The following are set to their current default values log_destination = \"\" # Also accepts: Any valid file path log_level = \"INFO\" # Also accepts: TRACE, DEBUG, WARNING, ERROR, CRITICAL (Not case sensitive) log_serialization = \"\" # Also accepts: JSON (Not case sensitive) By default fidesctl will look for a configuration file in the following three places: At the path specified by the FIDESCTL_CONFIG_PATH environment variable In the current working directory In the user's home directory","title":"Configuration file"},{"location":"installation/configuration/#environment-variables","text":"To configure environment variables for fidesctl, the following pattern is used: 1 FIDESCTL__<SECTION>__<VAR_NAME> For example, if we want to set the server_url on a Linux machine we could use: 1 export FIDESCTL__CLI__SERVER_URL = \"http://localhost:8080\"","title":"Environment Variables"},{"location":"installation/database/","text":"Setting up the database The fidesctl webserver is the only part of the application that touches the fidesctl database directly. It will automatically run migrations and seed the database with the default taxonomy on startup. If needed, you can also run fidesctl init-db or fidesctl reset-db via the CLI, which will tell the webserver to execute those actions, although these should not be needed under normal circumstances.","title":"Setting up the database"},{"location":"installation/database/#setting-up-the-database","text":"The fidesctl webserver is the only part of the application that touches the fidesctl database directly. It will automatically run migrations and seed the database with the default taxonomy on startup. If needed, you can also run fidesctl init-db or fidesctl reset-db via the CLI, which will tell the webserver to execute those actions, although these should not be needed under normal circumstances.","title":"Setting up the database"},{"location":"installation/docker/","text":"Installation from Docker For the ease of deployment in production, the community releases a production-ready reference container image. The fidesctl community releases Docker Images which are reference images for fidesctl. Every time a new version of fidesctl is released, the images are available in the ethyca/fidesctl DockerHub . There are also mid-release versions (dirty versions) that get uploaded to DockerHub on every commit to the main branch. These reference images contain all of the extras and dependencies for running the Python application. However they do not contain the required Postgres database. Fidesctl requires multiple components to function as it is a multi-part application. You may therefore also be interested in launching fidesctl in the Docker Compose environment, see: Running Fidesctl in Docker .","title":"Installation from Docker"},{"location":"installation/docker/#installation-from-docker","text":"For the ease of deployment in production, the community releases a production-ready reference container image. The fidesctl community releases Docker Images which are reference images for fidesctl. Every time a new version of fidesctl is released, the images are available in the ethyca/fidesctl DockerHub . There are also mid-release versions (dirty versions) that get uploaded to DockerHub on every commit to the main branch. These reference images contain all of the extras and dependencies for running the Python application. However they do not contain the required Postgres database. Fidesctl requires multiple components to function as it is a multi-part application. You may therefore also be interested in launching fidesctl in the Docker Compose environment, see: Running Fidesctl in Docker .","title":"Installation from Docker"},{"location":"installation/installation/","text":"Installation This page describes installation options that you might use when considering how to install fidesctl. Fidesctl consists of multiple components, possibly distributed among various physical or virtual machines. Fidesctl can be deployed flexibly, meeting the needs of various environments with different levels of complexity. You should also check-out the prerequisites that must be fulfilled when installing fidesctl. Fidesctl requires additional dependencies to be installed - which can be done via extras . When you install fidesctl, you need to setup the database which must also be kept updated when fidesctl is upgraded. Installation Tools Only pip and conda installations are currently officially supported. For more details see Installation from PyPI or Installation from Conda In some cases a lightweight installation might be desired, for instance, if the webserver is not needed. If this is the case, our pip installation supports optional dependencies. While there are some successes with using other tools like poetry or pip-tools, they do not share the same workflow as the supported tools - especially when it comes to constraint vs. requirements management. Installing via Poetry or pip-tools is not currently supported. If you wish to install fidesctl using those tools you do so at your own discretion. When this option works best This installation method is useful when you are not familiar with containers and Docker and want to install fidesctl on physical or virtual machines and you are used to installing and running software using custom deployment mechanism. The only officially supported mechanisms of installation are pip and conda. Intended users Users who are familiar with installing and configuring Python applications, managing Python environments, dependencies and running software with their custom deployment mechanisms. What are you expected to handle You are expected to install fidesctl - all components of it - on your own. You should develop and handle the deployment for all components of fidesctl. You are responsible for setting up the database, automated startup and recovery, maintenance, cleanup and upgrades of fidesctl. What the Fidesctl community provides for this method You have Installation from PyPI and Installation from Conda on how to install the software but due to various environments and tools you might want to use, you might expect that there will be problems which are specific to your deployment and environment that you will have to diagnose and solve. You have the Running fidesctl Locally guide where you can see an example of running fidesctl with minimal dependencies and setup. You can use this guide to start fidesctl quickly for local testing and development, however this is only intended to provide inspiration, not to represent a production-grade installation. Where to ask for help For quick and general troubleshooting questions, visit the #troubleshooting channel on the fidesctl Slack. For longer discussions or to share information, visit the GitHub discussions page. If you can provide description of a reproducible problem with the fidesctl software, you can open issue in GitHub issues . Using Production Docker Images More details: Installation from Docker When this option works best This installation method is useful if you are familiar with the container/Docker stack. It provides a capability of running fidesctl components in isolation from other software running on the same physical or virtual machines with easy maintenance of dependencies. The images are built by fidesctl CI/CD pipelines and offer versions for official releases as well as for every commit made to the main branch. For this reason, it is highly discouraged to use the latest tag, as any non-official release versions may contain some instability. Intended users Users who are familiar with containers and Docker stack and understand how to build and extend their own container images. Users who know how to create deployments using Docker by linking together multiple Docker containers and maintaining such deployments. What are you expected to handle You are expected to be able to customize or extend container/Docker images if you want to add extra dependencies. You are expected to put together a deployment built of several containers (for example using docker-compose) and to make sure that they are linked together. You are responsible for setting up the database, automated startup and recovery, maintenance, cleanup and upgrades of fidesctl. You should choose the right deployment mechanism. There a number of available options of deployments of containers. You can use your own custom mechanism, custom Kubernetes deployments, custom Docker Compose, custom Helm charts etc., and you should choose it based on your experience and expectations. What the Fidesctl community provides for this method You have Running Fidesctl in Docker where you can see an example of how to start fidesctl quickly for local testing and development. However this is just an inspiration. Do not expect to use this docker-compose.yml file for production installation, you need to get familiar with Docker Compose and its capabilities and build your own production-ready deployment with it if you choose Docker Compose for your deployment. The Docker Image is managed by the same people who build fidesctl, and they are committed to keeping it updated whenever new features and capabilities of fidesctl are released. Where to ask for help For quick and general troubleshooting questions, visit the #troubleshooting channel on the fidesctl Slack. For longer discussions or to share information, visit the GitHub discussions page. If you can provide description of a reproducible problem with the fidesctl software, you can open issue in GitHub issues .","title":"Installation Overview"},{"location":"installation/installation/#installation","text":"This page describes installation options that you might use when considering how to install fidesctl. Fidesctl consists of multiple components, possibly distributed among various physical or virtual machines. Fidesctl can be deployed flexibly, meeting the needs of various environments with different levels of complexity. You should also check-out the prerequisites that must be fulfilled when installing fidesctl. Fidesctl requires additional dependencies to be installed - which can be done via extras . When you install fidesctl, you need to setup the database which must also be kept updated when fidesctl is upgraded.","title":"Installation"},{"location":"installation/installation/#installation-tools","text":"Only pip and conda installations are currently officially supported. For more details see Installation from PyPI or Installation from Conda In some cases a lightweight installation might be desired, for instance, if the webserver is not needed. If this is the case, our pip installation supports optional dependencies. While there are some successes with using other tools like poetry or pip-tools, they do not share the same workflow as the supported tools - especially when it comes to constraint vs. requirements management. Installing via Poetry or pip-tools is not currently supported. If you wish to install fidesctl using those tools you do so at your own discretion. When this option works best This installation method is useful when you are not familiar with containers and Docker and want to install fidesctl on physical or virtual machines and you are used to installing and running software using custom deployment mechanism. The only officially supported mechanisms of installation are pip and conda. Intended users Users who are familiar with installing and configuring Python applications, managing Python environments, dependencies and running software with their custom deployment mechanisms. What are you expected to handle You are expected to install fidesctl - all components of it - on your own. You should develop and handle the deployment for all components of fidesctl. You are responsible for setting up the database, automated startup and recovery, maintenance, cleanup and upgrades of fidesctl. What the Fidesctl community provides for this method You have Installation from PyPI and Installation from Conda on how to install the software but due to various environments and tools you might want to use, you might expect that there will be problems which are specific to your deployment and environment that you will have to diagnose and solve. You have the Running fidesctl Locally guide where you can see an example of running fidesctl with minimal dependencies and setup. You can use this guide to start fidesctl quickly for local testing and development, however this is only intended to provide inspiration, not to represent a production-grade installation. Where to ask for help For quick and general troubleshooting questions, visit the #troubleshooting channel on the fidesctl Slack. For longer discussions or to share information, visit the GitHub discussions page. If you can provide description of a reproducible problem with the fidesctl software, you can open issue in GitHub issues .","title":"Installation Tools"},{"location":"installation/installation/#using-production-docker-images","text":"More details: Installation from Docker When this option works best This installation method is useful if you are familiar with the container/Docker stack. It provides a capability of running fidesctl components in isolation from other software running on the same physical or virtual machines with easy maintenance of dependencies. The images are built by fidesctl CI/CD pipelines and offer versions for official releases as well as for every commit made to the main branch. For this reason, it is highly discouraged to use the latest tag, as any non-official release versions may contain some instability. Intended users Users who are familiar with containers and Docker stack and understand how to build and extend their own container images. Users who know how to create deployments using Docker by linking together multiple Docker containers and maintaining such deployments. What are you expected to handle You are expected to be able to customize or extend container/Docker images if you want to add extra dependencies. You are expected to put together a deployment built of several containers (for example using docker-compose) and to make sure that they are linked together. You are responsible for setting up the database, automated startup and recovery, maintenance, cleanup and upgrades of fidesctl. You should choose the right deployment mechanism. There a number of available options of deployments of containers. You can use your own custom mechanism, custom Kubernetes deployments, custom Docker Compose, custom Helm charts etc., and you should choose it based on your experience and expectations. What the Fidesctl community provides for this method You have Running Fidesctl in Docker where you can see an example of how to start fidesctl quickly for local testing and development. However this is just an inspiration. Do not expect to use this docker-compose.yml file for production installation, you need to get familiar with Docker Compose and its capabilities and build your own production-ready deployment with it if you choose Docker Compose for your deployment. The Docker Image is managed by the same people who build fidesctl, and they are committed to keeping it updated whenever new features and capabilities of fidesctl are released. Where to ask for help For quick and general troubleshooting questions, visit the #troubleshooting channel on the fidesctl Slack. For longer discussions or to share information, visit the GitHub discussions page. If you can provide description of a reproducible problem with the fidesctl software, you can open issue in GitHub issues .","title":"Using Production Docker Images"},{"location":"installation/prerequisites_dependencies/","text":"Prerequisites & Dependencies Fidesctl supports the following Python versions: Python: 3.8 Fidesctl supports the following databases as the application database: PostgreSQL: 12 All of these must be installed, either locally or via Docker, before attempting to run fidesctl as an application. The CLI is capable of running with only the Python dependency.","title":"Prerequisites & Dependencies"},{"location":"installation/prerequisites_dependencies/#prerequisites-dependencies","text":"Fidesctl supports the following Python versions: Python: 3.8 Fidesctl supports the following databases as the application database: PostgreSQL: 12 All of these must be installed, either locally or via Docker, before attempting to run fidesctl as an application. The CLI is capable of running with only the Python dependency.","title":"Prerequisites &amp; Dependencies"},{"location":"installation/pypi/","text":"Installation from PyPI This page describes installations using the fidesctl package published on PyPI . Basic Installation To install Fidesctl, run: pip install fidesctl With the default installation fidesctl is designed to be as lightweight as possible. It ships with the ability to do most things you would do via the standalone CLI, such as evaluate and parse without the need to run a webserver. For interacting directly with databases and running the webserver, see the optional dependencies below. Installing Optional Dependencies Fidesctl ships with a number of optional dependencies that extend its functionality. To install these, use the following syntax: pip install \"fidesctl[extra_1, extra_2]\" The optional dependencies are as follows: webserver : includes FastAPI and the Postgres database connector. Enables fidesctl webserver . postgres : includes the Postgres database connector. mysql : includes the MySQL database connector. mssql : includes the MSSQL database connector. all : includes all of the optional dependencies except for mssql due to platform-specific issues. NOTE: When installing database adapters there may be other dependencies, such as the pg_hba.conf file that usually requires a Postgres installation or the Microsoft ODBC Driver for SQL Server Apple M1 users of MSSQL: Known issues around connecting to MSSQL exist today, please reference the following issue for potential solutions: https://github.com/mkleehammer/pyodbc/issues/846","title":"Installation from PyPI"},{"location":"installation/pypi/#installation-from-pypi","text":"This page describes installations using the fidesctl package published on PyPI .","title":"Installation from PyPI"},{"location":"installation/pypi/#basic-installation","text":"To install Fidesctl, run: pip install fidesctl With the default installation fidesctl is designed to be as lightweight as possible. It ships with the ability to do most things you would do via the standalone CLI, such as evaluate and parse without the need to run a webserver. For interacting directly with databases and running the webserver, see the optional dependencies below.","title":"Basic Installation"},{"location":"installation/pypi/#installing-optional-dependencies","text":"Fidesctl ships with a number of optional dependencies that extend its functionality. To install these, use the following syntax: pip install \"fidesctl[extra_1, extra_2]\" The optional dependencies are as follows: webserver : includes FastAPI and the Postgres database connector. Enables fidesctl webserver . postgres : includes the Postgres database connector. mysql : includes the MySQL database connector. mssql : includes the MSSQL database connector. all : includes all of the optional dependencies except for mssql due to platform-specific issues. NOTE: When installing database adapters there may be other dependencies, such as the pg_hba.conf file that usually requires a Postgres installation or the Microsoft ODBC Driver for SQL Server Apple M1 users of MSSQL: Known issues around connecting to MSSQL exist today, please reference the following issue for potential solutions: https://github.com/mkleehammer/pyodbc/issues/846","title":"Installing Optional Dependencies"},{"location":"language/overview/","text":"Fides Language Documentation This is the documentation for Fides' configuration language. It is relevant to users of Fides Control ( fidesctl ), Fides Ops ( fidesops , and other privacy tools that are in the roadmap. Hands-on : Try the fidesctl: Getting Started . The Fides language is Fides' primary user interface. In every use of Fides, configuration files written in the Fides language is always at the heart of the workflow. About the Fides Language The Fides language is based on YAML configuration files. YAML provides a well-understood structure, upon which the Fides language adds helpful primitives which represent types of data, processes or policies. By declaring these primitives with Fides you can describe: what types of data your application process (using Fides data_category annotations) how your system uses that data (using Fides data_use annotations) what policies you want your system to adhere to (using Fides Policy resources) etc. All other language features exist only to make the definition of privacy primitives more flexible and convenient. When fully utilized, these configuration files written using the Fides language tell other Fides tools what your software is doing with data and how to manage the privacy risks of that data process. Software systems are complicated though, so a full Fides configuration will consist of multiple files describing different resources, including: Dataset YAML A Dataset declaration in Fides language represents any location where data is stored: databases, data warehouses, caches and other data storage systems. Within a Fides Dataset, you declare the individual fields (e.g. database columns) where data is located and annotate them to describe the categories of data that are stored. System YAML A System declaration in Fides language represents the privacy properties of a single software project, service, codebase, or application. So the Fides System declaration describes both the categories of data being processed, but also the purposes for which that data is processed. Policy YAML A Policy declaration in Fides language represents a set of rules for privacy or compliance that the system must adhere to. The fidesctl tool evaluates these policies against the system & dataset declarations to ensure automated compliance.","title":"Overview"},{"location":"language/overview/#fides-language-documentation","text":"This is the documentation for Fides' configuration language. It is relevant to users of Fides Control ( fidesctl ), Fides Ops ( fidesops , and other privacy tools that are in the roadmap. Hands-on : Try the fidesctl: Getting Started . The Fides language is Fides' primary user interface. In every use of Fides, configuration files written in the Fides language is always at the heart of the workflow.","title":"Fides Language Documentation"},{"location":"language/overview/#about-the-fides-language","text":"The Fides language is based on YAML configuration files. YAML provides a well-understood structure, upon which the Fides language adds helpful primitives which represent types of data, processes or policies. By declaring these primitives with Fides you can describe: what types of data your application process (using Fides data_category annotations) how your system uses that data (using Fides data_use annotations) what policies you want your system to adhere to (using Fides Policy resources) etc. All other language features exist only to make the definition of privacy primitives more flexible and convenient. When fully utilized, these configuration files written using the Fides language tell other Fides tools what your software is doing with data and how to manage the privacy risks of that data process. Software systems are complicated though, so a full Fides configuration will consist of multiple files describing different resources, including:","title":"About the Fides Language"},{"location":"language/overview/#dataset-yaml","text":"A Dataset declaration in Fides language represents any location where data is stored: databases, data warehouses, caches and other data storage systems. Within a Fides Dataset, you declare the individual fields (e.g. database columns) where data is located and annotate them to describe the categories of data that are stored.","title":"Dataset YAML"},{"location":"language/overview/#system-yaml","text":"A System declaration in Fides language represents the privacy properties of a single software project, service, codebase, or application. So the Fides System declaration describes both the categories of data being processed, but also the purposes for which that data is processed.","title":"System YAML"},{"location":"language/overview/#policy-yaml","text":"A Policy declaration in Fides language represents a set of rules for privacy or compliance that the system must adhere to. The fidesctl tool evaluates these policies against the system & dataset declarations to ensure automated compliance.","title":"Policy YAML"},{"location":"language/syntax/","text":"Fides Configuration Syntax Other pages in this language section describe various concepts and resources that appear in the Fides language. This page describes the syntax of the language in more detail to help better interpret Fides whether you're authoring or reading. The Fides language is an intentionally simple language designed to be relatively easy for anyone to read and write. The primary objective is to translate complex privacy compliance concepts into a simple syntax, it's for this reason Fides is entirely written as YAML configurations. YAML - Building Block of Fides Fides Taxonomy The Fides language is intentionally simple. To assure this, Fides declarations use predefined primitives (e.g. data categories) that are used when describing your datasets, systems, policies, etc. These predefined primitives exist as part of the Fides taxonomy which is maintained in your fidesctl server so they can be consistently used across your organization's development team. You can learn more about the taxonomy structure and how to extend it in the taxonomy guide . Dot Notation and Snake_Case To make writing and reading Fides language as easy for humans as possible, declarations from the privacy taxonomy use dot notation for the keys and use snake_case compound labels. For example, to describe a field in a database as information provided by a user that is personally identifiable, you can write it's data category as: 1 2 # This declares that the data is provided by the user and identifies them directly user.provided.identifiable If we require greater specificity that just \"identifiable\", we could declare the contact type as a phone number by using a more specific sub-category: 1 2 3 # This declares that the is data provided by the user, # identifies them directly and is from the contact category and of type phone number. user.provided.identifiable.contact.phone_number The diagram below shows you the structure of that statement: notation-conventions Key-Value The key-value is YAML, and Fides', basic building block. Every item in a Fides YAML document is a member of at least one dictionary. The key is always a string . The value is a scalar so that it can be any datatype. So the value can be a string , a number , or another dictionary - most commonly in Fides, this will be a string that may provide a description or a pointer to a reference object in the taxonomy. If we use the example of a user's contact email, to correctly declare this in valid Fides YAML as part of a Dataset, it would be: 1 2 3 4 5 6 fields : # Group of fields in the dataset. - name : email description : User's Email data_categories : # Data category label(s) to assign field. - user.provided.identifiable.contact.email - account.contact.email The key for each key-value pair determines what value types are valid (for example, a resource type such as data_categories must use values from the Data Categories taxonomy), but many keys accept arbitrary strings as descriptive labels. Finally, as you see in the example above, keys such as data_categories accept a list of values for multi-labeling. In this case, the field email has been assigned the value user provided identifiable contact email as well as account related contact email , indicating that it may be either of those categories when used. Character Encoding Fides configuration files must always be UTF-8 encoded. While the delimiters of the language are all ASCII characters, Fides accepts non-ASCII characters in key-values, comments, and string values.","title":"Syntax"},{"location":"language/syntax/#fides-configuration-syntax","text":"Other pages in this language section describe various concepts and resources that appear in the Fides language. This page describes the syntax of the language in more detail to help better interpret Fides whether you're authoring or reading. The Fides language is an intentionally simple language designed to be relatively easy for anyone to read and write. The primary objective is to translate complex privacy compliance concepts into a simple syntax, it's for this reason Fides is entirely written as YAML configurations.","title":"Fides Configuration Syntax"},{"location":"language/syntax/#yaml-building-block-of-fides","text":"","title":"YAML - Building Block of Fides"},{"location":"language/syntax/#fides-taxonomy","text":"The Fides language is intentionally simple. To assure this, Fides declarations use predefined primitives (e.g. data categories) that are used when describing your datasets, systems, policies, etc. These predefined primitives exist as part of the Fides taxonomy which is maintained in your fidesctl server so they can be consistently used across your organization's development team. You can learn more about the taxonomy structure and how to extend it in the taxonomy guide .","title":"Fides Taxonomy"},{"location":"language/syntax/#dot-notation-and-snake_case","text":"To make writing and reading Fides language as easy for humans as possible, declarations from the privacy taxonomy use dot notation for the keys and use snake_case compound labels. For example, to describe a field in a database as information provided by a user that is personally identifiable, you can write it's data category as: 1 2 # This declares that the data is provided by the user and identifies them directly user.provided.identifiable If we require greater specificity that just \"identifiable\", we could declare the contact type as a phone number by using a more specific sub-category: 1 2 3 # This declares that the is data provided by the user, # identifies them directly and is from the contact category and of type phone number. user.provided.identifiable.contact.phone_number The diagram below shows you the structure of that statement: notation-conventions","title":"Dot Notation and Snake_Case"},{"location":"language/syntax/#key-value","text":"The key-value is YAML, and Fides', basic building block. Every item in a Fides YAML document is a member of at least one dictionary. The key is always a string . The value is a scalar so that it can be any datatype. So the value can be a string , a number , or another dictionary - most commonly in Fides, this will be a string that may provide a description or a pointer to a reference object in the taxonomy. If we use the example of a user's contact email, to correctly declare this in valid Fides YAML as part of a Dataset, it would be: 1 2 3 4 5 6 fields : # Group of fields in the dataset. - name : email description : User's Email data_categories : # Data category label(s) to assign field. - user.provided.identifiable.contact.email - account.contact.email The key for each key-value pair determines what value types are valid (for example, a resource type such as data_categories must use values from the Data Categories taxonomy), but many keys accept arbitrary strings as descriptive labels. Finally, as you see in the example above, keys such as data_categories accept a list of values for multi-labeling. In this case, the field email has been assigned the value user provided identifiable contact email as well as account related contact email , indicating that it may be either of those categories when used.","title":"Key-Value"},{"location":"language/syntax/#character-encoding","text":"Fides configuration files must always be UTF-8 encoded. While the delimiters of the language are all ASCII characters, Fides accepts non-ASCII characters in key-values, comments, and string values.","title":"Character Encoding"},{"location":"language/resources/dataset/","text":"Dataset A Dataset takes a database schema (tables and columns) and adds Fides privacy categorizations. This is a database-agnostic way to annotate privacy declarations. 1 2 3 4 5 6 organization |-> registry (optional) |-> system |-> ** dataset ** |-> collections |-> fields The schema is represented as a set of \"collections\" (tables) that contain \"fields\" (columns). At each level -- Dataset, collection, and field, you can assign one or more Data Categories and Data Qualifiers. The Categories and Qualifiers declared at each child level is additive, for example, if you declare a collection with category user.derived , and a field with category user.provided.identifiable.name , your dataset will contain both user-derived and user-provided name data. While you can create Dataset objects by hand, you typically use the fidesctl generate-dataset command to create rudimentary Dataset manifest files that are based on your real-world databases. After you run the command, which creates the schema components, you add your Data Categories and Data Qualifiers to the manifest. You use your Datasets by adding them to Systems. A System can contain any number of Datasets, and a Dataset can be added to any number of Systems. Datasets cannot contain other Datasets. Object Structure fides_key string A string token of your own invention that uniquely identifies this Dataset. It's your responsibility to ensure that the value is unique across all of your Dataset objects. The value may only contain alphanumeric characters and underbars ( [A-Za-z0-9_] ). name string A UI-friendly label for the Dataset. description string A human-readable description of the Dataset. organization_fides_key string default: default_organization The fides key of the Organization to which this Dataset belongs. meta object An optional object that provides additional information about the Dataset. You can structure the object however you like. It can be a simple set of key: value properties or a deeply nested hierarchy of objects. How you use the object is up to you: Fides ignores it. data_categories [ string ] data_qualifiers [ string ] Arrays of Data Category and Data Qualifier resources, identified by fides_key , that apply to all collections in the Dataset. collections [ object ] An array of objects that describe the Dataset's collections. collections.name string A UI-friendly label for the collection. collections.description string A human-readable description of the collection. collections.data_categories [ string ] collections.data_qualifiers [ string ] Arrays of Data Category and Data Qualifier resources, identified by fides_key , that apply to all fields in the collection. collections.fields [ object ] An array of objects that describe the collection's fields. collections.fields.name string A UI-friendly label for the field. collections.fields.description string A human-readable description of the field. collections.fields.data_categories [ string ] Arrays of Data Categories, identified by fides_key , that applies to this field. collections.fields.data_qualifier string A Data Qualifier that applies to this field. Note that this field holds a single value, therefore, the property name is singular. Examples Manifest File 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 dataset : - fides_key : demo_users_dataset name : Demo Users Dataset description : Data collected about users for our analytics system. collections : - name : users description : User information data_categories : - user.derived fields : - name : first_name description : User's first name data_categories : - user.provided.identifiable.name - name : email description : User's Email data_categories : - user.provided.identifiable.contact.email API Payload 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 { \"fides_key\" : \"demo_users_dataset\" , \"name\" : \"Demo Users Dataset\" , \"description\" : \"Data collected about users for our analytics system.\" , \"collections\" : [ { \"name\" : \"users\" , \"description\" : \"User information\" , \"fields\" : [ { \"name\" : \"first_name\" , \"description\" : \"User's first name\" , \"data_categories\" : [ \"user.provided.identifiable.name\" ] }, { \"name\" : \"email\" , \"description\" : \"User's Email\" , \"data_categories\" : [ \"user.provided.identifiable.contact.email\" ] } ] } ] }","title":"Dataset"},{"location":"language/resources/dataset/#dataset","text":"A Dataset takes a database schema (tables and columns) and adds Fides privacy categorizations. This is a database-agnostic way to annotate privacy declarations. 1 2 3 4 5 6 organization |-> registry (optional) |-> system |-> ** dataset ** |-> collections |-> fields The schema is represented as a set of \"collections\" (tables) that contain \"fields\" (columns). At each level -- Dataset, collection, and field, you can assign one or more Data Categories and Data Qualifiers. The Categories and Qualifiers declared at each child level is additive, for example, if you declare a collection with category user.derived , and a field with category user.provided.identifiable.name , your dataset will contain both user-derived and user-provided name data. While you can create Dataset objects by hand, you typically use the fidesctl generate-dataset command to create rudimentary Dataset manifest files that are based on your real-world databases. After you run the command, which creates the schema components, you add your Data Categories and Data Qualifiers to the manifest. You use your Datasets by adding them to Systems. A System can contain any number of Datasets, and a Dataset can be added to any number of Systems. Datasets cannot contain other Datasets.","title":"Dataset"},{"location":"language/resources/dataset/#object-structure","text":"fides_key string A string token of your own invention that uniquely identifies this Dataset. It's your responsibility to ensure that the value is unique across all of your Dataset objects. The value may only contain alphanumeric characters and underbars ( [A-Za-z0-9_] ). name string A UI-friendly label for the Dataset. description string A human-readable description of the Dataset. organization_fides_key string default: default_organization The fides key of the Organization to which this Dataset belongs. meta object An optional object that provides additional information about the Dataset. You can structure the object however you like. It can be a simple set of key: value properties or a deeply nested hierarchy of objects. How you use the object is up to you: Fides ignores it. data_categories [ string ] data_qualifiers [ string ] Arrays of Data Category and Data Qualifier resources, identified by fides_key , that apply to all collections in the Dataset. collections [ object ] An array of objects that describe the Dataset's collections. collections.name string A UI-friendly label for the collection. collections.description string A human-readable description of the collection. collections.data_categories [ string ] collections.data_qualifiers [ string ] Arrays of Data Category and Data Qualifier resources, identified by fides_key , that apply to all fields in the collection. collections.fields [ object ] An array of objects that describe the collection's fields. collections.fields.name string A UI-friendly label for the field. collections.fields.description string A human-readable description of the field. collections.fields.data_categories [ string ] Arrays of Data Categories, identified by fides_key , that applies to this field. collections.fields.data_qualifier string A Data Qualifier that applies to this field. Note that this field holds a single value, therefore, the property name is singular.","title":"Object Structure"},{"location":"language/resources/dataset/#examples","text":"","title":"Examples"},{"location":"language/resources/dataset/#manifest-file","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 dataset : - fides_key : demo_users_dataset name : Demo Users Dataset description : Data collected about users for our analytics system. collections : - name : users description : User information data_categories : - user.derived fields : - name : first_name description : User's first name data_categories : - user.provided.identifiable.name - name : email description : User's Email data_categories : - user.provided.identifiable.contact.email","title":"Manifest File"},{"location":"language/resources/dataset/#api-payload","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 { \"fides_key\" : \"demo_users_dataset\" , \"name\" : \"Demo Users Dataset\" , \"description\" : \"Data collected about users for our analytics system.\" , \"collections\" : [ { \"name\" : \"users\" , \"description\" : \"User information\" , \"fields\" : [ { \"name\" : \"first_name\" , \"description\" : \"User's first name\" , \"data_categories\" : [ \"user.provided.identifiable.name\" ] }, { \"name\" : \"email\" , \"description\" : \"User's Email\" , \"data_categories\" : [ \"user.provided.identifiable.contact.email\" ] } ] } ] }","title":"API Payload"},{"location":"language/resources/organization/","text":"Organization An Organization represents all or part of an enterprise or company, and establishes the root of your resource hierarchy. This means that while you can have more than Organization resource, they can't refer to each other's sub-resources. For example, your \"American Stores\" Organization can't refer to the Policy objects that are defined by your \"European Stores\" Organization. Unless you're creating multiple Organizations (which should be rare), you can ignore the Organization resource. While all of your other resources must refer to an Organization (through their organization_fides_key properties), Fides creates a default Organization that it uses for all resources that don't otherwise specify an Organization. The fides key for the default Organization is default_organization Object Structure fides_key string A string token of your own invention that uniquely identifies this Organization. It's your responsibility to ensure that the value is unique across all of your Organization objects. The value should only contain alphanumeric characters and underbars ( [A-Za-z0-9_] ). name string A UI-friendly label for the Organization. description string A human-readable description of the Organization. Examples Manifest File 1 2 3 4 organization : fides_key : default_organization name : Acme Incorporated description : An Organization that represents all of Acme Inc. API Payload 1 2 3 4 5 { \"fides_key\" : \"default_organization\" , \"name\" : \"Acme Incorporated\" , \"description\" : \"An Organization that represents all of Acme Inc.\" }","title":"Organization"},{"location":"language/resources/organization/#organization","text":"An Organization represents all or part of an enterprise or company, and establishes the root of your resource hierarchy. This means that while you can have more than Organization resource, they can't refer to each other's sub-resources. For example, your \"American Stores\" Organization can't refer to the Policy objects that are defined by your \"European Stores\" Organization. Unless you're creating multiple Organizations (which should be rare), you can ignore the Organization resource. While all of your other resources must refer to an Organization (through their organization_fides_key properties), Fides creates a default Organization that it uses for all resources that don't otherwise specify an Organization. The fides key for the default Organization is default_organization","title":"Organization"},{"location":"language/resources/organization/#object-structure","text":"fides_key string A string token of your own invention that uniquely identifies this Organization. It's your responsibility to ensure that the value is unique across all of your Organization objects. The value should only contain alphanumeric characters and underbars ( [A-Za-z0-9_] ). name string A UI-friendly label for the Organization. description string A human-readable description of the Organization.","title":"Object Structure"},{"location":"language/resources/organization/#examples","text":"","title":"Examples"},{"location":"language/resources/organization/#manifest-file","text":"1 2 3 4 organization : fides_key : default_organization name : Acme Incorporated description : An Organization that represents all of Acme Inc.","title":"Manifest File"},{"location":"language/resources/organization/#api-payload","text":"1 2 3 4 5 { \"fides_key\" : \"default_organization\" , \"name\" : \"Acme Incorporated\" , \"description\" : \"An Organization that represents all of Acme Inc.\" }","title":"API Payload"},{"location":"language/resources/policy/","text":"Policy A Policy is your privacy policy as code, it lists a set of acceptable and non-acceptable rules and uses all 4 privacy attributes ( data_category , data_use , data_subject , and data_qualifier ). The purpose of the policy is to state what types of data are allowed for certain usages. 1 2 3 organization |-> ** policy ** |-> rules Object Structure fides_key string A string token of your own invention that uniquely identifies this Policy. It's your responsibility to ensure that the value is unique across all of your Policy objects. The value may only contain alphanumeric characters and underbars ( [A-Za-z0-9_] ). name string A UI-friendly label for the Policy. description string A human-readable description of the Policy. data_categories string The Data Categories privacy attribute describes types of sensitive data as defined in the taxonomy. data_uses string The Data Use privacy attribute describes the various categories of data processing and operations at your organization. data_subject string The Data Subjects privacy attribute describes the individual persons whose data your rule pertains to. data_qualifier string The Data Qualifier privacy attribute describes the acceptable or non-acceptable level of deidentification for this data. matches enum ANY ALL NONE OTHER The matches criteria describes how you would like this rule to be evaluated. These basic logic gates determine whether the array of privacy attributes will be fully included ( ALL ), not included at all ( NONE ), only included if at least 1 item in the array matches ( ANY ), or excluded with any additional attributes included ( OTHER ). organization_fides_key string default: default_organization The fides key of the Organization to which this Policy belongs. Examples Manifest File 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 policy : - fides_key : demo_privacy_policy name : Demo Privacy Policy description : The main privacy policy for the organization. rules : - fides_key : reject_direct_marketing name : Reject Direct Marketing description : Disallow collecting any user contact info to use for marketing. data_categories : matches : ANY values : - user.provided.identifiable.contact data_uses : matches : ANY values : - advertising data_subjects : matches : ANY values : - customer data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified Demo manifest file: /fides/fidesctl/demo_resources/demo_policy.yml API Payload 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 POST /policy { \"fides_key\" : \"demo_privacy_policy\" , \"organization_fides_key\" : \"default_organization\" , \"name\" : \"string\" , \"description\" : \"The main privacy policy for the organization.\" , \"rules\" : [ { \"fides_key\" : \"reject_direct_marketing\" , \"organization_fides_key\" : \"default_organization\" , \"name\" : \"Reject Direct Marketing\" , \"description\" : \"Disallow collecting any user contact info to use for marketing.\" , \"data_categories\" : { \"matches\" : \"ANY\" , \"values\" : [ \"user.provided.identifiable.contact\" ] }, \"data_uses\" : { \"matches\" : \"ANY\" , \"values\" : [ \"advertising\" ] }, \"data_subjects\" : { \"matches\" : \"ANY\" , \"values\" : [ \"customer\" ] }, \"data_qualifier\" : \"aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified\" } ] }","title":"Policy"},{"location":"language/resources/policy/#policy","text":"A Policy is your privacy policy as code, it lists a set of acceptable and non-acceptable rules and uses all 4 privacy attributes ( data_category , data_use , data_subject , and data_qualifier ). The purpose of the policy is to state what types of data are allowed for certain usages. 1 2 3 organization |-> ** policy ** |-> rules","title":"Policy"},{"location":"language/resources/policy/#object-structure","text":"fides_key string A string token of your own invention that uniquely identifies this Policy. It's your responsibility to ensure that the value is unique across all of your Policy objects. The value may only contain alphanumeric characters and underbars ( [A-Za-z0-9_] ). name string A UI-friendly label for the Policy. description string A human-readable description of the Policy. data_categories string The Data Categories privacy attribute describes types of sensitive data as defined in the taxonomy. data_uses string The Data Use privacy attribute describes the various categories of data processing and operations at your organization. data_subject string The Data Subjects privacy attribute describes the individual persons whose data your rule pertains to. data_qualifier string The Data Qualifier privacy attribute describes the acceptable or non-acceptable level of deidentification for this data. matches enum ANY ALL NONE OTHER The matches criteria describes how you would like this rule to be evaluated. These basic logic gates determine whether the array of privacy attributes will be fully included ( ALL ), not included at all ( NONE ), only included if at least 1 item in the array matches ( ANY ), or excluded with any additional attributes included ( OTHER ). organization_fides_key string default: default_organization The fides key of the Organization to which this Policy belongs.","title":"Object Structure"},{"location":"language/resources/policy/#examples","text":"","title":"Examples"},{"location":"language/resources/policy/#manifest-file","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 policy : - fides_key : demo_privacy_policy name : Demo Privacy Policy description : The main privacy policy for the organization. rules : - fides_key : reject_direct_marketing name : Reject Direct Marketing description : Disallow collecting any user contact info to use for marketing. data_categories : matches : ANY values : - user.provided.identifiable.contact data_uses : matches : ANY values : - advertising data_subjects : matches : ANY values : - customer data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified Demo manifest file: /fides/fidesctl/demo_resources/demo_policy.yml","title":"Manifest File"},{"location":"language/resources/policy/#api-payload","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 POST /policy { \"fides_key\" : \"demo_privacy_policy\" , \"organization_fides_key\" : \"default_organization\" , \"name\" : \"string\" , \"description\" : \"The main privacy policy for the organization.\" , \"rules\" : [ { \"fides_key\" : \"reject_direct_marketing\" , \"organization_fides_key\" : \"default_organization\" , \"name\" : \"Reject Direct Marketing\" , \"description\" : \"Disallow collecting any user contact info to use for marketing.\" , \"data_categories\" : { \"matches\" : \"ANY\" , \"values\" : [ \"user.provided.identifiable.contact\" ] }, \"data_uses\" : { \"matches\" : \"ANY\" , \"values\" : [ \"advertising\" ] }, \"data_subjects\" : { \"matches\" : \"ANY\" , \"values\" : [ \"customer\" ] }, \"data_qualifier\" : \"aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified\" } ] }","title":"API Payload"},{"location":"language/resources/registry/","text":"Registry A Registry is a collection of System resources. You add a system to a Registry by setting the System's registry_id field. 1 2 3 organization |-> ** registry ** (optional) |-> system A System may belong to only one Registry. All Registries are siblings: You cannot create a hierarchy of Registries. Collecting your systems into Registries is optional. Object Structure fides_key string A string token of your own invention that uniquely identifies this Registry. It's your responsibility to ensure that the value is unique across all of your Registry objects. The value may only contain alphanumeric characters and underbars ( [A-Za-z0-9_] ). name string A UI-friendly label for the Registry. description string A human-readable description of the Registry. organization_fides_key string default: default_organization The fides key of the Organization to which this Registry belongs. Examples Manifest File 1 2 3 4 registry : - fides_key : user_systems_registry name : User Systems Registry description : A Registry for all of the user-related systems. API Payload 1 2 3 4 5 { \"fides_key\" : \"user_systems_registry\" , \"name\" : \"User Systems Registry\" , \"description\" : \"A Registry for all of the user-related systems.\" }","title":"Registry"},{"location":"language/resources/registry/#registry","text":"A Registry is a collection of System resources. You add a system to a Registry by setting the System's registry_id field. 1 2 3 organization |-> ** registry ** (optional) |-> system A System may belong to only one Registry. All Registries are siblings: You cannot create a hierarchy of Registries. Collecting your systems into Registries is optional.","title":"Registry"},{"location":"language/resources/registry/#object-structure","text":"fides_key string A string token of your own invention that uniquely identifies this Registry. It's your responsibility to ensure that the value is unique across all of your Registry objects. The value may only contain alphanumeric characters and underbars ( [A-Za-z0-9_] ). name string A UI-friendly label for the Registry. description string A human-readable description of the Registry. organization_fides_key string default: default_organization The fides key of the Organization to which this Registry belongs.","title":"Object Structure"},{"location":"language/resources/registry/#examples","text":"","title":"Examples"},{"location":"language/resources/registry/#manifest-file","text":"1 2 3 4 registry : - fides_key : user_systems_registry name : User Systems Registry description : A Registry for all of the user-related systems.","title":"Manifest File"},{"location":"language/resources/registry/#api-payload","text":"1 2 3 4 5 { \"fides_key\" : \"user_systems_registry\" , \"name\" : \"User Systems Registry\" , \"description\" : \"A Registry for all of the user-related systems.\" }","title":"API Payload"},{"location":"language/resources/system/","text":"System A System is a model for describing anything that processes data for your organization (applications, services, 3rd party APIs, etc.) and describes how these datasets are used for business functions of instances of your data resources. It contains all 4 privacy attributes ( data_category , data_use , data_subject , and data_qualifier ). 1 2 3 4 organization |-> registry (optional) |-> ** system ** |-> privacy declarations Object Structure fides_key string A string token of your own invention that uniquely identifies this System. It's your responsibility to ensure that the value is unique across all of your System objects. The value may only contain alphanumeric characters and underbars ( [A-Za-z0-9_] ). name string A UI-friendly label for the System. description string A human-readable description of the System. privacy_declarations [array] The array of declarations describing the types of data in your system. This is a list of the privcy attributes ( data_category , data_use , data_subject , and data_qualifier ) for each of your systems. organization_fides_key string default: default_organization The fides key of the Organization to which this System belongs. Examples Manifest File 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 system : - fides_key : demo_analytics_system name : Demo Analytics System description : A system used for analyzing customer behaviour. system_type : Service privacy_declarations : - name : Analyze customer behaviour for improvements. data_categories : - user.provided.identifiable.contact - user.derived.identifiable.device.cookie_id data_use : improve.system data_subjects : - customer data_qualifier : identified_data dataset_references : - demo_users_dataset Demo manifest file: /fides/fidesctl/demo_resources/demo_system.yml API 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 POST /sys te m { \"fides_key\" : \"demo_analytics_system\" , \"name\" : \"Demo Analytics System\" , \"description\" : \"A system used for analyzing customer behaviour.\" , \"system_type\" : \"Service\" , \"privacy_declarations\" : [ { \"name\" : \"Analyze customer behaviour for improvements.\" , \"data_categories\" : [ \"user.provided.identifiable.contact\" , \"user.derived.identifiable.device.cookie_id\" ], \"data_use\" : \"improve.system\" , \"data_subjects\" : [ \"customer\" ], \"data_qualifier\" : \"identified_data\" , \"dataset_references\" : [ \"demo_users_dataset\" ] } ] }","title":"System"},{"location":"language/resources/system/#system","text":"A System is a model for describing anything that processes data for your organization (applications, services, 3rd party APIs, etc.) and describes how these datasets are used for business functions of instances of your data resources. It contains all 4 privacy attributes ( data_category , data_use , data_subject , and data_qualifier ). 1 2 3 4 organization |-> registry (optional) |-> ** system ** |-> privacy declarations","title":"System"},{"location":"language/resources/system/#object-structure","text":"fides_key string A string token of your own invention that uniquely identifies this System. It's your responsibility to ensure that the value is unique across all of your System objects. The value may only contain alphanumeric characters and underbars ( [A-Za-z0-9_] ). name string A UI-friendly label for the System. description string A human-readable description of the System. privacy_declarations [array] The array of declarations describing the types of data in your system. This is a list of the privcy attributes ( data_category , data_use , data_subject , and data_qualifier ) for each of your systems. organization_fides_key string default: default_organization The fides key of the Organization to which this System belongs.","title":"Object Structure"},{"location":"language/resources/system/#examples","text":"","title":"Examples"},{"location":"language/resources/system/#manifest-file","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 system : - fides_key : demo_analytics_system name : Demo Analytics System description : A system used for analyzing customer behaviour. system_type : Service privacy_declarations : - name : Analyze customer behaviour for improvements. data_categories : - user.provided.identifiable.contact - user.derived.identifiable.device.cookie_id data_use : improve.system data_subjects : - customer data_qualifier : identified_data dataset_references : - demo_users_dataset Demo manifest file: /fides/fidesctl/demo_resources/demo_system.yml","title":"Manifest File"},{"location":"language/resources/system/#api","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 POST /sys te m { \"fides_key\" : \"demo_analytics_system\" , \"name\" : \"Demo Analytics System\" , \"description\" : \"A system used for analyzing customer behaviour.\" , \"system_type\" : \"Service\" , \"privacy_declarations\" : [ { \"name\" : \"Analyze customer behaviour for improvements.\" , \"data_categories\" : [ \"user.provided.identifiable.contact\" , \"user.derived.identifiable.device.cookie_id\" ], \"data_use\" : \"improve.system\" , \"data_subjects\" : [ \"customer\" ], \"data_qualifier\" : \"identified_data\" , \"dataset_references\" : [ \"demo_users_dataset\" ] } ] }","title":"API"},{"location":"language/taxonomy/data_categories/","text":"Data Categories Reference Data Categories are hierarchical labels used to describe the type of data processed by your software. Data Category objects form a hierarchy: A Data Category can contain any number of children, but a given Category may only have one parent. You assign a child Category to a parent by setting the child's parent_key property. For example, the user.provided.identifiable.job_title Category is used for personally-identifiable job title information that was provided by the user. These are most heavily used by the System and Dataset resources, where you can assign one or more data categories to each field. Object Structure fides_key string A string token that uniquely identifies this Data Category. The value is a dot-separated concatenation of the fides_key values of the resource's ancestors plus a final element for this resource: grandparent.parent.this_data_category The final element ( this_data_category ) may only contain alphanumeric characters and underbars ( [A-Za-z0-9_] ). The dot character is reserved as a separator. name string A UI-friendly label for the Data Category. description string A human-readable description of the Data Category. parent_key string The fides key of the the Data Category's parent. organization_fides_key string default: default_organization The fides key of the organization to which this Data Category belongs. Extensibility and Interopability Data Categories in Fides are designed to support common privacy regulations and standards out of the box, these include GDPR, CCPA, LGPD and ISO 19944. You can extend the taxonomy to support your system needs. If you do this, we recommend extending from the existing categories to ensure interopability inside and outside your organization. If you have suggestions for core categories that should ship with the taxonomy, please submit your requests here Top Level Data Categories There are three top-level categories: Label Parent Key Description account - Data related to an account on the system. system - Data unique to, and under control of the system. user - Data related to the user of the system. For each top level category there are multiple subcategories that provide richer context. Below is a reference for all subcategories of account , system and user to assist with describing all data across systems. Account Data Categories Account Contact Data Label Parent Key Description contact account Contact data related to a system account. city account.contact Account's city level address data. country account.contact Account's country level address data. email account.contact Account's email address. phone_number account.contact Account's phone number. postal_code account.contact Account's postal code. state account.contact Account's state level address data. street account.contact Account's street level address. Account Payment Data Label Parent Key Description payment account Payment data related to system account. financial_account_number account.payment Payment data related to system account. System Data Categories Label Parent Key Description authentication system Data used to manage access to the system. operations system Data used for system operations. User Data Categories The \"User\" data category has two important subcategories for derived and provided data. In turn, derived and provided both have subcategories for identifiable and nonidentifiable data, to make it clear what data is considered identifiable in your systems. User Derived Data Data derived from user provided data or as a result of user actions in the system. Label Parent Key Description identifiable user.derived Derived data that is linked to, or identifies a user. biometric_health user.derived.identifiable Encoded characteristic collected about a user. browsing_history user.derived.identifiable Content browsing history of a user. contact user.derived.identifiable Contact data collected about a user. demographic user.derived.identifiable Demographic data about a user. gender user.derived.identifiable Gender of an individual. location user.derived.identifiable Records of the location of a user. media_consumption user.derived.identifiable Media type consumption data of a user. non_specific_age user.derived.identifiable Age range data. observed user.derived.identifiable Data collected through observation of use of the system. organization user.derived.identifiable Derived data that is linked to, or identifies an organization. profiling user.derived.identifiable Preference and interest data about a user. race user.derived.identifiable Racial or ethnic origin data. religious_belief user.derived.identifiable Religion or religious belief. search_history user.derived.identifiable Records of search history and queries of a user. sexual_orientation user.derived.identifiable Personal sex life or sexual data. social user.derived.identifiable Social activity and interaction data. telemetry user.derived.identifiable User identifiable measurement data from system sensors and monitoring. unique_id user.derived.identifiable Unique identifier for a user assigned through system use. user_sensor user.derived.identifiable Measurement data derived about a user's environment through system use. workplace user.derived.identifiable Organization of employment. device user.derived.identifiable Data related to a user's device, configuration and setting. cookie_id user.derived.identifiable.device Cookie unique identification number. device_id user.derived.identifiable.device Device unique identification number. ip_address user.derived.identifiable.device Unique identifier related to device connection. nonidentifiable user.derived Non-user identifiable data derived related to a user as a result of user actions in the system. nonsensor user.derived.nonidentifiable Non-user identifiable measurement data derived from sensors and monitoring systems. User Provided Data Data provided or created directly by a user of the system. Label Parent Key Description identifiable user.provided Data provided or created directly by a user that is linked to or identifies a user. biometric user.provided.identifiable Encoded characteristics provided by a user. childrens user.provided.identifiable Data relating to children. health_and_medical user.provided.identifiable Health records or individual's personal medical information. job_title user.provided.identifiable Professional data. name user.provided.identifiable User's real name. non_specific_age user.provided.identifiable Age range data. political_opinion user.provided.identifiable Data related to the individual's political opinions. race user.provided.identifiable Racial or ethnic origin data. religious_belief user.provided.identifiable Religion or religious belief. sexual_orientation user.provided.identifiable Personal sex life or sexual data. workplace user.provided.identifiable Organization of employment. date_of_birth user.provided.identifiable User's date of birth. gender user.provided.identifiable Gender of an individual. genetic user.provided.identifiable Data about the genetic makeup provided by a user. contact user.provided.identifiable User provided contact data for purposes other than account management. city user.provided.identifiable.contact User's city level address data. country user.provided.identifiable.contact User's country level address data. email user.provided.identifiable.contact User's provided email address. phone_number user.provided.identifiable.contact User's phone number. postal_code user.provided.identifiable.contact User's postal code. state user.provided.identifiable.contact User's state level address data. street user.provided.identifiable.contact User's street level address data. credentials user.provided.identifiable User provided authentication data. biometric_credentials user.provided.identifiable.credentials Credentials for system authentication. password user.provided.identifiable.credentials Password for system authentication. financial user.provided.identifiable Payment data and financial history. account_number user.provided.identifiable.financial User's account number for a payment card, bank account, or other financial system. government_id user.provided.identifiable State provided identification data. drivers_license_number user.provided.identifiable.government_id State issued driving identification number. national_identification_number user.provided.identifiable.government_id State issued personal identification number. passport_number user.provided.identifiable.government_id State issued passport data. nonidentifiable user.provided Data provided or created directly by a user that is not identifiable.","title":"Data Categories"},{"location":"language/taxonomy/data_categories/#data-categories-reference","text":"Data Categories are hierarchical labels used to describe the type of data processed by your software. Data Category objects form a hierarchy: A Data Category can contain any number of children, but a given Category may only have one parent. You assign a child Category to a parent by setting the child's parent_key property. For example, the user.provided.identifiable.job_title Category is used for personally-identifiable job title information that was provided by the user. These are most heavily used by the System and Dataset resources, where you can assign one or more data categories to each field.","title":"Data Categories Reference"},{"location":"language/taxonomy/data_categories/#object-structure","text":"fides_key string A string token that uniquely identifies this Data Category. The value is a dot-separated concatenation of the fides_key values of the resource's ancestors plus a final element for this resource: grandparent.parent.this_data_category The final element ( this_data_category ) may only contain alphanumeric characters and underbars ( [A-Za-z0-9_] ). The dot character is reserved as a separator. name string A UI-friendly label for the Data Category. description string A human-readable description of the Data Category. parent_key string The fides key of the the Data Category's parent. organization_fides_key string default: default_organization The fides key of the organization to which this Data Category belongs. Extensibility and Interopability Data Categories in Fides are designed to support common privacy regulations and standards out of the box, these include GDPR, CCPA, LGPD and ISO 19944. You can extend the taxonomy to support your system needs. If you do this, we recommend extending from the existing categories to ensure interopability inside and outside your organization. If you have suggestions for core categories that should ship with the taxonomy, please submit your requests here","title":"Object Structure"},{"location":"language/taxonomy/data_categories/#top-level-data-categories","text":"There are three top-level categories: Label Parent Key Description account - Data related to an account on the system. system - Data unique to, and under control of the system. user - Data related to the user of the system. For each top level category there are multiple subcategories that provide richer context. Below is a reference for all subcategories of account , system and user to assist with describing all data across systems.","title":"Top Level Data Categories"},{"location":"language/taxonomy/data_categories/#account-data-categories","text":"","title":"Account Data Categories"},{"location":"language/taxonomy/data_categories/#account-contact-data","text":"Label Parent Key Description contact account Contact data related to a system account. city account.contact Account's city level address data. country account.contact Account's country level address data. email account.contact Account's email address. phone_number account.contact Account's phone number. postal_code account.contact Account's postal code. state account.contact Account's state level address data. street account.contact Account's street level address.","title":"Account Contact Data"},{"location":"language/taxonomy/data_categories/#account-payment-data","text":"Label Parent Key Description payment account Payment data related to system account. financial_account_number account.payment Payment data related to system account.","title":"Account Payment Data"},{"location":"language/taxonomy/data_categories/#system-data-categories","text":"Label Parent Key Description authentication system Data used to manage access to the system. operations system Data used for system operations.","title":"System Data Categories"},{"location":"language/taxonomy/data_categories/#user-data-categories","text":"The \"User\" data category has two important subcategories for derived and provided data. In turn, derived and provided both have subcategories for identifiable and nonidentifiable data, to make it clear what data is considered identifiable in your systems.","title":"User Data Categories"},{"location":"language/taxonomy/data_categories/#user-derived-data","text":"Data derived from user provided data or as a result of user actions in the system. Label Parent Key Description identifiable user.derived Derived data that is linked to, or identifies a user. biometric_health user.derived.identifiable Encoded characteristic collected about a user. browsing_history user.derived.identifiable Content browsing history of a user. contact user.derived.identifiable Contact data collected about a user. demographic user.derived.identifiable Demographic data about a user. gender user.derived.identifiable Gender of an individual. location user.derived.identifiable Records of the location of a user. media_consumption user.derived.identifiable Media type consumption data of a user. non_specific_age user.derived.identifiable Age range data. observed user.derived.identifiable Data collected through observation of use of the system. organization user.derived.identifiable Derived data that is linked to, or identifies an organization. profiling user.derived.identifiable Preference and interest data about a user. race user.derived.identifiable Racial or ethnic origin data. religious_belief user.derived.identifiable Religion or religious belief. search_history user.derived.identifiable Records of search history and queries of a user. sexual_orientation user.derived.identifiable Personal sex life or sexual data. social user.derived.identifiable Social activity and interaction data. telemetry user.derived.identifiable User identifiable measurement data from system sensors and monitoring. unique_id user.derived.identifiable Unique identifier for a user assigned through system use. user_sensor user.derived.identifiable Measurement data derived about a user's environment through system use. workplace user.derived.identifiable Organization of employment. device user.derived.identifiable Data related to a user's device, configuration and setting. cookie_id user.derived.identifiable.device Cookie unique identification number. device_id user.derived.identifiable.device Device unique identification number. ip_address user.derived.identifiable.device Unique identifier related to device connection. nonidentifiable user.derived Non-user identifiable data derived related to a user as a result of user actions in the system. nonsensor user.derived.nonidentifiable Non-user identifiable measurement data derived from sensors and monitoring systems.","title":"User Derived Data"},{"location":"language/taxonomy/data_categories/#user-provided-data","text":"Data provided or created directly by a user of the system. Label Parent Key Description identifiable user.provided Data provided or created directly by a user that is linked to or identifies a user. biometric user.provided.identifiable Encoded characteristics provided by a user. childrens user.provided.identifiable Data relating to children. health_and_medical user.provided.identifiable Health records or individual's personal medical information. job_title user.provided.identifiable Professional data. name user.provided.identifiable User's real name. non_specific_age user.provided.identifiable Age range data. political_opinion user.provided.identifiable Data related to the individual's political opinions. race user.provided.identifiable Racial or ethnic origin data. religious_belief user.provided.identifiable Religion or religious belief. sexual_orientation user.provided.identifiable Personal sex life or sexual data. workplace user.provided.identifiable Organization of employment. date_of_birth user.provided.identifiable User's date of birth. gender user.provided.identifiable Gender of an individual. genetic user.provided.identifiable Data about the genetic makeup provided by a user. contact user.provided.identifiable User provided contact data for purposes other than account management. city user.provided.identifiable.contact User's city level address data. country user.provided.identifiable.contact User's country level address data. email user.provided.identifiable.contact User's provided email address. phone_number user.provided.identifiable.contact User's phone number. postal_code user.provided.identifiable.contact User's postal code. state user.provided.identifiable.contact User's state level address data. street user.provided.identifiable.contact User's street level address data. credentials user.provided.identifiable User provided authentication data. biometric_credentials user.provided.identifiable.credentials Credentials for system authentication. password user.provided.identifiable.credentials Password for system authentication. financial user.provided.identifiable Payment data and financial history. account_number user.provided.identifiable.financial User's account number for a payment card, bank account, or other financial system. government_id user.provided.identifiable State provided identification data. drivers_license_number user.provided.identifiable.government_id State issued driving identification number. national_identification_number user.provided.identifiable.government_id State issued personal identification number. passport_number user.provided.identifiable.government_id State issued passport data. nonidentifiable user.provided Data provided or created directly by a user that is not identifiable.","title":"User Provided Data"},{"location":"language/taxonomy/data_qualifiers/","text":"Data Qualifiers Reference Data Qualifiers describe the degree of identification of the given data. Think of this as a spectrum: on one end is completely anonymous data, i.e. it is impossible to identify an individual from it, and on the other end is data that specifically identifies an individual. Extensibility and Interopability Data Qualifiers in Fides are designed to support common privacy regulations and standards out of the box, these include GDPR, CCPA, LGPD and ISO 19944. You can extend the taxonomy to support your system needs. If you do this, we recommend extending from the existing categories to ensure interopability inside and outside your organization. If you have suggestions for core categories that should ship with the taxonomy, please submit your requests here Data Qualifiers Data Qualifiers are arranged as a series of nested subcategories, going from least identifiable (aggregated) to most identifiable (identified). Label Parent Key Description aggregated - Statistical data that does not contain individually identifying information but includes information about groups of individuals that renders individual identification impossible. anonymized anonymized Data where all attributes have been sufficiently altered that the individaul cannot be reidentified by this data or in combination with other datasets. unlinked_pseudonymized aggregated.anonymized Data for which all identifiers have been substituted with unrelated values and linkages broken such that it may not be reversed, even by the party that performed the pseudonymization. pseudonymized aggregated.anonymized.unlinked_pseudonymized Data for which all identifiers have been substituted with unrelated values, rendering the individual unidentifiable and cannot be reasonably reversed other than by the party that performed the pseudonymization. identified aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified Data that directly identifies an individual.","title":"Data Qualifiers"},{"location":"language/taxonomy/data_qualifiers/#data-qualifiers-reference","text":"Data Qualifiers describe the degree of identification of the given data. Think of this as a spectrum: on one end is completely anonymous data, i.e. it is impossible to identify an individual from it, and on the other end is data that specifically identifies an individual. Extensibility and Interopability Data Qualifiers in Fides are designed to support common privacy regulations and standards out of the box, these include GDPR, CCPA, LGPD and ISO 19944. You can extend the taxonomy to support your system needs. If you do this, we recommend extending from the existing categories to ensure interopability inside and outside your organization. If you have suggestions for core categories that should ship with the taxonomy, please submit your requests here","title":"Data Qualifiers Reference"},{"location":"language/taxonomy/data_qualifiers/#data-qualifiers","text":"Data Qualifiers are arranged as a series of nested subcategories, going from least identifiable (aggregated) to most identifiable (identified). Label Parent Key Description aggregated - Statistical data that does not contain individually identifying information but includes information about groups of individuals that renders individual identification impossible. anonymized anonymized Data where all attributes have been sufficiently altered that the individaul cannot be reidentified by this data or in combination with other datasets. unlinked_pseudonymized aggregated.anonymized Data for which all identifiers have been substituted with unrelated values and linkages broken such that it may not be reversed, even by the party that performed the pseudonymization. pseudonymized aggregated.anonymized.unlinked_pseudonymized Data for which all identifiers have been substituted with unrelated values, rendering the individual unidentifiable and cannot be reasonably reversed other than by the party that performed the pseudonymization. identified aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified Data that directly identifies an individual.","title":"Data Qualifiers"},{"location":"language/taxonomy/data_subjects/","text":"Data Subjects Reference A Data Subject is a label that describes a segment of individuals whose data you store. Data Subject labels are typically fairly broad -- \"Citizen\", \"Visitor\", \"Passenger\", and so on -- although you be as specific as your system needs: \"Fans in Section K\", for example. Object Structure fides_key string A string token of your own invention that uniquely identifies this Data Subject. It's your responsibility to ensure that the value is unique across all of your Data Subject objects. The value should only contain alphanumeric characters and underbars ( [A-Za-z0-9_] ). name string A UI-friendly label for the Data Subject. description string A human-readable description of the Data Subject. organization_fides_key string default: default_organization The fides key of the organization to which this Data Subject belongs. Extensibility and Interopability Data Subjects in Fides are designed to support common privacy regulations and standards out of the box, these include GDPR, CCPA, LGPD and ISO 19944. You can extend the taxonomy to support your organization's needs. If you do this, we recommend extending from the existing categories to ensure interopability inside and outside your organization. If you have suggestions for core categories that should ship with the taxonomy, please submit your requests here Default Data Subject Types Currently, your collection of Data Subjects is given as a flat list: A Data Subject can't contain other Data Subjects. Label Parent Key Description anonymous_user - An individual who is unidentifiable to the systems. Note - This should only be applied to truly anonymous users where there is no risk of re-identification citizen_voter - An individual registered to voter with a state or authority. commuter - An individual who is traveling or transiting in the context of location tracking. consultant - An individual employed in a consultative/temporary capacity by the organization. customer - An individual or other organization that purchases goods or services from the organization. employee - An individual employed by the organization. job_applicant - An individual applying for employment to the organization. next_of_kin - A relative of any other individual subject where such a relationship is known. passenger - An individual traveling on some means of provided transport. patient - An individual identified for the purposes of any medical care. prospect - An individual or organization to whom an organization is selling goods or services. shareholder - An individual or organization that holds equity in the organization. supplier_vendor - An individual or organization that provides services or goods to the organization. trainee - An individual undergoing training by the organization. visitor - An individual visiting a location.","title":"Data Subjects"},{"location":"language/taxonomy/data_subjects/#data-subjects-reference","text":"A Data Subject is a label that describes a segment of individuals whose data you store. Data Subject labels are typically fairly broad -- \"Citizen\", \"Visitor\", \"Passenger\", and so on -- although you be as specific as your system needs: \"Fans in Section K\", for example.","title":"Data Subjects Reference"},{"location":"language/taxonomy/data_subjects/#object-structure","text":"fides_key string A string token of your own invention that uniquely identifies this Data Subject. It's your responsibility to ensure that the value is unique across all of your Data Subject objects. The value should only contain alphanumeric characters and underbars ( [A-Za-z0-9_] ). name string A UI-friendly label for the Data Subject. description string A human-readable description of the Data Subject. organization_fides_key string default: default_organization The fides key of the organization to which this Data Subject belongs. Extensibility and Interopability Data Subjects in Fides are designed to support common privacy regulations and standards out of the box, these include GDPR, CCPA, LGPD and ISO 19944. You can extend the taxonomy to support your organization's needs. If you do this, we recommend extending from the existing categories to ensure interopability inside and outside your organization. If you have suggestions for core categories that should ship with the taxonomy, please submit your requests here","title":"Object Structure"},{"location":"language/taxonomy/data_subjects/#default-data-subject-types","text":"Currently, your collection of Data Subjects is given as a flat list: A Data Subject can't contain other Data Subjects. Label Parent Key Description anonymous_user - An individual who is unidentifiable to the systems. Note - This should only be applied to truly anonymous users where there is no risk of re-identification citizen_voter - An individual registered to voter with a state or authority. commuter - An individual who is traveling or transiting in the context of location tracking. consultant - An individual employed in a consultative/temporary capacity by the organization. customer - An individual or other organization that purchases goods or services from the organization. employee - An individual employed by the organization. job_applicant - An individual applying for employment to the organization. next_of_kin - A relative of any other individual subject where such a relationship is known. passenger - An individual traveling on some means of provided transport. patient - An individual identified for the purposes of any medical care. prospect - An individual or organization to whom an organization is selling goods or services. shareholder - An individual or organization that holds equity in the organization. supplier_vendor - An individual or organization that provides services or goods to the organization. trainee - An individual undergoing training by the organization. visitor - An individual visiting a location.","title":"Default Data Subject Types"},{"location":"language/taxonomy/data_uses/","text":"Data Uses Reference A Data Use is a label that denotes the way data is used in your system: \"Advertising, Marketing or Promotion\", \"First Party Advertising\", and \"Sharing for Legal Obligation\", as examples. Data Use objects form a hierarchy: A Data Use can contain any number of children, but a given Data Use may only have one parent. You assign a child Data Use to a parent by setting the child's parent_key property. For example, the third_party_sharing.personalized_advertising Data Use type is data used for personalized advertising when shared with third parties. Object Structure fides_key string A string token that uniquely identifies this Data Use. The value is a dot-separated concatenation of the fides_key values of the resource's ancestors plus a final element for this resource: grandparent.parent.this_data_use The final element ( this_data_use ) may only contain alphanumeric characters and underbars ( [A-Za-z0-9_] ). The dot character is reserved as a separator. name string A UI-friendly label for the Data Use. description string A human-readable description of the Data Use. parent_key string The fides key of the the Data Use's parent. organization_fides_key string default: default_organization The fides key of the organization to which this Data Use belongs. Extensibility and Interopability Data Uses in Fides are designed to support common privacy regulations and standards out of the box, these include GDPR, CCPA, LGPD and ISO 19944. You can extend the taxonomy to support your organization's needs. If you do this, we recommend extending from the existing categories to ensure interopability inside and outside your organization. If you have suggestions for core categories that should ship with the taxonomy, please submit your requests here Top Level Data Uses There are seven top-level Data Use classes: Label Parent Key Description provide - Provide, give, or make available the product, service, application or system. improve - Improve the product, service, application or system. personalize - Personalize the product, service, application or system. advertising - The promotion of products or services targeted to users based on the the processing of user provided data in the system. third_party_sharing - The transfer of specified data categories to third parties outside of the system/application's scope. collect - Collecting and storing data in order to use it for another purpose such as data training for ML. train_ai_system - Training an AI system. Please note when this data use is specified, the method and degree to which a user may be directly identified in the resulting AI system should be appended. For each top level classification there are multiple subclasses that provide richer context. Below is a reference for all subclasses of account , system and user to assist with describing all data across systems. Provide Data Uses Label Parent Key Description system provide The source system, product, service or application being provided to the user. provide.system.operations provide.system Use of specified data categories to operate and protect the system in order to provide the service. provide.system.operations.support provide.system.operations Use of specified data categories to provide support for operation and protection of the system in order to provide the service. provide.system.operations.support.optimization provide.system.operations.support Use of specified data categories to optimize and improve support operations in order to provide the service. provide.system.upgrades provide.system Offer upgrades or upsales such as increased capacity for the service based on monitoring of service usage. Improve Data Uses Label Parent Key Description system improve The source system, product, service or application being improved. Personalize Data Uses Label Parent Key Description system personalize The source system, product, service or application being personalized. Advertising Data Uses Label Parent Key Description first_party advertising The promotion of products or services targeting users based on processing of derviced data from prior use of the system. contextual advertising.first_party The promotion of products or services targeted to users based on the processing of derived data from the users prior use of the services. personalized advertising.first_party The targeting and changing of promotional content based on processing of specific data categories from the user. third_party advertising The promotion of products or services targeting users based on processing of specific categories of data acquired from third party sources. personalized advertising.third_party The targeting and changing of promotional content based on processing of specific categories of user data acquired from third party sources. Third Party Sharing Data Uses Label Parent Key Description payment_processing third_party_sharing Sharing of specified data categories with a third party for payment processing. personalized_advertising third_party_sharing Sharing of specified data categories for the purpose of marketing/advertising/promotion. fraud_detection third_party_sharing Sharing of specified data categories with a third party fo fraud prevention/detection. legal_obligation third_party_sharing Sharing of data for legal obligations, including contracts, applicable laws or regulations. Collection & AI Training Data Uses In the case of collection and train_ai_system , you will see these have no subclasses at present however define very specific data use cases that should be captured in data processes if they occur. Label Parent Key Description collect - Collecting and storing data in order to use it for another purpose such as data training for ML. train_ai_system - Training an AI system. Please note when this data use is specified, the method and degree to which a user may be directly identified in the resulting AI system should be appended.","title":"Data Uses"},{"location":"language/taxonomy/data_uses/#data-uses-reference","text":"A Data Use is a label that denotes the way data is used in your system: \"Advertising, Marketing or Promotion\", \"First Party Advertising\", and \"Sharing for Legal Obligation\", as examples. Data Use objects form a hierarchy: A Data Use can contain any number of children, but a given Data Use may only have one parent. You assign a child Data Use to a parent by setting the child's parent_key property. For example, the third_party_sharing.personalized_advertising Data Use type is data used for personalized advertising when shared with third parties.","title":"Data Uses Reference"},{"location":"language/taxonomy/data_uses/#object-structure","text":"fides_key string A string token that uniquely identifies this Data Use. The value is a dot-separated concatenation of the fides_key values of the resource's ancestors plus a final element for this resource: grandparent.parent.this_data_use The final element ( this_data_use ) may only contain alphanumeric characters and underbars ( [A-Za-z0-9_] ). The dot character is reserved as a separator. name string A UI-friendly label for the Data Use. description string A human-readable description of the Data Use. parent_key string The fides key of the the Data Use's parent. organization_fides_key string default: default_organization The fides key of the organization to which this Data Use belongs. Extensibility and Interopability Data Uses in Fides are designed to support common privacy regulations and standards out of the box, these include GDPR, CCPA, LGPD and ISO 19944. You can extend the taxonomy to support your organization's needs. If you do this, we recommend extending from the existing categories to ensure interopability inside and outside your organization. If you have suggestions for core categories that should ship with the taxonomy, please submit your requests here","title":"Object Structure"},{"location":"language/taxonomy/data_uses/#top-level-data-uses","text":"There are seven top-level Data Use classes: Label Parent Key Description provide - Provide, give, or make available the product, service, application or system. improve - Improve the product, service, application or system. personalize - Personalize the product, service, application or system. advertising - The promotion of products or services targeted to users based on the the processing of user provided data in the system. third_party_sharing - The transfer of specified data categories to third parties outside of the system/application's scope. collect - Collecting and storing data in order to use it for another purpose such as data training for ML. train_ai_system - Training an AI system. Please note when this data use is specified, the method and degree to which a user may be directly identified in the resulting AI system should be appended. For each top level classification there are multiple subclasses that provide richer context. Below is a reference for all subclasses of account , system and user to assist with describing all data across systems.","title":"Top Level Data Uses"},{"location":"language/taxonomy/data_uses/#provide-data-uses","text":"Label Parent Key Description system provide The source system, product, service or application being provided to the user. provide.system.operations provide.system Use of specified data categories to operate and protect the system in order to provide the service. provide.system.operations.support provide.system.operations Use of specified data categories to provide support for operation and protection of the system in order to provide the service. provide.system.operations.support.optimization provide.system.operations.support Use of specified data categories to optimize and improve support operations in order to provide the service. provide.system.upgrades provide.system Offer upgrades or upsales such as increased capacity for the service based on monitoring of service usage.","title":"Provide Data Uses"},{"location":"language/taxonomy/data_uses/#improve-data-uses","text":"Label Parent Key Description system improve The source system, product, service or application being improved.","title":"Improve Data Uses"},{"location":"language/taxonomy/data_uses/#personalize-data-uses","text":"Label Parent Key Description system personalize The source system, product, service or application being personalized.","title":"Personalize Data Uses"},{"location":"language/taxonomy/data_uses/#advertising-data-uses","text":"Label Parent Key Description first_party advertising The promotion of products or services targeting users based on processing of derviced data from prior use of the system. contextual advertising.first_party The promotion of products or services targeted to users based on the processing of derived data from the users prior use of the services. personalized advertising.first_party The targeting and changing of promotional content based on processing of specific data categories from the user. third_party advertising The promotion of products or services targeting users based on processing of specific categories of data acquired from third party sources. personalized advertising.third_party The targeting and changing of promotional content based on processing of specific categories of user data acquired from third party sources.","title":"Advertising Data Uses"},{"location":"language/taxonomy/data_uses/#third-party-sharing-data-uses","text":"Label Parent Key Description payment_processing third_party_sharing Sharing of specified data categories with a third party for payment processing. personalized_advertising third_party_sharing Sharing of specified data categories for the purpose of marketing/advertising/promotion. fraud_detection third_party_sharing Sharing of specified data categories with a third party fo fraud prevention/detection. legal_obligation third_party_sharing Sharing of data for legal obligations, including contracts, applicable laws or regulations.","title":"Third Party Sharing Data Uses"},{"location":"language/taxonomy/data_uses/#collection-ai-training-data-uses","text":"In the case of collection and train_ai_system , you will see these have no subclasses at present however define very specific data use cases that should be captured in data processes if they occur. Label Parent Key Description collect - Collecting and storing data in order to use it for another purpose such as data training for ML. train_ai_system - Training an AI system. Please note when this data use is specified, the method and degree to which a user may be directly identified in the resulting AI system should be appended.","title":"Collection &amp; AI Training Data Uses"},{"location":"language/taxonomy/explorer/","text":"Fides Taxonomy Explorer The taxonomy explorer is a useful way to visualize and review the taxonomy for those looking to explore in greater depth. Data Categories Data Uses Data Subjects Data Qualifiers","title":"Taxonomy Explorer"},{"location":"language/taxonomy/explorer/#fides-taxonomy-explorer","text":"The taxonomy explorer is a useful way to visualize and review the taxonomy for those looking to explore in greater depth. Data Categories Data Uses Data Subjects Data Qualifiers","title":"Fides Taxonomy Explorer"},{"location":"language/taxonomy/overview/","text":"Fides Taxonomy The Fides taxonomy contains four classification groups that are used together to easily describe all of the data types and associated processing behaviors of an entire tech stack; both the application and it's data storage. Summary of Taxonomy Classification Groups 1. Data Categories Data Categories are labels to describe the type of data processed by your software. These are most heavily used by the System and Dataset resources, where you can assign one or more data categories to each field. Data Categories are hierarchical with natural inheritance, meaning you can classify data coarsely with a high-level category (e.g. user.provided data), or you can classify it with greater precision using subcategories (e.g. user.provided.identifiable.contact.email data). Learn more about Data Categories in the taxonomy reference now . 2. Data Uses Data Uses are labels that describe how, or for what purpose(s) a component of your system is using data. Data Uses are also hierarchical with natural inheritance, meaning you can easily describe what you're using data for either coarsely (e.g. provide.system.operations ) or with more precision using subcategories (e.g. provide.system.operations.support.optimization ). Learn more about Data Uses in the taxonomy reference now . 3. Data Subjects Data Subject is a label commonly used in the regulatory world to describe the users of a system who's data is being processed. In many systems a generic user label may be sufficient, however Fides language is intended to provide greater control through specificity where needed. Examples of this are: anonymous_user employee customer patient next_of_kin Learn more about Data Subjects in the taxonomy reference now . 4. Data Qualifiers Data Qualifiers describe the degree of identification of the given data. Think of this as a spectrum: on one end is completely anonymous data, i.e. it is impossible to identify an individual from it, and on the other end is data that specifically identifies an individual. Along this spectrum are labels that describe the degree of identification that a given data might provide, such as: identified anonymized aggregated Learn more about Data Qualifiers in the taxonomy reference now . Extensibility & Interopability The Fides language is designed to support common privacy compliance regulations and standards out of the box, these include GDPR, CCPA, LGPD and ISO 19944. You can extend the taxonomy to support your organization's needs. If you do this, we recommend extending from the existing categories to ensure interopability inside and outside your organization.","title":"Overview"},{"location":"language/taxonomy/overview/#fides-taxonomy","text":"The Fides taxonomy contains four classification groups that are used together to easily describe all of the data types and associated processing behaviors of an entire tech stack; both the application and it's data storage.","title":"Fides Taxonomy"},{"location":"language/taxonomy/overview/#summary-of-taxonomy-classification-groups","text":"","title":"Summary of Taxonomy Classification Groups"},{"location":"language/taxonomy/overview/#1-data-categories","text":"Data Categories are labels to describe the type of data processed by your software. These are most heavily used by the System and Dataset resources, where you can assign one or more data categories to each field. Data Categories are hierarchical with natural inheritance, meaning you can classify data coarsely with a high-level category (e.g. user.provided data), or you can classify it with greater precision using subcategories (e.g. user.provided.identifiable.contact.email data). Learn more about Data Categories in the taxonomy reference now .","title":"1. Data Categories"},{"location":"language/taxonomy/overview/#2-data-uses","text":"Data Uses are labels that describe how, or for what purpose(s) a component of your system is using data. Data Uses are also hierarchical with natural inheritance, meaning you can easily describe what you're using data for either coarsely (e.g. provide.system.operations ) or with more precision using subcategories (e.g. provide.system.operations.support.optimization ). Learn more about Data Uses in the taxonomy reference now .","title":"2. Data Uses"},{"location":"language/taxonomy/overview/#3-data-subjects","text":"Data Subject is a label commonly used in the regulatory world to describe the users of a system who's data is being processed. In many systems a generic user label may be sufficient, however Fides language is intended to provide greater control through specificity where needed. Examples of this are: anonymous_user employee customer patient next_of_kin Learn more about Data Subjects in the taxonomy reference now .","title":"3. Data Subjects"},{"location":"language/taxonomy/overview/#4-data-qualifiers","text":"Data Qualifiers describe the degree of identification of the given data. Think of this as a spectrum: on one end is completely anonymous data, i.e. it is impossible to identify an individual from it, and on the other end is data that specifically identifies an individual. Along this spectrum are labels that describe the degree of identification that a given data might provide, such as: identified anonymized aggregated Learn more about Data Qualifiers in the taxonomy reference now .","title":"4. Data Qualifiers"},{"location":"language/taxonomy/overview/#extensibility-interopability","text":"The Fides language is designed to support common privacy compliance regulations and standards out of the box, these include GDPR, CCPA, LGPD and ISO 19944. You can extend the taxonomy to support your organization's needs. If you do this, we recommend extending from the existing categories to ensure interopability inside and outside your organization.","title":"Extensibility &amp; Interopability"},{"location":"quickstart/docker/","text":"Running Fidesctl in Docker The recommended way to get Fidesctl running is via Docker. The following guide will describe how to get things going, step-by-step. System Requirements Docker and Docker-Compose are the only requirements here. Install docker locally (see Docker Desktop or your preferred installation). The minimum verified Docker version is 20.10.8 If your docker installation did not include docker-compose , make sure to get at least version 1.29.0 . Installation instructions can be found here . Docker Setup This is a reference file that you can copy/paste into a local docker-compose.yml file. It will create a database and spin up the fidesctl webserver. Make sure that you don't have anything else running on port 5432 or 8080 before using this file. docker-compose.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 services: fidesctl: image: ethyca/fidesctl:1.0.0 command: fidesctl webserver healthcheck: test: [\"CMD\", \"curl\", \"-f\", \"http://0.0.0.0:8000/health\"] interval: 5s timeout: 5s retries: 5 depends_on: fidesctl-db: condition: service_healthy expose: - 8080 ports: - \"8080:8080\" environment: - FIDESCTL__CLI__SERVER_URL=http://fidesctl:8080 - FIDESCTL__API__DATABASE_URL=postgresql+psycopg2://postgres:fidesctl@fidesctl-db:5432/fidesctl volumes: - type: bind source: ./fides_resources/ # Update this to be the path of your fides_resource folder target: /fides/fides_resources/ read_only: False fidesctl-db: image: postgres:12 healthcheck: test: [\"CMD-SHELL\", \"pg_isready -U postgres\"] interval: 5s timeout: 5s retries: 5 volumes: - postgres-fidesctl:/var/lib/postgresql/data expose: - 5432 ports: - \"5432:5432\" environment: - POSTGRES_USER=postgres - POSTGRES_PASSWORD=fidesctl - POSTGRES_DB=fidesctl volumes: postgres-fidesctl: Now we can start interacting with our installation. Let's run the following commands to get going: docker-compose up -d -> This will spin up the docker-compose file in the background docker-compose run --rm fidesctl /bin/bash -> Opens a shell within the fidesctl container fidesctl ping -> This confirms that your fidesctl CLI can reach the server and everything is ready to go! 1 2 3 4 5 6 7 root@796cfde906f1:/fides/fidesctl# fidesctl ping Pinging http://fidesctl:8080/health... { \"data\" : { \"message\" : \"Fidesctl API service is healthy!\" } } Next Steps Now that you're up and running, you can use fidesctl from the shell to get a list of all the possible CLI commands. You're now ready to start enforcing privacy with Fidesctl! See the Tutorial page for a step-by-step guide on setting up a Fidesctl data privacy workflow.","title":"Running Fidesctl in Docker"},{"location":"quickstart/docker/#running-fidesctl-in-docker","text":"The recommended way to get Fidesctl running is via Docker. The following guide will describe how to get things going, step-by-step.","title":"Running Fidesctl in Docker"},{"location":"quickstart/docker/#system-requirements","text":"Docker and Docker-Compose are the only requirements here. Install docker locally (see Docker Desktop or your preferred installation). The minimum verified Docker version is 20.10.8 If your docker installation did not include docker-compose , make sure to get at least version 1.29.0 . Installation instructions can be found here .","title":"System Requirements"},{"location":"quickstart/docker/#docker-setup","text":"This is a reference file that you can copy/paste into a local docker-compose.yml file. It will create a database and spin up the fidesctl webserver. Make sure that you don't have anything else running on port 5432 or 8080 before using this file. docker-compose.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 services: fidesctl: image: ethyca/fidesctl:1.0.0 command: fidesctl webserver healthcheck: test: [\"CMD\", \"curl\", \"-f\", \"http://0.0.0.0:8000/health\"] interval: 5s timeout: 5s retries: 5 depends_on: fidesctl-db: condition: service_healthy expose: - 8080 ports: - \"8080:8080\" environment: - FIDESCTL__CLI__SERVER_URL=http://fidesctl:8080 - FIDESCTL__API__DATABASE_URL=postgresql+psycopg2://postgres:fidesctl@fidesctl-db:5432/fidesctl volumes: - type: bind source: ./fides_resources/ # Update this to be the path of your fides_resource folder target: /fides/fides_resources/ read_only: False fidesctl-db: image: postgres:12 healthcheck: test: [\"CMD-SHELL\", \"pg_isready -U postgres\"] interval: 5s timeout: 5s retries: 5 volumes: - postgres-fidesctl:/var/lib/postgresql/data expose: - 5432 ports: - \"5432:5432\" environment: - POSTGRES_USER=postgres - POSTGRES_PASSWORD=fidesctl - POSTGRES_DB=fidesctl volumes: postgres-fidesctl: Now we can start interacting with our installation. Let's run the following commands to get going: docker-compose up -d -> This will spin up the docker-compose file in the background docker-compose run --rm fidesctl /bin/bash -> Opens a shell within the fidesctl container fidesctl ping -> This confirms that your fidesctl CLI can reach the server and everything is ready to go! 1 2 3 4 5 6 7 root@796cfde906f1:/fides/fidesctl# fidesctl ping Pinging http://fidesctl:8080/health... { \"data\" : { \"message\" : \"Fidesctl API service is healthy!\" } }","title":"Docker Setup"},{"location":"quickstart/docker/#next-steps","text":"Now that you're up and running, you can use fidesctl from the shell to get a list of all the possible CLI commands. You're now ready to start enforcing privacy with Fidesctl! See the Tutorial page for a step-by-step guide on setting up a Fidesctl data privacy workflow.","title":"Next Steps"},{"location":"quickstart/local_full/","text":"Running Fidesctl Locally (Full Installation) Fidesctl can be spun up locally in its entirety without relying on Docker, but it is a bit more complicated. If you'd like something simpler, please see the Running Fidesctl in Docker guide for the recommended setup experience or Running Fidesctl Locally (Standalone) for the simplest possible installation. System Requirements See the Prerequisites and Dependencies page for more information. Fidesctl installation The next step is to install fidesctl via pip with the required extras: 1 pip install \"fidesctl[webserver]\" For more information on pip installing fidesctl as well as the other potential extras, see the Installation from PyPI guide. Database installation Due to environmental differences, there is no specific guide on running/configuring your own Postgres database outside of the version constraints mentioned in the System Requirements section above. Make sure to note your database credentials and use them to generate a SQLAlchemy Connection String . This will be used in the database_url configuration value mentioned below. Configuring Fidesctl See our Configuration guide for more information on how to configure fidesctl. Running the webserver Now that we've spun up our database and set our configuration values, it's time to start our webserver. In a shell, run the following command: 1 fidesctl webserver The fidesctl webserver will now be accessible at localhost:8080 , you can test this by going to localhost:8080/health and localhost:8080/docs . Using the CLI Now that the database and webserver are running, it's time to verify that the whole installation is working properly. Run the command fidesctl ping to make sure that the CLI can talk to the webserver. The output should look something like this: 1 2 3 4 5 6 Pinging http://fidesctl:8080/health... { \"data\": { \"message\": \"Fidesctl API service is healthy!\" } } Next is to verify that the database is reachable from the webserver. Run the command fidesctl ls organizations to verify that all is working. The output should look something like this: 1 2 3 4 5 6 7 8 9 [ { \"fides_key\" : \"default_organization\" , \"organization_fides_key\" : \"default_organization\" , \"name\" : null , \"description\" : null , \"organization_parent_key\" : null } ] That's it! Your local installation of fidesctl is completely up and running. Next Steps See the Tutorial page for a step-by-step guide on setting up a Fides data privacy workflow.","title":"Running Fidesctl Locally (Full Installation)"},{"location":"quickstart/local_full/#running-fidesctl-locally-full-installation","text":"Fidesctl can be spun up locally in its entirety without relying on Docker, but it is a bit more complicated. If you'd like something simpler, please see the Running Fidesctl in Docker guide for the recommended setup experience or Running Fidesctl Locally (Standalone) for the simplest possible installation.","title":"Running Fidesctl Locally (Full Installation)"},{"location":"quickstart/local_full/#system-requirements","text":"See the Prerequisites and Dependencies page for more information.","title":"System Requirements"},{"location":"quickstart/local_full/#fidesctl-installation","text":"The next step is to install fidesctl via pip with the required extras: 1 pip install \"fidesctl[webserver]\" For more information on pip installing fidesctl as well as the other potential extras, see the Installation from PyPI guide.","title":"Fidesctl installation"},{"location":"quickstart/local_full/#database-installation","text":"Due to environmental differences, there is no specific guide on running/configuring your own Postgres database outside of the version constraints mentioned in the System Requirements section above. Make sure to note your database credentials and use them to generate a SQLAlchemy Connection String . This will be used in the database_url configuration value mentioned below.","title":"Database installation"},{"location":"quickstart/local_full/#configuring-fidesctl","text":"See our Configuration guide for more information on how to configure fidesctl.","title":"Configuring Fidesctl"},{"location":"quickstart/local_full/#running-the-webserver","text":"Now that we've spun up our database and set our configuration values, it's time to start our webserver. In a shell, run the following command: 1 fidesctl webserver The fidesctl webserver will now be accessible at localhost:8080 , you can test this by going to localhost:8080/health and localhost:8080/docs .","title":"Running the webserver"},{"location":"quickstart/local_full/#using-the-cli","text":"Now that the database and webserver are running, it's time to verify that the whole installation is working properly. Run the command fidesctl ping to make sure that the CLI can talk to the webserver. The output should look something like this: 1 2 3 4 5 6 Pinging http://fidesctl:8080/health... { \"data\": { \"message\": \"Fidesctl API service is healthy!\" } } Next is to verify that the database is reachable from the webserver. Run the command fidesctl ls organizations to verify that all is working. The output should look something like this: 1 2 3 4 5 6 7 8 9 [ { \"fides_key\" : \"default_organization\" , \"organization_fides_key\" : \"default_organization\" , \"name\" : null , \"description\" : null , \"organization_parent_key\" : null } ] That's it! Your local installation of fidesctl is completely up and running.","title":"Using the CLI"},{"location":"quickstart/local_full/#next-steps","text":"See the Tutorial page for a step-by-step guide on setting up a Fides data privacy workflow.","title":"Next Steps"},{"location":"quickstart/local_standalone/","text":"Running Fidesctl Locally (Standalone) This method of running fidesctl requires zero dependencies outside of Python and a default pip installation of fidesctl. It is intended as the fastest possible quick start and is not designed for production-grade deployments. In standalone mode most CLI commands will not work as they require webserver connectivity for persistence, and so those commands are not available. Crucially though, the core evaluation functionality is still present. To run in standalone mode, use one of the following methods: CLI flag 1 fidesctl --local <subcommand> fidesctl.toml 1 2 [cli] local_mode = true For more information on running a full fidesctl installation, see the Running Fidesctl Locally (Full Installation) or Running Fidesctl in Docker pages. System Requirements See the Python section of the Prerequisites and Dependencies page for more information. Fidesctl Installation The next step is to install fidesctl via pip: 1 pip install fidesctl For more information on installing fidesctl with pip, as well as the other potential extras, see the Installation from PyPI guide. Using the CLI Now that we have fidesctl installed, let's verify the installation: Command 1 fidesctl --version Expected Output 1 fidesctl, version 1.0.0 That's it! Your local standalone installation of fidesctl is up and running. Next Steps See the Tutorial page for a step-by-step guide on setting up a Fides data privacy workflow.","title":"Running Fidesctl Locally (Standalone)"},{"location":"quickstart/local_standalone/#running-fidesctl-locally-standalone","text":"This method of running fidesctl requires zero dependencies outside of Python and a default pip installation of fidesctl. It is intended as the fastest possible quick start and is not designed for production-grade deployments. In standalone mode most CLI commands will not work as they require webserver connectivity for persistence, and so those commands are not available. Crucially though, the core evaluation functionality is still present. To run in standalone mode, use one of the following methods: CLI flag 1 fidesctl --local <subcommand> fidesctl.toml 1 2 [cli] local_mode = true For more information on running a full fidesctl installation, see the Running Fidesctl Locally (Full Installation) or Running Fidesctl in Docker pages.","title":"Running Fidesctl Locally (Standalone)"},{"location":"quickstart/local_standalone/#system-requirements","text":"See the Python section of the Prerequisites and Dependencies page for more information.","title":"System Requirements"},{"location":"quickstart/local_standalone/#fidesctl-installation","text":"The next step is to install fidesctl via pip: 1 pip install fidesctl For more information on installing fidesctl with pip, as well as the other potential extras, see the Installation from PyPI guide.","title":"Fidesctl Installation"},{"location":"quickstart/local_standalone/#using-the-cli","text":"Now that we have fidesctl installed, let's verify the installation: Command 1 fidesctl --version Expected Output 1 fidesctl, version 1.0.0 That's it! Your local standalone installation of fidesctl is up and running.","title":"Using the CLI"},{"location":"quickstart/local_standalone/#next-steps","text":"See the Tutorial page for a step-by-step guide on setting up a Fides data privacy workflow.","title":"Next Steps"},{"location":"quickstart/overview/","text":"Quick Start The fastest way to get fidesctl running is to launch it using the fidesctl standlone) guide. For guides on setting up a complete installation, see the Docker instructions here or the local full-installation instructions here .","title":"Overview"},{"location":"quickstart/overview/#quick-start","text":"The fastest way to get fidesctl running is to launch it using the fidesctl standlone) guide. For guides on setting up a complete installation, see the Docker instructions here or the local full-installation instructions here .","title":"Quick Start"},{"location":"tutorial/","text":"Tutorial Overview In this tutorial you will learn how to use fidesctl to solve a real-world data privacy problem. These steps closely follow the example found in the ethyca/fidesdemo repository here . You will run a local instance of a basic web app to demonstrate the use of Fidesctl as part of a \"real\" project that uses: Flask to run a web server simulating a basic e-commerce application PostgreSQL as the application's database SQLAlchemy to connect to the database fidesctl to declare privacy manifests and evaluate policies The app itself is the Flask tutorial app , but modified to simulate an e-commerce marketplace. This helps to highlight some basic examples of data categories that might be stored in a \"real\" user-facing application. Setup Instructions System Requirements Before beginning, ensure you have the following software installed and configured to your liking: Docker (v12+) Python (v3.7+) Make pg_config (required for the Python project. Installed via Homebrew with brew install libpq or brew install postgres .) Installation Clone the ethyca/fidesdemo repository to your machine. Checkout the repository's tutorial-start tag : 1 git checkout tutorial-start Each step in this tutorial will explain the changes made in each commit of the fidesdemo repository. You can follow along by checking out each one, or by building everything yourself and comparing your work to each commit's changeset. Navigate to the repository directory in your command line, and run: 1 make install This will create the project's virtual environment, and set up all required containers, databases, and dependencies. If you prefer, you may execute the project's test suite by running: 1 make test About the Example Application (\"Flaskr\") This example application is meant to simulate a basic e-commerce marketplace where users can create accounts and purchase products from one another. Using the web app you can: Register a new user Login as a user Post a \"product\" for sale Delete/update products you've posted Purchase a product (no products are actually for sale) The schema itself is designed to highlight a few very simple examples of how identifiable data might get stored in a web application like this one. The sample data below shows what this looks like: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 flaskr = # SELECT * FROM users; id | created_at | email | password | first_name | last_name ----+---------------------+-------------------+------------------------------------+------------+----------- 1 | 2020 -01-01 00 :00:00 | admin@example.com | pbkdf2:sha256:260000 $O87nanbSkl ... | Admin | User 2 | 2020 -01-03 00 :00:00 | user@example.com | pbkdf2:sha256:260000 $PGcBy5NzZe ... | Example | User ( 2 rows ) flaskr = # SELECT * FROM products; id | created_at | seller_id | name | description | price ----+---------------------+-----------+-------------------+--------------------------------------+------- 1 | 2020 -01-01 12 :00:00 | 1 | Example Product 1 | A description for example product #1 | 10 2 | 2020 -01-02 12 :00:00 | 1 | Example Product 2 | A description for example product #2 | 20 3 | 2020 -01-03 12 :00:00 | 2 | Example Product 3 | A description for example product #3 | 50 ( 3 rows ) flaskr = # SELECT * FROM purchases; id | created_at | product_id | buyer_id | street_1 | street_2 | city | state | zip ----+---------------------+------------+----------+----------------+----------+-------------+-------+------- 1 | 2020 -01-04 12 :00:00 | 1 | 2 | 123 Example St | Apt 123 | Exampletown | NY | 12345 ( 1 row ) Check Your Progress After running the commands outlined in the Installation section, your app should resemble the state of the ethyca/fidesdemo repository at the tutorial-start tag. Next: Add Fidesctl to the App Work within the sample app prior to the installation and configuration of the Fides developer tools to add fidesctl .","title":"Overview"},{"location":"tutorial/#tutorial-overview","text":"In this tutorial you will learn how to use fidesctl to solve a real-world data privacy problem. These steps closely follow the example found in the ethyca/fidesdemo repository here . You will run a local instance of a basic web app to demonstrate the use of Fidesctl as part of a \"real\" project that uses: Flask to run a web server simulating a basic e-commerce application PostgreSQL as the application's database SQLAlchemy to connect to the database fidesctl to declare privacy manifests and evaluate policies The app itself is the Flask tutorial app , but modified to simulate an e-commerce marketplace. This helps to highlight some basic examples of data categories that might be stored in a \"real\" user-facing application.","title":"Tutorial Overview"},{"location":"tutorial/#setup-instructions","text":"","title":"Setup Instructions"},{"location":"tutorial/#system-requirements","text":"Before beginning, ensure you have the following software installed and configured to your liking: Docker (v12+) Python (v3.7+) Make pg_config (required for the Python project. Installed via Homebrew with brew install libpq or brew install postgres .)","title":"System Requirements"},{"location":"tutorial/#installation","text":"Clone the ethyca/fidesdemo repository to your machine. Checkout the repository's tutorial-start tag : 1 git checkout tutorial-start Each step in this tutorial will explain the changes made in each commit of the fidesdemo repository. You can follow along by checking out each one, or by building everything yourself and comparing your work to each commit's changeset. Navigate to the repository directory in your command line, and run: 1 make install This will create the project's virtual environment, and set up all required containers, databases, and dependencies. If you prefer, you may execute the project's test suite by running: 1 make test","title":"Installation"},{"location":"tutorial/#about-the-example-application-flaskr","text":"This example application is meant to simulate a basic e-commerce marketplace where users can create accounts and purchase products from one another. Using the web app you can: Register a new user Login as a user Post a \"product\" for sale Delete/update products you've posted Purchase a product (no products are actually for sale) The schema itself is designed to highlight a few very simple examples of how identifiable data might get stored in a web application like this one. The sample data below shows what this looks like: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 flaskr = # SELECT * FROM users; id | created_at | email | password | first_name | last_name ----+---------------------+-------------------+------------------------------------+------------+----------- 1 | 2020 -01-01 00 :00:00 | admin@example.com | pbkdf2:sha256:260000 $O87nanbSkl ... | Admin | User 2 | 2020 -01-03 00 :00:00 | user@example.com | pbkdf2:sha256:260000 $PGcBy5NzZe ... | Example | User ( 2 rows ) flaskr = # SELECT * FROM products; id | created_at | seller_id | name | description | price ----+---------------------+-----------+-------------------+--------------------------------------+------- 1 | 2020 -01-01 12 :00:00 | 1 | Example Product 1 | A description for example product #1 | 10 2 | 2020 -01-02 12 :00:00 | 1 | Example Product 2 | A description for example product #2 | 20 3 | 2020 -01-03 12 :00:00 | 2 | Example Product 3 | A description for example product #3 | 50 ( 3 rows ) flaskr = # SELECT * FROM purchases; id | created_at | product_id | buyer_id | street_1 | street_2 | city | state | zip ----+---------------------+------------+----------+----------------+----------+-------------+-------+------- 1 | 2020 -01-04 12 :00:00 | 1 | 2 | 123 Example St | Apt 123 | Exampletown | NY | 12345 ( 1 row )","title":"About the Example Application (\"Flaskr\")"},{"location":"tutorial/#check-your-progress","text":"After running the commands outlined in the Installation section, your app should resemble the state of the ethyca/fidesdemo repository at the tutorial-start tag.","title":"Check Your Progress"},{"location":"tutorial/#next-add-fidesctl-to-the-app","text":"Work within the sample app prior to the installation and configuration of the Fides developer tools to add fidesctl .","title":"Next: Add Fidesctl to the App"},{"location":"tutorial/add/","text":"Add Fidesctl to the App In this step you will incorporate fidesctl , which will enable you to declare your system , dataset , and policy resources as manifest YAML files. Add the fidesctl Dependency Open the requirements.txt file and add the fidesctl dependency by including the following line: 1 fidesctl>=1.0.0 Then, install the dependencies by running: 1 pip install -r requirements.txt Configure Fidesctl Fidesctl needs some configuration to work for your environment; this is handled by looking for a TOML file in the current working directory. Create a fidesctl.toml file at the root level of the repository. It should contain the following configuration: 1 2 3 4 5 6 [cli] server_url = \"http://localhost:8080\" [api] database_url = \"postgresql://postgres:postgres@localhost:5432/fidesctl\" test_database_url = \"postgresql://postgres:postgres@localhost:5432/fidesctl_test\" The [cli] -scoped server_url option specifies the address that the fidesctl CLI will use when connecting to the fidesctl server. The [api] -scoped database_url option specifies the connection string that the fidesctl API will use to connect to the PostgreSQL database created in the previous step. The [api] -scoped test_database_url option that will override database_url when the fidesctl server is started with the environment variable FIDESCTL_TEST_MODE set to True Run Fidesctl via Docker Now that the dependency is included in the project and the configuration is in place, the fidesctl server needs to be told to run. The app uses docker-compose to orchestrate resources, so include fidesctl as a service by adding the following configuration after the database service: 1 2 3 4 5 6 7 8 9 10 11 fidesctl : image : ethyca/fidesctl:latest depends_on : - db command : fidesctl webserver expose : - 8080 ports : - \"8080:8080\" environment : - FIDESCTL__API__DATABASE_URL=postgresql://postgres:postgres@db:5432/fidesctl See the fidesctl installation guide for a more detailed fidesctl server setup walkthrough, and the docker-compose documentation for an explanation of the above configuration options. Add Makefile Commands This step is optional, but the commands added to the Makefile here will be referenced later in this tutorial. The above changes will enable fidesctl CLI commands to be run within the project's virtual environment. You can simplify usage of the fidesctl CLI by adding commands to the Makefile like the following: 1 2 3 4 5 6 7 8 9 10 11 fidesctl-init-db : compose - up @echo \"Initializing fidesctl db..\" ./venv/bin/fidesctl init-db fidesctl-evaluate : compose - up @echo \"Evaluating policy with fidesctl...\" ./venv/bin/fidesctl evaluate --dry fides_resources fidesctl-generate-dataset : compose - up @echo \"Generating dataset with fidesctl...\" ./venv/bin/fidesctl generate-dataset postgresql://postgres:postgres@localhost:5432/flaskr example.yml Note: There are additional Makefile changes included in the fidesdemo repository, but they are only intended to enable cleaner usage of this project for demonstration purposes. Check Your Progress After making the above changes, your app should resemble the state of the ethyca/fidesdemo repository at the fidesops-start tag. Next: Annotate the Resources Now that the fidesctl tools are available to use within the app's virtual environment, the next step is to configure fidesctl to work with the specifics of this app. This can be done by creating manifest files to annotate the resources .","title":"Add Fidesctl to the App"},{"location":"tutorial/add/#add-fidesctl-to-the-app","text":"In this step you will incorporate fidesctl , which will enable you to declare your system , dataset , and policy resources as manifest YAML files.","title":"Add Fidesctl to the App"},{"location":"tutorial/add/#add-the-fidesctl-dependency","text":"Open the requirements.txt file and add the fidesctl dependency by including the following line: 1 fidesctl>=1.0.0 Then, install the dependencies by running: 1 pip install -r requirements.txt","title":"Add the fidesctl Dependency"},{"location":"tutorial/add/#configure-fidesctl","text":"Fidesctl needs some configuration to work for your environment; this is handled by looking for a TOML file in the current working directory. Create a fidesctl.toml file at the root level of the repository. It should contain the following configuration: 1 2 3 4 5 6 [cli] server_url = \"http://localhost:8080\" [api] database_url = \"postgresql://postgres:postgres@localhost:5432/fidesctl\" test_database_url = \"postgresql://postgres:postgres@localhost:5432/fidesctl_test\" The [cli] -scoped server_url option specifies the address that the fidesctl CLI will use when connecting to the fidesctl server. The [api] -scoped database_url option specifies the connection string that the fidesctl API will use to connect to the PostgreSQL database created in the previous step. The [api] -scoped test_database_url option that will override database_url when the fidesctl server is started with the environment variable FIDESCTL_TEST_MODE set to True","title":"Configure Fidesctl"},{"location":"tutorial/add/#run-fidesctl-via-docker","text":"Now that the dependency is included in the project and the configuration is in place, the fidesctl server needs to be told to run. The app uses docker-compose to orchestrate resources, so include fidesctl as a service by adding the following configuration after the database service: 1 2 3 4 5 6 7 8 9 10 11 fidesctl : image : ethyca/fidesctl:latest depends_on : - db command : fidesctl webserver expose : - 8080 ports : - \"8080:8080\" environment : - FIDESCTL__API__DATABASE_URL=postgresql://postgres:postgres@db:5432/fidesctl See the fidesctl installation guide for a more detailed fidesctl server setup walkthrough, and the docker-compose documentation for an explanation of the above configuration options.","title":"Run Fidesctl via Docker"},{"location":"tutorial/add/#add-makefile-commands","text":"This step is optional, but the commands added to the Makefile here will be referenced later in this tutorial. The above changes will enable fidesctl CLI commands to be run within the project's virtual environment. You can simplify usage of the fidesctl CLI by adding commands to the Makefile like the following: 1 2 3 4 5 6 7 8 9 10 11 fidesctl-init-db : compose - up @echo \"Initializing fidesctl db..\" ./venv/bin/fidesctl init-db fidesctl-evaluate : compose - up @echo \"Evaluating policy with fidesctl...\" ./venv/bin/fidesctl evaluate --dry fides_resources fidesctl-generate-dataset : compose - up @echo \"Generating dataset with fidesctl...\" ./venv/bin/fidesctl generate-dataset postgresql://postgres:postgres@localhost:5432/flaskr example.yml Note: There are additional Makefile changes included in the fidesdemo repository, but they are only intended to enable cleaner usage of this project for demonstration purposes.","title":"Add Makefile Commands"},{"location":"tutorial/add/#check-your-progress","text":"After making the above changes, your app should resemble the state of the ethyca/fidesdemo repository at the fidesops-start tag.","title":"Check Your Progress"},{"location":"tutorial/add/#next-annotate-the-resources","text":"Now that the fidesctl tools are available to use within the app's virtual environment, the next step is to configure fidesctl to work with the specifics of this app. This can be done by creating manifest files to annotate the resources .","title":"Next: Annotate the Resources"},{"location":"tutorial/dataset/","text":"Annotate the Dataset Making the fidesctl tools available within the app's virtual environment is just the beginning. Next, configure fidesctl for this app by annotating its resources using manifest files. First, create a fides_resources directory at the project root. This is where the manifest files will be stored. Note: In a production app this directory can have any name, but it's a best practice to create a specific directory to house the fidesctl manifest files. Fundamentally, the data ecosystem is built on data that is stored somewhere . In fidesctl, Datasets are used for granular, field-level annotations of exactly what data your systems are storing and where that data is stored. For example, an app might declare one dataset for a Postgres application database, a second dataset for a Mongo orders collection, and a third dataset for some CSV files in cloud storage. The Dataset resource provides a database-agnostic way to annotate the fields stored in these systems with Data Categories, providing a metadata layer consumable by other tooling. This app contains a single PostgreSQL dataset. Create a dataset resource to annotate it by adding a flaskr_postgres_dataset.yml file to the fides_resources directory. To annotate this dataset correctly, go through each column of each table and answer the question: \"What data categories are stored here?\" For this project, the file should contain the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 dataset : - fides_key : flaskr_postgres_dataset name : Flaskr Example PostgreSQL Database description : Application database for Flaskr example app collections : - name : products fields : - name : created_at data_categories : [ system.operations ] - name : description data_categories : [ user.provided.identifiable ] - name : id data_categories : [ system.operations ] - name : name data_categories : [ user.provided.identifiable ] - name : price data_categories : [ user.provided.identifiable ] - name : seller_id data_categories : [ user.derived.identifiable.unique_id ] - name : purchases fields : - name : buyer_id data_categories : [ user.derived.identifiable.unique_id ] - name : city data_categories : [ user.provided.identifiable.contact.city ] - name : created_at data_categories : [ system.operations ] - name : id data_categories : [ system.operations ] - name : product_id data_categories : [ system.operations ] - name : state data_categories : [ user.provided.identifiable.contact.state ] - name : street_1 data_categories : [ user.provided.identifiable.contact.street ] - name : street_2 data_categories : [ user.provided.identifiable.contact.street ] - name : zip data_categories : [ user.provided.identifiable.contact.postal_code ] - name : users fields : - name : created_at data_categories : [ system.operations ] - name : email data_categories : [ user.provided.identifiable.contact.email ] - name : first_name data_categories : [ user.provided.identifiable.name ] - name : id data_categories : [ user.derived.identifiable.unique_id ] - name : last_name data_categories : [ user.provided.identifiable.name ] - name : password data_categories : [ user.provided.identifiable.credentials.password ] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized As an alternative to manually authoring the resource file, you can also use the generate-dataset CLI command. The CLI will connect to the database and automatically generate a non-annotated resource YAML file in the specified location, based on the database schema. For this project, the command is: 1 2 3 ./venv/bin/fidesctl generate-dataset \\ postgresql://postgres:postgres@localhost:5432/flaskr \\ fides_resources/flaskr_postgres_dataset.yml Understanding the Dataset Resource This YAML serves as the foundation of fideslang , the Fides language; it answers \" What data and kinds of data do we have? \" and \" How is our data organized? \". The language is built on declaring the types of data found in storage for your organization. In traditional SQL, fidesctl defines the following: \"datasets\" as database schemas \"collections\" as database tables \"fields\" as database columns For NoSQL datasets, fidesctl defines the following: \"dataset\" \"collection\" as a logical grouping of data fields (ie: in MongoDB, this is called a \"Collection\") \"fields\" as a reference to an individual data element (ie: in MongoDB, this is called a \"field\") Additionally, fideslang has attributes that describe what kind of data is contained in this dataset. We use the following attributes to describe the data: Name Type Description name String The name of this field description String A description of what this field contains data_categories List[FidesKey] The types of sensitive data, as defined by the taxonomy, that can be found in this field data_qualifier FidesKey The level of deidentification for the dataset For more detail on Dataset resources, see the full Dataset resource documentation . PRO TIP As you're progressing with the tutorial, we recommend installing our fidesctl VS Code extension , which will validate the syntax in real-time as you're writing your resource files! Maintaining a Dataset Resource As apps add more databases and other services to store potentially sensitive data, it is recommended that updating this resource file becomes a part of the development process when building a new feature. Next: Annotate the System Resource With the underlying database resource declared, you must now include the database in an application-level System resource annotation .","title":"Annotate the Dataset"},{"location":"tutorial/dataset/#annotate-the-dataset","text":"Making the fidesctl tools available within the app's virtual environment is just the beginning. Next, configure fidesctl for this app by annotating its resources using manifest files. First, create a fides_resources directory at the project root. This is where the manifest files will be stored. Note: In a production app this directory can have any name, but it's a best practice to create a specific directory to house the fidesctl manifest files. Fundamentally, the data ecosystem is built on data that is stored somewhere . In fidesctl, Datasets are used for granular, field-level annotations of exactly what data your systems are storing and where that data is stored. For example, an app might declare one dataset for a Postgres application database, a second dataset for a Mongo orders collection, and a third dataset for some CSV files in cloud storage. The Dataset resource provides a database-agnostic way to annotate the fields stored in these systems with Data Categories, providing a metadata layer consumable by other tooling. This app contains a single PostgreSQL dataset. Create a dataset resource to annotate it by adding a flaskr_postgres_dataset.yml file to the fides_resources directory. To annotate this dataset correctly, go through each column of each table and answer the question: \"What data categories are stored here?\" For this project, the file should contain the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 dataset : - fides_key : flaskr_postgres_dataset name : Flaskr Example PostgreSQL Database description : Application database for Flaskr example app collections : - name : products fields : - name : created_at data_categories : [ system.operations ] - name : description data_categories : [ user.provided.identifiable ] - name : id data_categories : [ system.operations ] - name : name data_categories : [ user.provided.identifiable ] - name : price data_categories : [ user.provided.identifiable ] - name : seller_id data_categories : [ user.derived.identifiable.unique_id ] - name : purchases fields : - name : buyer_id data_categories : [ user.derived.identifiable.unique_id ] - name : city data_categories : [ user.provided.identifiable.contact.city ] - name : created_at data_categories : [ system.operations ] - name : id data_categories : [ system.operations ] - name : product_id data_categories : [ system.operations ] - name : state data_categories : [ user.provided.identifiable.contact.state ] - name : street_1 data_categories : [ user.provided.identifiable.contact.street ] - name : street_2 data_categories : [ user.provided.identifiable.contact.street ] - name : zip data_categories : [ user.provided.identifiable.contact.postal_code ] - name : users fields : - name : created_at data_categories : [ system.operations ] - name : email data_categories : [ user.provided.identifiable.contact.email ] - name : first_name data_categories : [ user.provided.identifiable.name ] - name : id data_categories : [ user.derived.identifiable.unique_id ] - name : last_name data_categories : [ user.provided.identifiable.name ] - name : password data_categories : [ user.provided.identifiable.credentials.password ] data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized As an alternative to manually authoring the resource file, you can also use the generate-dataset CLI command. The CLI will connect to the database and automatically generate a non-annotated resource YAML file in the specified location, based on the database schema. For this project, the command is: 1 2 3 ./venv/bin/fidesctl generate-dataset \\ postgresql://postgres:postgres@localhost:5432/flaskr \\ fides_resources/flaskr_postgres_dataset.yml","title":"Annotate the Dataset"},{"location":"tutorial/dataset/#understanding-the-dataset-resource","text":"This YAML serves as the foundation of fideslang , the Fides language; it answers \" What data and kinds of data do we have? \" and \" How is our data organized? \". The language is built on declaring the types of data found in storage for your organization. In traditional SQL, fidesctl defines the following: \"datasets\" as database schemas \"collections\" as database tables \"fields\" as database columns For NoSQL datasets, fidesctl defines the following: \"dataset\" \"collection\" as a logical grouping of data fields (ie: in MongoDB, this is called a \"Collection\") \"fields\" as a reference to an individual data element (ie: in MongoDB, this is called a \"field\") Additionally, fideslang has attributes that describe what kind of data is contained in this dataset. We use the following attributes to describe the data: Name Type Description name String The name of this field description String A description of what this field contains data_categories List[FidesKey] The types of sensitive data, as defined by the taxonomy, that can be found in this field data_qualifier FidesKey The level of deidentification for the dataset For more detail on Dataset resources, see the full Dataset resource documentation .","title":"Understanding the Dataset Resource"},{"location":"tutorial/dataset/#pro-tip","text":"As you're progressing with the tutorial, we recommend installing our fidesctl VS Code extension , which will validate the syntax in real-time as you're writing your resource files!","title":"PRO TIP"},{"location":"tutorial/dataset/#maintaining-a-dataset-resource","text":"As apps add more databases and other services to store potentially sensitive data, it is recommended that updating this resource file becomes a part of the development process when building a new feature.","title":"Maintaining a Dataset Resource"},{"location":"tutorial/dataset/#next-annotate-the-system-resource","text":"With the underlying database resource declared, you must now include the database in an application-level System resource annotation .","title":"Next: Annotate the System Resource"},{"location":"tutorial/google/","text":"Add Google Analytics To better understand the behavior of the app's users, add Google Analytics to the app and a fidesctl System resource to annotate it. Define the App's Google Analytics Identifier Open the flaskr/__init__.py file in your favorite editor, and define the GOOGLE_ANALYTICS_ID constant below line 7: 1 GOOGLE_ANALYTICS_ID = \"UA-xxxxxxxxx-y\" In the create_app function defined on line 11, include the Google Analytics ID value in the application's configuration by adding the following line below line 17: 1 GOOGLE_ANALYTICS_ID = GOOGLE_ANALYTICS_ID , Add the Google Analytics Script Open the flaskr/templates/base.html file in your favorite editor, and include the following at the beginning of the <head> tag: 1 2 3 4 5 6 7 8 9 10 {% if config['GOOGLE_ANALYTICS_ID'] %} <!-- Global site tag (gtag.js) - Google Analytics --> < script async src = \"https://www.googletagmanager.com/gtag/js?id={{ config['GOOGLE_ANALYTICS_ID'] }}\" ></ script > < script > window . dataLayer = window . dataLayer || []; function gtag (){ dataLayer . push ( arguments );} gtag ( \"js\" , new Date ()); gtag ( \"config\" , \"{{ config['GOOGLE_ANALYTICS_ID'] }}\" ); </ script > {% endif %} Annotate a Fidesctl System Resource To ensure that the app's policies can account for the data collected by Google Analytics, define a new fidesctl System resource by adding a google_analytics_system.yml file to the fides_resources directory. This System resource annotation should reflect the uses of the Google Analytics features configured in this app's implementation. Some things to think about might be: What fields are being tracked? (See the field reference documentation for a list of all possible fields) What data_use value would be appropriate for this app? ( provide vs. improve ) For this System resource, the file should contain the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 system : - fides_key : google_analytics_system name : Google Analytics description : Hosted third party analytics to track and analyze user behaviour system_type : Third Party privacy_declarations : # See the Google Analytics documentation for a description of the possible # fields collected by the tracker, including page URL, referrer, cookie ID, etc. # https://developers.google.com/analytics/devguides/collection/analyticsjs/field-reference - name : Track & report on page views data_categories : - user.derived.identifiable.browsing_history - user.derived.identifiable.device.cookie_id - user.derived.identifiable.telemetry - user.derived.identifiable.location - user.derived.nonidentifiable data_use : improve data_subjects : - customer data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized # Google Analytics collects the user's IP address and derives geographic dimensions server-side. # See https://developers.google.com/analytics/devguides/reporting/realtime/dimsmets/geonetwork - name : Derive user geographic location data_categories : - user.derived.identifiable.device.ip_address - user.derived.identifiable.location - user.derived.identifiable data_use : improve data_subjects : - customer # With \"IP Anonymization\" disabled, IP Addresses will remain identifiable. # See https://developers.google.com/analytics/devguides/collection/gtagjs/ip-anonymization data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified There are two privacy_declaration s defined: The use of pseudonymized behavioral data to analyze app usage The use of user IP addresses to derive their geographic location The two declarations reflect the separate purposes for which data is collected and used by Google Analytics here. They are meant to align with the app's actual usage of its specific Google Analytics implementation; there are many other data uses for Google Analytics, but this app does not leverage them. Check Your Progress After making the above changes, your app should resemble the state of the ethyca/fidesdemo repository at the fidesctl-add-google-analytics tag . Next: Manage Google Analytics with Fidesctl Google Analytics is implemented and working correctly, but - oh no! - executing make fidesctl-evaluate shows a failure: 1 2 3 4 5 6 7 8 { \"fides_key\" : \"4e739b1b_732e_43b1_8747_e833905dfc4c_1635789050\" , \"status\" : \"FAIL\" , \"details\" : [ \"Declaration (Derive user geographic location) of System (google_analytics_system) failed Rule (Minimize User Identifiable Data) from Policy (flaskr_policy)\" ], \"message\" : null } In the final step, enable the fidesctl policy already in place to pass by updating Google Analytics .","title":"Add Google Analytics"},{"location":"tutorial/google/#add-google-analytics","text":"To better understand the behavior of the app's users, add Google Analytics to the app and a fidesctl System resource to annotate it.","title":"Add Google Analytics"},{"location":"tutorial/google/#define-the-apps-google-analytics-identifier","text":"Open the flaskr/__init__.py file in your favorite editor, and define the GOOGLE_ANALYTICS_ID constant below line 7: 1 GOOGLE_ANALYTICS_ID = \"UA-xxxxxxxxx-y\" In the create_app function defined on line 11, include the Google Analytics ID value in the application's configuration by adding the following line below line 17: 1 GOOGLE_ANALYTICS_ID = GOOGLE_ANALYTICS_ID ,","title":"Define the App's Google Analytics Identifier"},{"location":"tutorial/google/#add-the-google-analytics-script","text":"Open the flaskr/templates/base.html file in your favorite editor, and include the following at the beginning of the <head> tag: 1 2 3 4 5 6 7 8 9 10 {% if config['GOOGLE_ANALYTICS_ID'] %} <!-- Global site tag (gtag.js) - Google Analytics --> < script async src = \"https://www.googletagmanager.com/gtag/js?id={{ config['GOOGLE_ANALYTICS_ID'] }}\" ></ script > < script > window . dataLayer = window . dataLayer || []; function gtag (){ dataLayer . push ( arguments );} gtag ( \"js\" , new Date ()); gtag ( \"config\" , \"{{ config['GOOGLE_ANALYTICS_ID'] }}\" ); </ script > {% endif %}","title":"Add the Google Analytics Script"},{"location":"tutorial/google/#annotate-a-fidesctl-system-resource","text":"To ensure that the app's policies can account for the data collected by Google Analytics, define a new fidesctl System resource by adding a google_analytics_system.yml file to the fides_resources directory. This System resource annotation should reflect the uses of the Google Analytics features configured in this app's implementation. Some things to think about might be: What fields are being tracked? (See the field reference documentation for a list of all possible fields) What data_use value would be appropriate for this app? ( provide vs. improve ) For this System resource, the file should contain the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 system : - fides_key : google_analytics_system name : Google Analytics description : Hosted third party analytics to track and analyze user behaviour system_type : Third Party privacy_declarations : # See the Google Analytics documentation for a description of the possible # fields collected by the tracker, including page URL, referrer, cookie ID, etc. # https://developers.google.com/analytics/devguides/collection/analyticsjs/field-reference - name : Track & report on page views data_categories : - user.derived.identifiable.browsing_history - user.derived.identifiable.device.cookie_id - user.derived.identifiable.telemetry - user.derived.identifiable.location - user.derived.nonidentifiable data_use : improve data_subjects : - customer data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized # Google Analytics collects the user's IP address and derives geographic dimensions server-side. # See https://developers.google.com/analytics/devguides/reporting/realtime/dimsmets/geonetwork - name : Derive user geographic location data_categories : - user.derived.identifiable.device.ip_address - user.derived.identifiable.location - user.derived.identifiable data_use : improve data_subjects : - customer # With \"IP Anonymization\" disabled, IP Addresses will remain identifiable. # See https://developers.google.com/analytics/devguides/collection/gtagjs/ip-anonymization data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified There are two privacy_declaration s defined: The use of pseudonymized behavioral data to analyze app usage The use of user IP addresses to derive their geographic location The two declarations reflect the separate purposes for which data is collected and used by Google Analytics here. They are meant to align with the app's actual usage of its specific Google Analytics implementation; there are many other data uses for Google Analytics, but this app does not leverage them.","title":"Annotate a Fidesctl System Resource"},{"location":"tutorial/google/#check-your-progress","text":"After making the above changes, your app should resemble the state of the ethyca/fidesdemo repository at the fidesctl-add-google-analytics tag .","title":"Check Your Progress"},{"location":"tutorial/google/#next-manage-google-analytics-with-fidesctl","text":"Google Analytics is implemented and working correctly, but - oh no! - executing make fidesctl-evaluate shows a failure: 1 2 3 4 5 6 7 8 { \"fides_key\" : \"4e739b1b_732e_43b1_8747_e833905dfc4c_1635789050\" , \"status\" : \"FAIL\" , \"details\" : [ \"Declaration (Derive user geographic location) of System (google_analytics_system) failed Rule (Minimize User Identifiable Data) from Policy (flaskr_policy)\" ], \"message\" : null } In the final step, enable the fidesctl policy already in place to pass by updating Google Analytics .","title":"Next: Manage Google Analytics with Fidesctl"},{"location":"tutorial/pass/","text":"Manage Google Analytics with Fidesctl By default, Google Analytics disables \"IP Anonymization\" (see the documentation for more information). The \"Minimize User Identifiable Data\" fidesctl Policy resource created earlier in this tutorial is configured to reject data collection of this nature. POP QUIZ There are two options to remedy this situation, and to get the make fidesctl-evaluate command to pass. Which option is best? Modify the \"Minimize User Identifiable Data\" policy resource to accept data collection of this nature Modify the Google Analytics implementation such that it becomes compliant with the \"Minimize User Identifiable Data\" policy Click to see the correct answer Option 2 is the best path forward: the Google Analytics implementation should be modified, not the \"Minimize User Identifiable Data\" policy resource. The policy resource's configuration is dictated by the app's Privacy Policy, and changes could lead to larger compliance issues throughout the system. Enable IP Anonymization Open the flaskr/templates/base.html file in your favorite editor, and add the following line just above the closing <script> tag in the Google Analytics script: 1 2 3 4 5 6 7 8 9 10 11 {% if config['GOOGLE_ANALYTICS_ID'] %} <!-- Global site tag (gtag.js) - Google Analytics --> <script async src=\"https://www.googletagmanager.com/gtag/js?id={{ config['GOOGLE_ANALYTICS_ID'] }}\"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag(\"js\", new Date()); gtag(\"config\", \"{{ config['GOOGLE_ANALYTICS_ID'] }}\"); + gtag(\"config\", \"{{ config['GOOGLE_ANALYTICS_ID'] }}\", { 'anonymize_ip': true }); </script> {% endif %} Update the Google Analytics System Resource Now that the data collection practices in the Google Analytics script have changed, the associated fidesctl System resource should be updated accordingly. Open the fides_resources/google_analytics_system.yml file in your favorite editor, and modify the last line (the data_qualifier configuration) so that it reads: 1 data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized By removing the final identified key of the Fides taxonomy, the updated nature of the data collection practices used in this System resource now aligns with the actual behavior of the updated Google Analytics script. Evaluate the Fidesctl Policies Execute the make fidesctl-evaluate command one final time. You should see the following output: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Evaluating policy with fidesctl... ./venv/bin/fidesctl evaluate --dry fides_resources Loading resource manifests from: fides_resources Taxonomy successfully created. ---------- Processing dataset resources... WOULD CREATE 0 dataset resources. WOULD UPDATE 0 dataset resources. WOULD SKIP 1 dataset resources. ---------- Processing system resources... WOULD CREATE 0 system resources. WOULD UPDATE 1 system resources. WOULD SKIP 1 system resources. ---------- Processing policy resources... WOULD CREATE 0 policy resources. WOULD UPDATE 0 policy resources. WOULD SKIP 1 policy resources. ---------- Loading resource manifests from: fides_resources Taxonomy successfully created. Evaluating the following policies: flaskr_policy ---------- Checking for missing resources... Executing evaluations... Evaluation passed! The fidesctl policy evaluation passes! Check Your Progress After making the above changes, your app should resemble the state of the ethyca/fidesdemo repository at the fidesctl-demo tag.","title":"Manage Google Analytics with Fidesctl"},{"location":"tutorial/pass/#manage-google-analytics-with-fidesctl","text":"By default, Google Analytics disables \"IP Anonymization\" (see the documentation for more information). The \"Minimize User Identifiable Data\" fidesctl Policy resource created earlier in this tutorial is configured to reject data collection of this nature.","title":"Manage Google Analytics with Fidesctl"},{"location":"tutorial/pass/#pop-quiz","text":"There are two options to remedy this situation, and to get the make fidesctl-evaluate command to pass. Which option is best? Modify the \"Minimize User Identifiable Data\" policy resource to accept data collection of this nature Modify the Google Analytics implementation such that it becomes compliant with the \"Minimize User Identifiable Data\" policy Click to see the correct answer Option 2 is the best path forward: the Google Analytics implementation should be modified, not the \"Minimize User Identifiable Data\" policy resource. The policy resource's configuration is dictated by the app's Privacy Policy, and changes could lead to larger compliance issues throughout the system.","title":"POP QUIZ"},{"location":"tutorial/pass/#enable-ip-anonymization","text":"Open the flaskr/templates/base.html file in your favorite editor, and add the following line just above the closing <script> tag in the Google Analytics script: 1 2 3 4 5 6 7 8 9 10 11 {% if config['GOOGLE_ANALYTICS_ID'] %} <!-- Global site tag (gtag.js) - Google Analytics --> <script async src=\"https://www.googletagmanager.com/gtag/js?id={{ config['GOOGLE_ANALYTICS_ID'] }}\"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag(\"js\", new Date()); gtag(\"config\", \"{{ config['GOOGLE_ANALYTICS_ID'] }}\"); + gtag(\"config\", \"{{ config['GOOGLE_ANALYTICS_ID'] }}\", { 'anonymize_ip': true }); </script> {% endif %}","title":"Enable IP Anonymization"},{"location":"tutorial/pass/#update-the-google-analytics-system-resource","text":"Now that the data collection practices in the Google Analytics script have changed, the associated fidesctl System resource should be updated accordingly. Open the fides_resources/google_analytics_system.yml file in your favorite editor, and modify the last line (the data_qualifier configuration) so that it reads: 1 data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized By removing the final identified key of the Fides taxonomy, the updated nature of the data collection practices used in this System resource now aligns with the actual behavior of the updated Google Analytics script.","title":"Update the Google Analytics System Resource"},{"location":"tutorial/pass/#evaluate-the-fidesctl-policies","text":"Execute the make fidesctl-evaluate command one final time. You should see the following output: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Evaluating policy with fidesctl... ./venv/bin/fidesctl evaluate --dry fides_resources Loading resource manifests from: fides_resources Taxonomy successfully created. ---------- Processing dataset resources... WOULD CREATE 0 dataset resources. WOULD UPDATE 0 dataset resources. WOULD SKIP 1 dataset resources. ---------- Processing system resources... WOULD CREATE 0 system resources. WOULD UPDATE 1 system resources. WOULD SKIP 1 system resources. ---------- Processing policy resources... WOULD CREATE 0 policy resources. WOULD UPDATE 0 policy resources. WOULD SKIP 1 policy resources. ---------- Loading resource manifests from: fides_resources Taxonomy successfully created. Evaluating the following policies: flaskr_policy ---------- Checking for missing resources... Executing evaluations... Evaluation passed! The fidesctl policy evaluation passes!","title":"Evaluate the Fidesctl Policies"},{"location":"tutorial/pass/#check-your-progress","text":"After making the above changes, your app should resemble the state of the ethyca/fidesdemo repository at the fidesctl-demo tag.","title":"Check Your Progress"},{"location":"tutorial/policy/","text":"Write a Policy Fidesctl's privacy declarations provide rich metadata about systems, the data categories they process, and the uses of that data. Policies allow you to enforce constraints on these declarations and decide what combinations to allow or reject at your company, thus providing a layer of automation to control data privacy at the source. Define a single Policy by creating a flaskr_policy.yml file in the fides_resources directory. For this project, the file should contain the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 policy : - fides_key : flaskr_policy name : Flaskr Privacy Policy description : A privacy policy for the example Flask app rules : - fides_key : minimize_user_identifiable_data name : Minimize User Identifiable Data description : Reject collecting any user identifiable data for uses other than system operations data_categories : matches : ANY values : - user.provided.identifiable - user.derived.identifiable data_uses : matches : ANY values : - improve - personalize - advertising - third_party_sharing - collect - train_ai_system data_subjects : matches : ANY values : - customer data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - fides_key : reject_sensitive_data name : Reject Sensitive Data description : Reject collecting sensitive user data for any use data_categories : matches : ANY values : - user.provided.identifiable.biometric - user.provided.identifiable.childrens - user.provided.identifiable.genetic - user.provided.identifiable.health_and_medical - user.provided.identifiable.political_opinion - user.provided.identifiable.race - user.provided.identifiable.religious_belief - user.provided.identifiable.sexual_orientation data_uses : matches : ANY values : - provide - improve - personalize - advertising - third_party_sharing - collect - train_ai_system data_subjects : matches : ANY values : - customer data_qualifier : aggregated This demo application is built without any real controls on user data, so the Fides policy is relatively restrictive. The two rules can be interpreted respectfully as: Do not use identifiable data for anything other than the app's primary functions (after all, it's just a demo app!). Do not collect any sensitive data at all. As a safe default, this is the type of policy you might add to all projects. Later, you can make exceptions (if you are working on a project that requires these categories). Understanding the Policy The purpose of a privacy policy is to state what types of data are allowed for certain means of use. In fidesctl, a Policy is comprised of rules against which the system's privacy declarations are evaluated. Policies will evaluate the data subjects, data category, and data qualifier values against data use cases. This generates a boolean output to either allow or reject the process from proceeding. Policies use the following attributes: Name Type Description fides_key FidesKey An identifier label that must be unique within your organization. A fides_key can only contain alphanumeric characters and _ . data_categories List[DataRule] The types of sensitive data as defined by the taxonomy data_uses List[DataRule] The various categories of data processing and operations within your organization data_subjects List[DataRule] The individual persons to whom you data rule pertains data_qualifier String The acceptable or non-acceptable level of deidentification For more detail on Policy resources, see the full Policy resource documentation . Maintaining a Policy As global privacy laws change and businesses scale, a company's policies will evolve with them. We recommend that updating this resource file becomes a regular part of the development planning process when building a new feature. Check Your Progress After making the above changes and the changes in the previous two steps, your app should resemble the state of the ethyca/fidesdemo repository at the fidesctl-manifests tag . Next: Add Google Analytics Improve usage telemetry for this project by adding the nefarious tracker, Google Analytics .","title":"Write a Policy"},{"location":"tutorial/policy/#write-a-policy","text":"Fidesctl's privacy declarations provide rich metadata about systems, the data categories they process, and the uses of that data. Policies allow you to enforce constraints on these declarations and decide what combinations to allow or reject at your company, thus providing a layer of automation to control data privacy at the source. Define a single Policy by creating a flaskr_policy.yml file in the fides_resources directory. For this project, the file should contain the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 policy : - fides_key : flaskr_policy name : Flaskr Privacy Policy description : A privacy policy for the example Flask app rules : - fides_key : minimize_user_identifiable_data name : Minimize User Identifiable Data description : Reject collecting any user identifiable data for uses other than system operations data_categories : matches : ANY values : - user.provided.identifiable - user.derived.identifiable data_uses : matches : ANY values : - improve - personalize - advertising - third_party_sharing - collect - train_ai_system data_subjects : matches : ANY values : - customer data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified - fides_key : reject_sensitive_data name : Reject Sensitive Data description : Reject collecting sensitive user data for any use data_categories : matches : ANY values : - user.provided.identifiable.biometric - user.provided.identifiable.childrens - user.provided.identifiable.genetic - user.provided.identifiable.health_and_medical - user.provided.identifiable.political_opinion - user.provided.identifiable.race - user.provided.identifiable.religious_belief - user.provided.identifiable.sexual_orientation data_uses : matches : ANY values : - provide - improve - personalize - advertising - third_party_sharing - collect - train_ai_system data_subjects : matches : ANY values : - customer data_qualifier : aggregated This demo application is built without any real controls on user data, so the Fides policy is relatively restrictive. The two rules can be interpreted respectfully as: Do not use identifiable data for anything other than the app's primary functions (after all, it's just a demo app!). Do not collect any sensitive data at all. As a safe default, this is the type of policy you might add to all projects. Later, you can make exceptions (if you are working on a project that requires these categories).","title":"Write a Policy"},{"location":"tutorial/policy/#understanding-the-policy","text":"The purpose of a privacy policy is to state what types of data are allowed for certain means of use. In fidesctl, a Policy is comprised of rules against which the system's privacy declarations are evaluated. Policies will evaluate the data subjects, data category, and data qualifier values against data use cases. This generates a boolean output to either allow or reject the process from proceeding. Policies use the following attributes: Name Type Description fides_key FidesKey An identifier label that must be unique within your organization. A fides_key can only contain alphanumeric characters and _ . data_categories List[DataRule] The types of sensitive data as defined by the taxonomy data_uses List[DataRule] The various categories of data processing and operations within your organization data_subjects List[DataRule] The individual persons to whom you data rule pertains data_qualifier String The acceptable or non-acceptable level of deidentification For more detail on Policy resources, see the full Policy resource documentation .","title":"Understanding the Policy"},{"location":"tutorial/policy/#maintaining-a-policy","text":"As global privacy laws change and businesses scale, a company's policies will evolve with them. We recommend that updating this resource file becomes a regular part of the development planning process when building a new feature.","title":"Maintaining a Policy"},{"location":"tutorial/policy/#check-your-progress","text":"After making the above changes and the changes in the previous two steps, your app should resemble the state of the ethyca/fidesdemo repository at the fidesctl-manifests tag .","title":"Check Your Progress"},{"location":"tutorial/policy/#next-add-google-analytics","text":"Improve usage telemetry for this project by adding the nefarious tracker, Google Analytics .","title":"Next: Add Google Analytics"},{"location":"tutorial/system/","text":"Annotate the System Now that you've built out the underlying database that describes how and what type of data is stored, include the database in application-level \"systems\", another critical fidesctl resource. This app contains a single Flaskr Web Application system resource. Create a system resource to annotate it by adding a flaskr_system.yml file to the fides_resources directory. Writing a Fides privacy declaration requires answering the questions: \"What data is this system processing?\" , \"Why is the system processing this data?\" , \"Whose data is involved?\" , and \"How is the data protected?\" Fides answers these questions with a privacy_declaration that describes the data categories, use, subjects, and qualifier. This application is quite simple, so it only has a single use: to provide the service to users. In order to do so, it requires some identifiable data (name, email, contact, etc.) and it derives some data as well (unique IDs). For this project, the file should contain the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 system : - fides_key : flaskr_system name : Flaskr Web Application description : An example Flask web app that simulates an e-commerce application system_type : Application privacy_declarations : - name : Provide e-commerce operations to example customers data_categories : - user.provided.identifiable - user.derived.identifiable - system.operations data_use : provide.system.operations data_subjects : - customer data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified dataset_references : - flaskr_postgres_dataset Privacy Declarations can be read colloquially as \"This system uses sensitive data types of data_categories for data_subjects with the purpose of data_use at a deidentification level of data_qualifier \". In a production app, create as many systems as are necessary to cover all relevant business applications. Understanding Systems In fidesctl, Systems are used to model things that process data for organizations (applications, services, 3rd party APIs, etc.) and describe how these datasets are used for business functions. These groupings are not mutually exclusive; they answer \" How and why are these datasets being used? \" The System resource groups the lowest level of data (your datasets) with your business use cases, and associates qualitative attributes describing the type of data being used. Systems use the following attributes: Name Type Description data_categories List[FidesKey] The types of sensitive data as defined by the taxonomy data_subjects List[FidesKey] The individual persons whose data resides in your datasets data_use List[FidesKey] The various categories of data processing and operations within your organization data_qualifier List[FidesKey] The level of deidentification for the dataset dataset_refereneces List[FidesKey] The fides_key (s) of the dataset fields used in this Privacy Declaration For more detail on System resources, see the full System resource documentation . Maintaining a System Resource As use cases evolve, your systems' data subjects, data categories, and data uses will change as well. We recommend that updating this resource file becomes a regular part of the development planning process when building a new feature. PRO TIP As more systems are added to a data ecosystem, consider grouping systems into another Fides resource type, called a Registry . Next: Write a Policy With database and system resources declared, you must now enforce your data constraints by writing a Policy .","title":"Annotate the System"},{"location":"tutorial/system/#annotate-the-system","text":"Now that you've built out the underlying database that describes how and what type of data is stored, include the database in application-level \"systems\", another critical fidesctl resource. This app contains a single Flaskr Web Application system resource. Create a system resource to annotate it by adding a flaskr_system.yml file to the fides_resources directory. Writing a Fides privacy declaration requires answering the questions: \"What data is this system processing?\" , \"Why is the system processing this data?\" , \"Whose data is involved?\" , and \"How is the data protected?\" Fides answers these questions with a privacy_declaration that describes the data categories, use, subjects, and qualifier. This application is quite simple, so it only has a single use: to provide the service to users. In order to do so, it requires some identifiable data (name, email, contact, etc.) and it derives some data as well (unique IDs). For this project, the file should contain the following configuration: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 system : - fides_key : flaskr_system name : Flaskr Web Application description : An example Flask web app that simulates an e-commerce application system_type : Application privacy_declarations : - name : Provide e-commerce operations to example customers data_categories : - user.provided.identifiable - user.derived.identifiable - system.operations data_use : provide.system.operations data_subjects : - customer data_qualifier : aggregated.anonymized.unlinked_pseudonymized.pseudonymized.identified dataset_references : - flaskr_postgres_dataset Privacy Declarations can be read colloquially as \"This system uses sensitive data types of data_categories for data_subjects with the purpose of data_use at a deidentification level of data_qualifier \". In a production app, create as many systems as are necessary to cover all relevant business applications.","title":"Annotate the System"},{"location":"tutorial/system/#understanding-systems","text":"In fidesctl, Systems are used to model things that process data for organizations (applications, services, 3rd party APIs, etc.) and describe how these datasets are used for business functions. These groupings are not mutually exclusive; they answer \" How and why are these datasets being used? \" The System resource groups the lowest level of data (your datasets) with your business use cases, and associates qualitative attributes describing the type of data being used. Systems use the following attributes: Name Type Description data_categories List[FidesKey] The types of sensitive data as defined by the taxonomy data_subjects List[FidesKey] The individual persons whose data resides in your datasets data_use List[FidesKey] The various categories of data processing and operations within your organization data_qualifier List[FidesKey] The level of deidentification for the dataset dataset_refereneces List[FidesKey] The fides_key (s) of the dataset fields used in this Privacy Declaration For more detail on System resources, see the full System resource documentation .","title":"Understanding Systems"},{"location":"tutorial/system/#maintaining-a-system-resource","text":"As use cases evolve, your systems' data subjects, data categories, and data uses will change as well. We recommend that updating this resource file becomes a regular part of the development planning process when building a new feature. PRO TIP As more systems are added to a data ecosystem, consider grouping systems into another Fides resource type, called a Registry .","title":"Maintaining a System Resource"},{"location":"tutorial/system/#next-write-a-policy","text":"With database and system resources declared, you must now enforce your data constraints by writing a Policy .","title":"Next: Write a Policy"}]}